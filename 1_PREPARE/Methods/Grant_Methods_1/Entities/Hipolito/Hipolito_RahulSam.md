https://www.youtube.com/watch?v=WoUnmStPji8
Inês Hipólito on Computational Phenomenology, E-Cognition and the AI of Maurice Merleau-Ponty

in this episode the thought in that paper was um to kind of like raise up the question which is not a question
that is uh it's it's new um other people other people like Tim vanhelder who is
very well known for his work in dynamical uh systems as Ro as as Rose
the same kind of question which is what is the requirement of um uh uh borrowing
certain Concepts from the toolkit of these other more computationalist view
such as uh the view that is developed within um uh modularity of the Mind such
as Notions like uh representation for example what does what what purpose Tim
velder asks and we also ask in this paper what purpose does really the notion of representation is going to
serve um if any uh in um in that framework to understand the mind so we
follow that um and get inspiration on that a little bit we are on board with that question really do not see a reason
to keep that cognitivist uh view um to think about uh these uh Network systems
that would require an explanation that includes the notion of representation so that's kind of like where we are in the
paper and then as we think about and we are inspired by these questions right
then we we need to think about the ways in which we develop machine Learning Systems right so the question then
became if we are training machine Learning Systems to to do tasks such as
perception then perhaps a better uh way of thinking about uh perception would be
rather than taking perception as the old school computationalist uh view takes it
uh is a recognition of inputs and outputs very computational in character
then perhaps uh we should um take perception as the phenomenon of
perception right and by phenomenon of perception here I mean going to the
phenomenology of perception and taking perception as a phenomenon that is
characterized with all of those phenomenal aspects to it rather than a
computational process of a recognition of inputs and outputs with um with a
with a with some form of uh in computational information processing he
everyone welcome to this conversation with Dr iness Hipolito a philosopher of
AI working through the tradition of ecognition and phenomenology uh it was a riveting and
solidifying dialogue uh I had the opportunity to go to MCC University uh in Sydney um and visit the philosophy
Department which is a beautiful building uh and just speak to some of the people there but also had this uh amazing
conversation with Dr hippoo uh we discussed a variety of things um all the way from uh the free energy principle to
the philosophy of AI to deep learning to Simone Deb and wetstein and of course
perhaps Dr hippo's favorite um marce mulu ponti before we get started though bit of a housekeeping note on a
technicality unfortunately uh when we were having the podcast my microphone it
caus a bit of flux in the audio and it can be a bit unpleasant to listen to um
although it's completely fine in the sense that you could understand what I'm saying it is still audible but it can be
a bit unpleasant um and I hate to do this I really do hate to do this but I think it's still better if you watch
this episode over listen to it because um I'm going to put an overlay text of
the questions that I ask uh in s if I may um and then you'll have a bit more
context as to what she's saying and what she's responding ing to now I do hate to do this because I know most of the
people are listeners to this podcast but unfortunately uh I tried my best to rectify this issue to the editors uh and
I think uh I've I've done my best with what I could but perhaps for a better listening or in this case a better
watching experience I do recommend watching the episode on YouTube uh over
listening to it on Spotify or apple podcast uh whatever the case may be but I sure I'm glad that in's mic is
completely fine and everything she says is totally Audible uh but unfortunately the questions might not be tooo clear
and of course before we get started a bit of a formal introduction to Dr hippoo Dr Ino is an assistant professor
at marur University specializing in cognitive science and philosophy of mind and AI prior to this role she served as
a lecturer at the Berlin School of mind and brain uh she employs e cognitive
science complex systems and the free energy principle to investigate the dynamic relationship between human
cognition and artificial intelligence furthermore Dr hippoo is also the
co-founder of the international Society of the philosophy of the Sciences of the mind and serves as the AI ethics advisor
architect for versus a cognitive Computing company having said that without further Ado here's my
conversation with Dr iness hippolito so iness thank you for being here and thank you for your time I really do appreciate
it um despite having a lot of AI researchers and philosophers of AI on
the podcast I haven't asked them this rather Elementary question uh why is it
that phenomenology and let's say the work of mar small py for instance a befitting discipline for AI
research yes right uh so that's quite a core question and I'm glad that we're starting right there um
phenomenology is is incredibly important for us to think about artificial
intelligence in many ways and uh in many way ways I think that we should bring it
to the foreground if we really want to achieve anything close to uh uh
artificial intelligence um so the reason that is so valuable is that that may be so its
scope of study may be very well what is going to be the element that is going to
differentiate uh let's call it natural intelligence and um artificial
intelligence while I can see that there can be some continuity between the two
done properly um one of the conditions for that to be done properly is actually
phenomenology if that makes sense because phenomenology is uh the study of
um perceptual experience subjective experience in general and is a whole
very wellestablished field um that looks into um the
experience of being alive uh for uh individuals like us and in that sense um
it brings to the foreground that intelligence cognition our psychological
experience is not uh quite reducible to computational processes so then in that
sense uh it's going to bring the whole experiential Dimension is going to bring the whole human natural experience that
is so relevant and important to uh cognition or to psychology uh or to
cognitive life and intelligence in general so in that sense one could think
that if we were to um aim towards
artificial intelligence to through the very lenses of the very early beginnings
of the goals of artificial intelligence which is to create create these systems
that are somewhere somehow close to being intelligent like us then we need
to pay attention to phenomenology yes well it's quite interesting because uh and correct me if
I'm wrong here but let's say in the kind of the history of 20th century philosophy phenomenology really came
from from like the so-called cinal philosophy or the or Europe for instance right with thinkers like hia Edmond H
and of course person I I believe your your favorite Mar ponti and then Simon
De baba um but my question would be you have this uh you laid down this critique
in uh your paper which is the one you published uh an alternative an alternative Cog cognitivism
computational phenomenology for deep learning um and in that paper you kind of critique the current let's call it
the cognitivist uh or the computational theory of mind kind of framework work of
understanding human cognition um so if you could lay down what that critique
was just for a general audience of cognitivism but also then why do you
propose uh computational phenomenology as an alternative framework uh to for
for future AI research yeah so that's quite um in the same line of what I was
just saying so the the the the purpose in that paper to begin from the
understanding of phenomenology is a an established field uh that is valuable to
understand um cognitive life in general right and uh when you depart from that
perspective you are departing from a very different perspective when where
when you depart from the computational theory of mind and there's a whole history of um computational theory of
mind where we find a very reach literature uh where you have different
approaches uh beginning with um the more um the more uh um let's say
computationalist one uh that uh starts with Jerry Fodor the modularity of the
mind and then all of the re revisions that that approach has been receiving um
in then you move on to uh parallel distributed processing uh uh inspired
kind of like theories of competitional theory of mind uh which uh is uh
cognitivism or connectionism and the thought in that paper was um to kind of
like raise up the question which is not a question that is uh it's it's new um
other people's other people like Tim vanhelder is very well known for his work in
dynamical systems as Ro as as Rose the same kind of question which is what is
the require M of um uh uh borrowing certain Concepts from the toolkit of
these other more computationalist view such as uh the view that is developed within um uh modularity of the Mind such
as Notions like uh representation for example what does what what purpose Tim
velder asks and we also ask in this paper what purpose does really the notion of representation is going to
serve um if any uh in um in that framework to understand the mind so we
follow that um and get inspiration on that a little bit we are on board with that question really do not see a reason
to keep that cognitivist uh view um to think about uh these uh Network systems
that would require an explanation that includes the notion of representation so that's kind of like where we are in the
paper and then is we think about and we are are inspired by these questions
right then we we need to think about the ways in which we develop machine Learning Systems right so the question
then became if we are training machine Learning Systems to to do tasks such as
perception then perhaps a better uh way of thinking about uh perception would be
rather than taking perception as the old school computation IST uh view takes it
uh as a recognition of inputs and outputs very computational in character
then perhaps uh we should um take perception as the phenomenon of
perception right and by phenomenon of perception here I mean going to the
phenomenology of perception and taking perception as a phenomenon that is
characterized with all of those phenomenal aspects to it rather than a
computational process of a recognition of inputs and outputs with um with a
with a with some form of uh in computational information processing
right so once we did that exercise and we were like okay if we want the machine learning to behave like us after all
that was the whole initial goal of artificial intelligence was precisely
can we build systems that are are similar to some kind to us um then if we
really are after building those systems that can perceive recognize things in
the world in ways that we do then perhaps we should take uh one of the
most established um approaches and theories to understand uh precisely uh
how we perceive the world if that makes sense totally uh well this probably you
know is a good segue to have deeply philosophical question from let's let's call it
scientific realism H so would a uh computational phenomenology
phenomenologist framework be a non-scientific realist framework would it would it view the world uh in terms
of scientific realism oh perhaps for the for the listeners you could Define what scientific realism is and then try to uh
how how would a a through this framework through the compology framework how would you view sign realism whether is
it are you for it or are you against it if I could put it in a crude way yeah so scientific realism is a an incredibly
it's got an incredibly Rich literature in philosophy of science I find it extremely important uh for anyone that
is a scientist uh to uh get educated on that and and and really take a stance
and think about what what their understanding of scientific practice is
uh because um however you answer or whatever you are going to situate
yourself on that debate is going to be quite uh informing of the kind of like
science that you practice um so scientific realism um to
to put it in in a nutshell uh which is probably not fair um to the debate
because it's extremely vast and reach um yes but to put it in a nutshell uh you
have on the one hand you have scientific realism let's put it like in one side of
like the range and then you have on the other side let's call it instrumentalism then you have many different um you got
many different uh approaches that are uh quite uh quite established um and
appealing um and robust so uh but talk about these two edges you've got
scientific realism and it departs from uh somewhat uh Plato's uh philosophy
which is this view that there are certain ideals in the world and the the
job of a scientist is to uh go out to the world and find those ideals so um
science is a process of discovery of what is out there uh in the world such
that then what we would have is what we our what our scientific practice is
going to be uh an output of it is going to be some kind of like model that
somehow is going to be isomorphic to the thing in the world that has been
discovered there's some form of isomorphism and here there's a a vast uh
number of approaches that that have been developed um that really need to be uh
really carefully understood and um I probably will not Venture there right here because there will be another other
episode um so then you have on the other side on the very other side you have um
instrumentalism and instrumentalism is is slightly more of a constructivist approach and in this constructivist
approach in its more radical form of course there are this is a range more radical form what you have is um The
View that there aren't really ideals like PL Plato would have it aren't
really ideals in the world um what there is is these real world um uh objects
that exist and then the scientific practice itself is going to be to begin
with first looking at the world and by looking at the natural world we would
see uh because we are reasoning um beings uh we have the capacity to
identify patterns in the behavior how uh
the natural world behaves and changes Etc we are able to identify patterns and
the job of science is to make those patterns intelligible such that if I
would not engage and develop scientific experiments and and critical thinking we
would not gain epistemic uh uh reach on
those patterns they would still exist the objects and the behavior it's still there those are real things that exist
in the world it's just that engaging in the scientific practice is uh kind of
like allowing us to bring up this um this kind of like
intelligibility uh because we see those patterns this intelligibility that we would not have if we were not engaging
in scientific practice these are the two options uh but then there's of course a whole range of very rich literature
indeed so but then from from the two options uh how would a computational
phenomenologist which side would they let's say side with or sway more
toward right um so then um so then that would depend on what kind of like flopy
of mind you would bring in right so the philosophy of science scientific realism is not going to answer that question in
itself because then you have to also bring in a kind of like a FY of Mind
framework right so let's say that we were going to put aside the
computational theory of mind right so let's say that we put aside the computational theory of mind and we want
to understand and develop um artificial intelligent
systems uh with our computational phenomenology right so that's what we
want to do so that is uh in my perspective a very compelling project to
pursue for several reasons stated before all one of the reasons is that if
you do want to uh attain the early goal of artificial intelligence which is that
these systems are as close as possible to us then uh computational
phenomenology is the best bet I'm not saying that it's going to be possible but I'm saying that this is the one that
I find that it's most uh most um appealing to get to that why well
because one very important aspect of our cognition and what is um part of our of
our defining us as human natural intelligent systems is that we have that
the ways in which we interact with the world for a certain purpose that is can be described within the phenomenology of
the ways in which we do things that are meaningful to us and how things in the environment become meaningful to us
given our experience so phenomenology is going to be very relevant to precisely get us anywhere close if we even have a
shot to get like some artificial intelligence to be closer to our natural
intelligence um so in that sense um the model so now I'm going to now that I've
defined the philosophy of Mind framework that I'm bringing in now I'm going to move on to the philosophy of science uh
framework that I think is going to be uh the correct way of looking at uh the
competitional models that we develop um I think that the competitional models
that we are going going to develop they are what they are they are computational models right so what they are is they
are these useful tools that are incredibly sophisticated and they do not come out
of nowhere they are um the they emerge from incredibly uh
sophisticated uh intelligence and resources that we have as a
technoscientific community been developing as part of the incredible capacity that human civilization has um
so then these are tools that we develop what I mean by this is that these
computational models are things that exist in the world um in a way that it's
not independent from our own doings our own
um our own practices that are incredibly highly situated in Social cultural
communities of epistemic communities right so these are our own doings and I
think that this is relevant because it's moving us away from scientific realism
in the sense that I'm thinking about these computational models uh for example those that use machine learning
um is tools that we develop right so in that sense what we
have is we have um these computational models or even artificial intelligence
systems that are a product of uh our technoscientific
development and those are tools um they're not much more than that and then
what we can do with them is we can ask them to do things for us for example we
can develop a system that uh whose job is to recognize patterns right and these
patterns can be like a a task of image recognition identifying categorizing uh
all of those kinds of things that we can ask a machine Learning System to do but it can also be the case of uh these
large language models for example what would they do they do exactly that the recognition of patterns so exactly so
then what happens is that what you have is uh an explanation here that you hold
on the one hand you are holding a a quite clear philosophy of Mind Theory
and framework which is like what why am I holding this one and living and setting aside the other ones well because I think that this one is the one
that best describes our human uh Way of perceiving the World our human cognition
our psychological life and the ways in which we are conscious being beings navigating a complex world that's why
I'm holding this philosophy of Mind framework and setting aside the computational theory of mind so that's
just aight for me um and then I'm bringing in um philosophy of science
framework that um I think uh has got sufficient reasons uh that is going to
be useful because what I'm saying is that in our own doings as we are
epistemic communities uh and engaging in technoscientific practices developing
all of these AI systems right we develop these tools that are part of our
practices and those tools are going to allow us to do certain things in the
world right but those are not more than tools these are tools that are completely emerging from our soci social
culturally situated practices is techno scientists perfect perfect uh in fact uh
in as this perhaps lay the groundwork for a bit more of the technical questions because one one thing you
beautifully outlined in the paper was uh firstly you you described what this uh
representationalist framework which I believe is inspired by uh cognitivism is
currently it's through that framework a lot of contemporary uh AI researchers that work on their models they they
build their tools but then of course in the in the paper uh what you propose is a non-representationalist framework so
and that was for me a key takeaway from the paper could you firstly um perhaps outline what the current contemporary uh
representational framework is and how it's being used by AI researchers and then what you propose in the paper which
is nonrepresentational as framework uh and hopefully for a lay person to understand how these two differ and give
us different grounds to work work off absolutely thank you so much for asking me that um yes so basically uh now we
can now now they that we have laid out like the kind of like theoretical Frameworks that we're working with that allows us to go a little bit like more
zooming in and focusing on on the representation bit and why I do not think that we need it right so the point
is I don't think that we need it I don't think it's necessary and I think it causes more
confusion beyond the fact that it's wrong so why is it wrong um if one would
look uh into uh defining what a representation is I would um I would agree with many
scholars that defend that uh a representation
requires um requires many other things but I'm just going to focus on one for the sake of of of time and making the
point here um a representation requires a fully
embodied uh symbolically inculturated being to be able to make a
representation communicate Itor understanding it right so then the
idea here is that a representation requires someone like us so it requires
that we not only have those capabilities but that we've been
inculturated and skilled into symbolic uh structures like numbers
languages uh any kind of like symbolic thinking that allows us to understand
that something represents something else and that not only our understanding of
that of something as as representing something to us as being meaningful to us in a certain way but also
communicating requires some kind of like symbolic structures that you need to engage it like the language that I'm
speaking right now uh if you would not share a common language I would not be able to communicate all of these ideas
to you so that's a requirement so some part of our in in our developmental lives we have been inculturated with a
with with a symbolic code that allows us to have this conversation right here right now right so when I think about
representation there is a set of criteria that needs to be there and this has actually been very well uh outlined
by and the defined by U by Frankie uh Egan um on the conditions for uh
representation to be the case right but I'm going to focus on on the one that is
it requires symbolic inculturation and that means it requires that we understand semantics we understand
meanings of things right so that being the case note how it requires that human
beings are situated in a social cultural environment and throughout life it's not something that you just like are born
with but throughout time you develop and become ever more and more and more skilled almost like like riding a bike
in the sense that the more you ride the bike the better and more skilled you become in riding a bike um so the
inculturation with symbolic structures is quite can be said to be quite similar in that sense so then imagine this I'm
saying that it is possible for us to communicate because we share and exchange these forms of representations
of how we understand Concepts in the world and we can use them um uh uh properly now why would we need um to
think about um that's why I wanted to make the point that I just think uh including the notion of representation
in networks of nodes um that are computational processes is just going to
be unnecessary it's just not necessary to have it there um because there have been some
arguments to say that well it's useful to have it there I don't think it's useful to have it there and I think it's wrong so wrong why because these systems
have not been inculturated with engaging in the world and understanding semantics
in the ways that we do because these are computational systems and I'm going to describe the kind of they are they are
in a moment but they're not that they are not human beings like us that have gone through these like this really
really you know um uh developmental um enculturation that we have so they do
not understand semantics right so because of that it would be wrong to say that node a represents what node B is
saying they'll be wrong some people might some people have argued that it is useful nevertheless right I think it's
not useful because we are anthropomorphizing a network right so
that's not useful and that's wrong right so I'm going to now give an example of what I mean uh in um large language
models right so that everybody is now perfect example ex because everybody now is acquainted with large language models
like Char GPT and I want to talk about that and and this is a perfect to give that the example of what I mean and the
dangers of anthropomorphizing because it may be the case that until we had this new technology that is large language
models that we were just playing around with philosophy of mind and doing all of these things like anthropomorphizing these uh networks these computational
networks and we would think like oh there's no danger in that that's useful and I'm going to tell you why it is
danger Dangerous and and how that came becomes very clear in the light of large
language models that we didn't have before right so large language model uh the way that I see it is a perfect
illustration of uh John Soul's Chinese room right why is that because uh it
performs things it looks like it's intelligent it looks like it understands
semantics it gets the job done right um in a way that looks like it's something
uh intelligent um and understand semantics but it doesn't because what happens in large anguage models is that
we have uh these incredibly sophisticated predictive models right
and I'm working on a paper um that hopefully is going to be out soon where we talk about um and we Define and
describe large language models as uh not being calculators for uh as being sorry
as being calculator calculators for words what does this mean this means that there are real dangers when we
interact with uh large language models because one goes to interact with it uh
thinking that uh when I'm interacting with a large language model that it's going to give me something that is
factual and that's just not what is happening right so the whatever it is
that it is the output the content that the content that is uh an output of large language model is not a fact but
we take it as it being a nor knowledge fact right but it's not what's happening
is that we have these highly sophisticated predictive models that are going to predict uh tokens so they're
going to predict um in the past so until 2021 depending on which version we have
until 2021 um these tokens have been the ones
that have come together with these other tokens Within These blanket of events or
topic that we are talking about right so what they going to do is going to tell us really uh How likely uh certain
Concepts and words and thoughts have been put together right so that's what it's going to give us and that is on the
basis of a monolith of data that we have that is sitting in the past so it's not
Dynamic whatsoever it's not um it's not it's not nonlinear it's just sitting there and what it's going to give us is
and and I think that this is the most important point that we need to understand is that if we are using Char
GPT or any other large language model to generate knowledge for us it is not
going to be able to give us anything that is interesting in the future because what it's going to do is just
giving us an organization of how things that are usually coming together with
other things in 2021 right so it might even take us back
um in all progresses that we may have done as a scientific Community uh and as
a social cultural Community when it comes uh down to social cultural values
and progresses that we may have made as communities and societies so it's incredibly uh danger in that sense and
now I'm going to say I'm going to go back to wrap it up with um with the point that I was making why is it
dangerous that we think or say or articulate that in a nodes Network like
like a l like like a machine learning networks that we use right why is it dangerous to say that node a represents
U uh no what node B knows or information from node b in a very simple way of
course um what does it mean it means that we are anthropomorphizing and and and working under the assumption that
not a understands semantics and that is not the case is exactly as it's not the
case in large language models because they do not large language models do not understand semantics they don't
understand what is going on that's why they cannot give you facts is because they do not have an understanding of semantics they do understand syntax but
they don't understand and semantics so that is what comes that is the danger
that comes with us anthropomorphizing and thinking that what that they understand what they're doing but they
have absolutely no clue what they're doing so large language models kind of like come as like the perfect example of
why we should refrain from um using the notion of
representation in any machine learning context or in any uh uh computational
model that we develop there is no need and the fact and it's not even that it's not needed it's going to be uh uh
problematic in the sense of the ways in which we now look at large language models and what they can do for us
indeed so and just to clarify I'm assuming you're saying or you're theorizing that if what you propose
which is the non-representationalist framework are you are you are you claiming that if we use such
framework uh an AI agent or AI model made from such a framework would
understand semantics no interesting so so in the sense that are you saying
right now we haven't got any proper framework to understand uh to build an agent that can understand semantics
absolutely we do not have Okay I'm glad that you clarified that exactly so now let's bring in the philosophy of Mind
framework that I'm working with that I selected right so let's bring that one in what would be the requirement that's
why phenomenology is going to be really important and E cognitive science is going to be really important we're going to go there for sure exactly so now
let's think about what would be the requirement for an artificial system
right uh to be able to understand semantics I have no
idea right so what would be from this framewor I can speculate perhaps being in the world being in the world doarian
term absolutely being in the world right so doing what doing the things that we've been doing which is like from
birth uh being situated in a social cultural environment right that has meanings that has values vales embedded
in it being part of these cultural practices being part and contributing to these cultural narratives being
inculturated with these symbolic structures sometimes people uh turn to me and they say well if all it takes is
that uh an artificial system is embodied and embedded uh in an environment for it to be considered intelligent somehow
closer to the ways in which human beings are intelligent then we can think about for example and they ask me do you think
that this would be enough that we would have for example a humanoid robot that is equipped with any sort of like large
language model right because now we have embodied and we have embeddedness right and I'm like that's not it yet right so
we need to go back to what phenomenology says but we need to go back to what eogn cognition uh says that are the defining
properties of cognition right so if you begin from the point of view that uh to
use uh to use a uh IAS um IA notion of
being thrown in the world thress which is a very very wonderful concept you're
thrown in the world and then you have to you don't have a choice you have to immediately start acting upon the world
and immediately being situated and embedded in a very strong embodiment sense not in a weak sense uh with that
environment and already participating and being part of a certain specific social cultural environment right so
that's what we are talking about that's the level that's the scale that we are talking about right so if you bring this
theory of this kind of like philosophy of Mind approach as I am bringing so then those would be um very specific
foundational requirements for any intellig artificial intelligence system
to be anywhere close to uh being able to have some level of sness or or or
intelligence like like we have because you need all of that interaction with
the environment not only on the phenomenological level but also on the representational level right you need
that interaction with the environment such that you are inculturated with this symbolic structure such that you
understand the use of Concepts in the ways in which you interact with the world and here use I'm really taking
that notion in terms of the viin steinan sense of the use of linguistic practices
as embedded in cultural practices so would this be like the language games AB talks about absolutely yeah okay iness
uh because I'm cognizant of the time I have a lot more to ask about the CP framework but perhaps we'll we'll post
we'll put that on the backround for now because I want to get to the other bit which is uh exciting ecognition and body
cognition um now uh I'll I'll ask the question in a bit of a bipar tied manner
firstly again if you could just outline what is Eco nition I know you've done this in many other podcasts before but
apologies for having to repeat yourself but just so that the audience is oriented and attuned to what we're talking about and then to if we could
make a sudden leap after you outline ecognition uh what's its relationship
philosophically speaking of course to the uh free energy principle right a lot I know it's a lot
I know it's a lot but if it's okay I just want to you know let you like play around with these Concepts and bring them together yes and I'm very happy to
do to to be asked to nerd about it because uh yeah that's uh that makes me
really happy so uh Happy excellent excellent I'm GL right so um it is not
an easy task to understand ecognition and I think that we need to be standing on a humble perspective to to precisely
do that um because it is of course uh grounded in in quite a few well
established approaches there are not new approaches they have Roots they have historical
Roots uh in philosophy of mind that does not reduce to Western analytic
philosophy of mind right so that's why it is important first step to be humble
about understanding the framework um and then understand that it each frame each
each approach is rich in itself got got strong roots and although there is there
there are common um common uh uh uh um claims across the board within the E
cognition approaches are there are specific focuses that each framework
brings and the focuses the focus that each framework brings is determined by
um the kind of or the or the level or scale uh that the framework is most
developed upon right so that's just sort of like a sort of like a prefacing um
framework so basically we have um we can think about e cognitive science again in
a range and I like that because uh uh uh that gives us a spectrum which is always
I think uh a very uh safe step uh to take rather than binary approaches so we
can think of um a distribution of e cognitive science approaches within a
range and how are they distributed they are distributed muted again it's like
all roads in philosophy of mind will take us to representation or at least let me just
rephrase that and correct it for all roads in Western analytic philosophy of M will take us to the notion of
representation and E cognitive science uh is no exception so what we have is um
the ways in which I find it more um intuitive to understand how they connect
to each other and how they connect as well to the other more tradition
analytical philosophy of mind which is more computational in character is uh by virtue of how they understand um and how
far they go in being radical according to the notion of representation so let's say that just
for the sake of like um of mapping the literature let's say that computational theory of mind which is also a very rich
uh literature um let's say that uh that literature is going to tell us that the
mark of the mentor is mental representation let's say that um
competitional theory of mind is going to tell us that um cognitive life is
reducible ontologically reducible not even just explanatory reducible but
ontologically reducible to mental representation which means that every
component and all the activities that we engage with uh in our cognitive life can
be explained to the form of a person having a belief and acting upon that
belief and updating that belief right so and then there's different um
computational theory of Mind approaches that are going to um uh uh uh sort of like build uh a theory about how these
beliefs come to be and how these beliefs come to be updated so that's in a nutshell computational theory of mind
and I'm so sorry to those that Endor compation your mind that I'm not doing a a super uh Fair yeah but but in the
interest of time so then this allows me now to map e cognition in according to
uh the more traditional computational theory of Mind analytic philosophy of mind so uh then you can think of
ecognition as a range of different approaches that you can ask how radical
are they or how much do they still endorse or borrow or need or leverage
from the notion of representation which is the core aspect of computational theory of mind right right so then you
can ask that and then you have different ones so now I'm going to just list them so we've got embeddedness we've got
embodied or embodiment we've got extended we've got inactive and there's
a few more like ecological and emotive but in the interest of time I'm going to
talk about four and I'm going to locate cognitive science model right absolutely soqu known let's say precisely so the E
comes from the fact that uh all these approaches with an E so then we have e
cognitive science um and then um so then we have let's say that here you have
computational theory of mind and then let's say that here you have the range of e cognitive science right so then we
can start locating them by how much do they need to use and find usefulness in
the concept of representation as being quite Central right so then we can say
that uh embeddedness would be the one that sits closer to um the computational
theory of mind because what it what is meant in that approach is that uh cognition cognitive life takes place in
a in an embedded way so the system the living being is situated in an
environment right so that's that's that's um there is a position that most
people endorse so that's not that's not controversial this sits very close to uh computational
theory of mind and then let's say that you have as the next one next stop is extended mind so the extended mind uh
developed by um by uh Clark and Charmers um what it says is that uh we
kind of like um uh integrate incorporate tools uh as part of our cognitive life
right and that is quite appealing uh and I think it was uh it was really good to have uh that um that uh thought and that
theory coming in 98 uh because it really came to ask
certain very important questions and uh kind of like revolutionize a little bit
the old school computational theory of mind right so in that particular case
why am I locating uh extended uh mind very close to the computational theory
of Mind well it's because even in its most radical form and uh this is quite
clear from um a paper from Andy Clark from 2015 which is a paper entitled um
radical predictive processing it is quite clear in that paper um that um
representation is still taking a main core in this extended mind right so what
we have is we have a system that is comprised by brain body and the object
that is in the environment right now this could be very well it could be seen
as being quite radical uh e cognitive science why is it not so it is not
because uh the ways in which you explain this system is that uh it is a
computational process throughout so that's why it is a computational theory of Mind still um so it is true that it
brings in the notion of the body to play a causal role in cognition as opposed to
many other theories that reduce cognition to the brain um so it is true that brings the body to play a
fundamental role in uh in cognition as well as something that is in the world
like a like a technological device do also play a causal role in cognition so that was quite revolutionary at the time
um the the the what makes it a computational theory of mind uh is an
and close to the computational the mind in this range that I've just established is that this whole process between the
brain the body and the tool is as explained by any Clark is of the computational kind meaning just to
clarify that would mean that it's something that could run on a touring machine it's it's a computational
process exactly so basically we are explaining here uh cognitive uh aspects
of Life cognitive life cognitive processes is being of the computational kind that process information so very
analogous to the to a machine and what what kind of machine a predictive
machine predictive machine that's it right so then what we have is it is a distributed system rather than saying
that cognition reduces to the brain which there are certain accounts that to that um this is also
a computational process except that it is distributed so that's what makes uh
extended mind sitting quite close to the computational theory of mind and that's no secet
and the ways in which uh Andy Clark understands the body is in no way uh the
ways in which uh mopon understands the body or embodiment in E cognitive
science understands the body because let's say that mopon and embodiment which I'm going to talk in a second take
a strong embodiment approach whereas Andy Clark when he talks about embodiment in and he does embodiment is
quite a fundamental concept within the extended mind um and and even within
radical productive processing but it is really important to understand that the embodiment that and clar is talking
about is not M embodiment because the embody the embodiment is the body plays
a crucial role in this computational predictive process so that's why uh I
would locate Extended mind close to uh computational theory of Mind approaches
and then let's move on into the ones that are actually now starting to question the notion of representation as
being Central as being the mark of the mental and questioning that uh cognition
comes down to a computational process that is analogous to computational process of any kind those that actually
question that and reject that we start having um embodied cognitive science so
embodiment as it is uh rooted in um in peace uh in mopon in the whole
phenomenology tradition so that's embodied science and we have uh extraordinary work on that um today in
for example by Sean Gallagher um who I would say that um because of um his most
recent approaches as well as his most recent books I would call uh that kind of approach the uh embodied in
activism so the there's there's that one which is very much rooted in phenomenology so then the focus on um
embodied cognitive science is going to be on the body and how the body is grounding of the experience so the body
is not in the service of the brain as Andy Clark would have it the body is in
the service of my cognitive experience so of the whole um agent
right so the body is what grounds the experience of the agent so that's embodied cognitive science in a nutshell
then we move on into um in activism and in an activism we find uh we can say
three different approaches because I'm going to include um a bit of work um
from Sean Gallagher in this embodied or in this embodied in activism right so
which which is uh quite interesting which is the the the situatedness of the body or the core aspect of the body as
well as the body being situated in the environment and then we have um another
form of in activism which is potentially the first one uh which is the one that
uh began with Matana and verella it's very much coming from biology um U Back
in the '90s ' 80s um and in there there are specific Concepts that are really
interesting and relevant uh to understand cognition that they bring in um at a time and I think they are very
much relevant still today uh which is the notion of aasis and which is kind of
like the notion of self-organization and how they really connect all of these like systems systems biology approach to
explain uh cognition in ways in ways that is completely antagonic to
computational theory of mind so they bring in like systems biology to explain cognition um uh in the sense of uh
living beings uh as uh being multiscale uh uh living beings that are both
operationally closed and thermodynamically open and living in this state of precariousness so this
quite interesting uh literature that then has been um been connected uh by the hands of um of Evan Thompson and um
mostly Evan Thompson has been uh making connections with the Buddhist philosophy which is extremely interesting and
engaging um as well as uh the work by the Pao Ezekiel the Pao and anad Diaga
who have been like um having this extraordinary uh work on bringing out uh
certain aspects that I find extremely appealing which is how um cognition does
not come down to representation because even when we are engaging in languaging
even when we are engaging in conversations with other people it is not just a matter of us using
representational structures uh such as language but there's so much more there
is involved in a conversational and in in an interaction that does not come down to those representational
structures or symbolic structures like language which is why uh they have the book uh linguistic bodies so we are
linguistic bodies rather than uh being like these computational machines that utter believes uh in a form of a
computational uh processes so that's rejected right so that's why I'm now getting away in in my range I'm kind of
like getting away from the computational theory of mine and then uh let me say let me just say the last one which is uh
radical um in activism exactly so that's U through the hands of um of uh Daniel
Hutto and Eric mean and uh in there um the the view is uh is more radical to
the sense that um they uh question uh and they ask uh a fundamental I think
question which is where does content come from and why is content relevant is because content is what is going to
allow us to then eventually engage in these social cultural practices that have some form of semantic meaning right
so then in the in the grand scheme of uh of cognition and cognitive development
then the question is uh is about how does content come to be that allows us
to engage in these semantic pract in in these cultural practices that also have a semantic content and how can we
explain that that content being shaped uh and shaping our uh individual uh
experiences so and and how that and how that shaping and being shaped by is
highly social culturally situated so that would be far out in the range that makes sense yeah that's the
that would be the map and those are the four e right we could also add uh the ecological psychology one which is a
whole field in itself as well and quite prominent and vastly CH perfect perfect
so inis um and now I'm going to try to outline this here but forgive me if I in
fact correct me if I do make any mistake so I'm trying to see how we can leap from ecognition or how we can step
towards this idea of the free energy principle that's inspired a lot of lot of you know researchers in Ai and all
the Neuroscience to a variety of fields which obviously was introduced by KL friston um so my understanding my very
lay person's understanding is that we have this as you mentioned we have the system it could be a body well most
likely a body and then the free energy principle it tries to reduce free energy
a system tries to reduce free energy in the world and free energy is to put it colloquially it's uncertainty we want to
reduce uncertainty and then uh there's this thing called The Mark of blanket which is a
statistical it's a statistical let's say mechanism but the mark of blanket for let's say all intents and purposes is
the the boundary between the world outside and then our system so what I'm trying to understand is from let's say
an eoy lens how do we how how do we make sense of the free energy principle and
then the more applicative sides of with active inference for instance right so thank you so much for that remember when
I was um earlier on I was describing uh my understanding of a computational
model and I said that we we in our most sophisticated uh science technos
scientific practices what we do is we develop computational models and why would we want to do that well we want to
do that because we want to understand the natural world around us right and again why would we specifically have to
develop these computational models well it's because the phenomenon that we want
to understand is highly complex what does that mean that means that I cannot set up an experimental Paradigm that
would allow me to study that because there's high levels of complexity like let's let's think that we want to um
understand and ideally predict uh feature States off a black
hole so one thing I cannot do that is not available to me that is not afforded to me um is I cannot set up an
experiment indeed in fact something even let's say like the stock market has never been anyone who's who's been able
to predict the stock market why is that because of the high levels of complexity of unpredictability of high levels of
uncertainty right so then our best chance is to develop this very
sophisticated um model right so there's got to be some touch
points between the models that we develop and the world that we are trying to understand and note that I'm not
saying mirror note that I'm I do not I'm not thinking about this computational model as something that is going to give
me a a mirror to a phenomenon it is a tool that is going to allow me to
generate some epistemic virtue some some understanding of something that I didn't have before by by virtue of what of
finding some uh reasonable way of understanding the patterns of behavior
right so we look at what we have as patterns of behavior and then by that hopefully we generate some understanding
and ideally we would gain some predict predictability or predictive power right
so that's what we want to do with a computational model and that's the way in which I see a computational model so
you can use and develop a computational model within active inference and with active inference but you can also do
that with many other techniques right whether or not active inference is going to be the best one is up to debate
right I tend to think that it is a very good one to understand cognition because
of certain features that active inference and the free energy principle bring to the table as a conceptual tool
kit as a mathematical toolkit that I find useful and I find that uh is going
to be specifically useful if you endorse um an e cognitive science perspective of
uh psychological life of cognitive life right so but this is again it's really
important to understand that this is a tool it's a model that we are going to
develop in order to um understand the phenomenon which is going to have
limitations I'm not I I would not say that this model is going to allow us to understand the phenomenology of
experience because that's not what the model is supposed to do um allows us some understanding of uh
behavior um of cognitive behavior of living beings and allows us hopefully uh
some predictability on the future states that we may find th that living being or
those living beings given the patterns of behavior that we know perfect perfect okay on the note and it's a bit of a
highly let's call it a highly speculative question because I've been thinking if you could imagine what would
an AI model built through this toolkit you you put forward which is the firstly
the a e cognition and then the active inference and then the broader free free
energy principle so what would an AI agent or model built with that toolkit how would that differ to like let's say
using deep learning something like a shat GPT or an llm how can we if we can
imagine an AI agent coming from that line of thinking or let's say that world
what would it look like excellent question very happy to answer that one um so it would look like something quite
different so when we were talking about large language models being um whatever
output they give you it's an output that is not factual is it's an output that is not intelligent it's an output that is
coming from the monolith uh databases that it has access to and it's
not extrapolating in the future it's not making decisions for the future even though it looks like again Chinese room
it looks like it is but it's not giving you facts it doesn't understand what it's doing and it's not giving you new
opportunities or creative uh U or creative Pathways towards the future so
those are the limitations that uh large language models have um that's why they
are called stochastic parrots yes I love that term exactly so that's why they call stochastic parrots these is these
are the the the the limitations that they have and uh even recently the open
AI CEO or CTO um in an inter you uh
quite rightly so said for us to make any progress from here we need another breakthrough because this is it right
this is it uh of course we can develop many many many apps on the basis of the large language models and we can do lots
of creative things that and that can help us um do our most festigious uh
tasks work tasks in in different ways and of course it's having a profound impact in all levels and scales of
society including the universities uh so all of the places where we generate knowledge as well as any other societal
domains um which makes it even more important for us to understand why these systems are stochastic parrots and why
we need to be careful about about it so uh that being said uh what would uh
large language model so that we have a a case that we can um use um look like
under an active inference uh framework which is something that we're actually working on um so that would look like a
distributed system of intelligence right what what this means is that um it's
important to maybe just first I would just um say something about active inference and free energy principle um
is it has been developed uh in the last few years uh to understand uh cognition
and the brain so the ways in which coming from where I'm coming from which is the E cognitive science understanding
of cognitive life um active inference as a model to understand that um is
relevant and interesting because it's um it gives you a coupling between a system
and its environment so it gives you a situatedness right so where there is
some level of uh operational closure right by the mark of blanket that you
mentioned but the system must if the system wants to remain alive and
typically they do um stressing that typically uh there are uh there are
exceptions which are very interesting to study um so if the system wants to
remain alive it has to be permanently open in in exchanging energy and matter
with the environment that's how it remains alive so that is the subtlety that is quite important and relevant
that that this framework brings in the table is that it tells you something that might look like a contradiction
which is how is it possible that the system is both operationally closed and
thermodynamically open right so once you do that that's not only uh quite
compatible with what an activist say right um and it's completely from this
perspective would be completely rejecting The View that uh cognition is encapsulated in the brain and the brain
is separated from the environment therefore it needs to infer quite literally what is happening in the
environment so from these perspective I'm rejecting uh computational theory of mind and saying that well that's not the
case actually because you need to be uh thermodynamically open constantly exchanging matter and energy with the
environment and interestingly I'm not talking here only on the agent level I'm
talking about all levels of life so a cell must be situated in a Cell tissue
such that it is operationally closed it's got boundaries right um and it must
be uh thermodynamically open such that it's always uh exchanging matter and
energy with its environments if it wants to remain alive right so that is quite
uh interesting um and relevant so once you understand uh cognition like that
you understand cognition as systems that are um permanently coupled with the environment and when they're not they
are dead because they become closed systems not open systems so that is all
coming from systems uh neuroscience and it's quite uh I think it's quite a good uh a good complement uh from a technical
computationally technical perspective it's a good complement to uh the more uh theoretical development that we do
within e cognitive science or in activism so that's that now applying all
of that knowledge that we've been working on within cognitive science to artificial intelligence things are going
to look quite different to when you come from a computational perspective right
because when you come from a computational perspective you may be happy to Define uh that a humanoid robot
that is equipped with a large language model is going to be sentient is going to be intelligent it's going to be a
cognitive system you might end up to those conclusions right it's easy to to make those steps uh when you come from E
cognitive science that's that doesn't come for free it's not a commodity that A system that is just like behaving like
it is intelligent is intelligence so we will see in there a Chinese room situation right um so then uh on that
note uh what you would want to achieve and where you want to go in the future
is you want to have uh if you we are talk talking about like any form of
artificial intelligence that is anywhere in the realm of a natural intelligent system then what you want to have is you
want to have a system that is capable of adapting to high levels of surprise and
here I'm already introducing the free energy principle um adaptable to high levels of surprise right the can deal
with high levels of surprise um that can make decisions real time real world
decisions based on the understanding of the present State of Affairs and this is
very different to what a large language model can do because a large language model is going to give you what was the
likelihood of certain words or certain facts or certain things coming uh until
with according to what we've gotten our databases until a certain point in time
so it's going to give you what happened in the past and if you really want to
have a system that is anywhere close to what we are capable to do it needs to be
able to in the real world in the present time make decisions that are highly
sensitive to the context around them right um in the ways that it understands
um the State of Affairs and that's not a large language model yeah no totally I mean forgive me I'm I'm a bit of a
romantic just just thinking about the idea that how beautiful uh that is because the one other thing with the
llms or large language models is the immense computational power it takes to
run these models absolutely yeah I mean I don't know if you're familiar Scott arenson the American commuter scientist
he was he was he a I believe he's a he's like a consultant at open AI he was
saying recently that um open AI has been investing in Quantum Computing because
they're running out of resources to to on Fu these uh llm models because they
take that much energy and with all of that it can't even still live in the it
can't exist in the present conditions it's still living in the past whereas as humans we're totally different in the
sense that we don't need one one millionth of that kind of energy but
also we can live in the present world and as you laid out you know reduce uncertainty U whatever the case may be
um so I just find that a beautiful idea of describing what it means to be a human being um
excellent um all right you know since we are already on the kind of the speculative terrain here I think I want
to get to more of the interesting questions that I I don't know if you've been asked these questions before in podcast but uh I want to talk about
psychoanalysis um and just as a philosopher of AI you know and and as
someone with a deep understanding of the in the literature of the philosophy of mind what are your views in general just
intimations on psycho analysis and do you think there's anything uh we can
gain just at least philosophically interesting or perhaps later on even for more technical work uh from the field of
psychoanalysis from the let's say uh controversial field of psychoanalysis um right so typically uh
I am not very drawn to psycho analysis why is that um because I do not uh
really endorse the view of uh mental life or psychological life being
something that is hidden and needs to be kind of like retrieved idea like the
unconscious you mean yes exactly so I am not um very much um I don't really see
philosophical reasons to believe that um
the ways in which we have access or could have access to our mental life is
through in introspection so to to open that a little bit more and
make more relations to the literature I am here being very vien
steinan okay so vonstein tells us in the remarks on philosophical
psychology that our um psychological life is right there next to us uh
accessible to us like any other objects in the world we just really have to um
pay attent attention and notice that it is right there so it is a matter of
um finding the possibilities of
communicating that psychological life um and I'm really here I'm kind of like I'm
kind of like trying not to use Mental life because mental might give us the the notion that I want to avoid which is
something that is like quite intrinsic quite quite obscure uh and needs to be retried from from the depths of of of of
something um so our psychological life is something that is accessible to us uh
quite accessible is right there because that's what we are made of that's that's what we are is that psychological life
and what what kind of psychological life well it's the one would say and here it
connects a little bit with Sean Gallagher's work on the self as patterns right is the view that my psychological
life is uh the conjunction of all my past experiences together to together
with this particular moment in time where I'm having this interaction right so that is right here right now because
that's what I am right so it connects a little bit with the selfish patterns of experiences that one has had that
brought me here today right in front of you right so it's right here whatever it is that I'm saying whatever it is that
I'm doing is a result of precisely uh that psychological experiences that I've
been having so there's nothing hidden uh there is nothing that needs to be retrieved through introspection um if
there is anything hidden and this is the subtle very important point in in fit's remarks of FL of psychology if there's
anything that is hidden is hidden to other people fascinating if you could
elaborate on that that's fascinating here is where the B comes in so it refers to our psychological
life as if like each one of us had a box with a B inside
right okay and the I've I can see my B yeah yeah I I have total access to my B
of course the more and more you are intentionally wanting to you know get to know yourself who you are and in the
ways in you behave and you interact you can pay attention to see who you really are right um the more committed you are
with it of course the the the better you're going to have a grasp on your identity um what is hidden is uh that
you don't have access to another people to another person's bit okay that's what's hidden yeah right
and the only possibility that we have to have access to each other is through
language and that's through our language games which is where where it comes from there is no such thing as a private
language because we we co-construct we are co-responsible for the language games that we engage with and construct
together so the the mental or the psychological life is nothing that is really hidden it just needs to be said
through the language game it needs to be communicated but I am here with all that I'm made of that is my psychological
life that is right here accessible to me now we can engage in practices that are
going to allow us to have a much clearer grasp of uh what is Meaningful to us and
who we are and our individualities and identities right we can be we can take more control we can take more charge we
can be more intentional in in in in in clarifying that right for for ourselves
and uh one tool that allows us to do that is through language is the ways in which we are going to communicate those
um those aspects of us uh with other people right or even with us um by Ma by
by by means of using uh language games th those are our Best Bets to to to precisely do that interesting well what
if it play a bit of Devil's Advocate um let's say a person who's more of a defender of psychoanalysis would say in
some sense uh a psychoanalyst would be working with a a client or an an alisand
and they'd be on the like the therapy couch or whatever produced u i I don't think they use a couch anymore I'm not
sure I've never been with therapy before so uh and the idea is through language that trying to help the person build
more clarity into their subjectivity or being hood or whatever you may call it
um and would you still say that there's some value in this idea that yes the the
truth of who we are isn't deep down somewhere in the unconscious uh but
rather it's it's out there the truth is out there but still for us to for us to
make make this truth more meaningful we need some kind of and language perhaps is the best tool for this we need the
other we need another another agent another party to clarify that for us absolutely so
the the means by which it is done let's say that it's a talk therapy right talk
therapy um it's quite relevant and uh there would be uh one way in which that
helps us um notice uh the most relevant aspects that
are most defining of our identities right so it doesn't mean that we need to
go to therapy because we are struggling with the general mental health conditions such as anxiety depression or
PTSD or whatever right that's relevant and that's useful even for someone that is not struggling with any general
mental health condition because what we get is we get somebody that is helping us navigate and and and and look um and
identify the aspects that are most relevant as defining features of who we
are right so in a way it's important to have those elements in our life that are
going to bring us out of our habitual perspective and help us have a different
more outside more Forest kind of like perspective to look at ourselves and
identify the aspects that are meaningful to us and relevant in the definition of our identities and there are many ways
in which that can be done one of them is talk therapy but there are many other ways in which uh that can be done um in
this particular case we can sign with have it that a good therapy session is a session in which uh the the therapist
helps us um identify um aspects of the ways in which
we perceive uh the world that would otherwise go unnoticed that we don't see
that those are the meaningful aspects so in the tractus it says uh the limits of
my language are the limits of my world that's what it says in the tractatus and I think that we could say that in later
vinin in the remarks of philosopy of psychology is the limits of my o o of my
perspective on the world are the limits of my world what does this mean this means that you cannot see the world as
the world is you cannot you can only see the world as you are so then therapy is going to be about who am I let's find
those um aspects that are defining um that allow me to see the world in a
certain way that another person does not see in that way because the other person didn't have the kind of like
psychological experience that I've had until now right so it's identifying
those aspects that make a certain object uh being perceived by me with such and
such and such and such features rather than other and other other features that would be the features that would appear
to someone else perfect that makes a lot more sense yeah I mean I I think uh I I
certainly uh in many ways share your your critique especially why I I find a lot of uh lot of people get into like
Union depth psychology and I'm I find that quite problematic because it's it does again assume that there's like deep
this unconscious that only your therapists can realize about yourself but the way you outlined it it makes
more sense to me to yeah broaden your perspective let's say or to build Clarity into what you already know
through the medium of language excellent the other think uh uh in is and you I'm so glad you mentioned Simon DEA in a lot
of your public talks because I me know I in know way I'm I'm an expert on her work but most people it's like lay
people like like like myself we know of her as being perhaps the most important feminist philosopher of the 20th century
right but of course apart from being a great social and political theorist she
was a a fantastic phenomenologist and she was heavily influenced by Jean Bart and Marti and all of them so uh just in
general um again because you're working in the realm of AI um what how how has
existentialism influenced your thinking and more specifically the work of Simon DEA yes right CU it would seem like why
would am I bringing uh s b to to do something here I I found as is more the
more I got into uh Artificial Intelligence coming from my background as philosophy of mind um and cognitive
science and computational Neuroscience so the more I got into artificial intelligence the more I felt the need to
understand the the position of artificial intelligence in our social cultural environment
through the philosophy of sim um so more specifically through um a
framework in uh ethics of ambiguity excellent book excellent book uh and why
did I find it extremely relevant because it helped me understand and position uh artificial intelligence systems and
understand how they shape and are shaped by what we do uh in our social cultural
practices right um how they affect uh our cultural
communities differently how they affect individuals within a community that has
a power structure by definition um differently so I found uh Enlightenment
uh on Sim B to understand the effects of artificial intelligence uh systems in uh
communities in Social cultural communities why well through um the ways in which which um she understands so for
starters of course she uh has got a a very strong notion of embodiment that I
find it's quite relevant to understand how artificial intelligence systems are going to affect people differently
depending on the body that they have and how that body is situated in a power dynamics social cultural setting so
that's quite relevant uh initial Point um in um I find that uh the toolbox is
useful uh because it allows us to understand a feedback loop it allows us
to understand that our social cultural practices within a community that have
certain values and certain power dynamics are going to be nurturing of
certain artificial intelligence systems to be developed rather than others they
are going to serve certain people rather than others they are going to be harmful to certain people rather than others so
whatever we are doing in in in developing these artificial intelligence systems is already very telling of the
values that we endorse as a community indeed and perhaps this is this is worth mentioning here there's no neutral uh
system there's no neutral system it's the bias of our society is going to be reflected on the system itself right
that's very important to keep in mind absolutely and in a parallel I would say that it's it's paralleling with uh the
ways in which we've been doing science so here I'm just making connection with uh feminist epistemology and feminist
falso science the ways in which we've been doing science for many many many years where there's been no diversity in
the ways in which we do science and in the ways in which we claim to have a scientific model of something but that
scientific model uh is an output of a very uh highly dominant group of people
and this connects with standpoint Theory um as well in which uh what we have come
to learn more recently as science has become more diverse as we have had uh
more perspectives in science and scientific practices that are not coming from the West uh and it's worth
acknowledging that uh the West is only representative of 19% of the population
so as the more we've been having um and listening uh carefully about sence
science practices and science uh work uh that has been coming from uh more
diverse groups the more diversity we've been having um and um in science in
general and interestingly the more we've been able to understand that many many
many wellestablished paradigms and many textbook um phenomena
uh that we thought we understood especially in Psychology and cognitive psychology are now being questioned with
many um uh problems arising like the replication crisis for example uh or the
weird problem in cognitive psychology as well um so I think that what we have in
artificial intelligence is a problem that is analogous to the kind of like
scientific practices that we had what is the problem is that if you have a
technoscientific community that is not diverse then what is going to emerge
like the resources that are going to be used um the problems that are going to come up as worth a solution uh as worth
the funds to be developed are going to be those that interest or are to in the interest of that dominant group indeed
so that's one part of it so there's no such thing as neutral AI so the AI the
the ways in which we are already uh thinking about a problem that needs to be solved the ways in which we design
the solution the ways in which we develop the software the ways in which we implement it is already profound ly
social profoundly social so then um I think that this allows us to understand
the feedback loop in which AI systems emerge from already a very situated uh
social cultural environment that has very specifics that are going to be there which is why then we can talk
about the the algorithmic biases and data biases and all of that kind of thing so that's the status I think in
which we should look and think about uh AI systems if we are to have any Hope on regulation and thinking about it ethical
AI if there's any hope to think about it like that and then there's the other side of the feedback loop which is how
now that we have already a system there is an AI system out there in the wild in the society uh how that is going to
affect differently different people in the par Dynamics within a social cultural environment and here is where I
found that Sim not to come back to sim here is where I find that Sim bis
has got a nice tool kit it uh it kind of like um we can think about it as uh what
we we call an AI dilemma so the AI dilemma is that it comes up uh with the
promises that it's going to make life easier uh for our human species survival
as a whole the promise is that like any other Tool uh That civilization has been
developing any in any other form of Niche construction the idea is that life
is going to be easier because we have these tools available to us right
utopian dream absolutely and then we can defy uh the second law of Thermodynamics we can defy like all of the constraints
coming from the natural world we can overcome all of that um and life is going to be uh much easier for for all
of us but why is there a dilemma The Dilemma is that that's the promise right uh the Dilemma is that in as in with
with many many tools and there's a very rich uh literature and philosophy of of Technology um from hia to uh many
other approaches and thinking about the role of technology in societies and in
communities um AI is no less of that so AI is uh uh the same kind of situation
where um an AI system is going to affect people differently so the the the the S
toolkit that comes that I find interesting to think about it is that Simone talks about our uh our EXP
experience our individual experience is situated um in uh within a social
cultural power dynamics is um a continuous negotiation between freedom
and facticity between agency and objectification so that I think really
helps us here to see our situation in a social cultural
environment that is employing AI that goes unregulated right because it comes
with a promise of Freedom it comes with the pro promise that we got to be much Freer because we're going to be much
more empowered as a species um to live lives more um conveniently let's put it
like that so it's the promise of Freedom it's going to free us from our biological social cultural constraints
right um but the thing is is not going to free everyone yeah and the question is free whom and what kind of freedom so
then we find ourselves in that particular situation that mon described as a continuous negotiation between
freedom and facticity so nothing really changed right we are going to continue
this NE we're going to continue this continuous negotiation between agency
and objectification yeah where you're going to have certain groups of social cultural
communities that are going to be harmed and you have a certain Elite that is
going to uh profit or benefit from those advancements of those Technologies so I
think that that needs to be brought to the foreground if we are to have any hope of talking about ethical AI indeed
yeah in fact people talk about a lot of things like AI alignment and whatnot but I find that this kind of game
theoretic way of viewing AI alignment it always misses out on those most subtler
and in my view the more important points embeddedness the fact that us situatedness um and then the fact that
we're a part of this socio symbolic world and that's fascinating I loved how
you vived in uh the embeddedness idea from the more technical work into kind
of the more political artw works of s that's that's that's beautiful in fact have you got any papers where you uh
explore these these ideas you laid out because I couldn't really find them publicly I I can leave them in the
description down below there's one there is a very very short one um there is a commentary on uh Susan Schneider's book
artificial U and it's just out on philosophy of east and west excellent I
I'll email you and then I'll I'll find the paper and I'll leave it in the description down below please do and then I'm working on a paper that is
going to be out uh soon in a in a book uh and this is with a colleague of mine
Paul podowski and that's where we uh go a little bit more into political philosophy um and thinking about uh all
these that I just La out but then thinking about from a critical theory perspective uh going much more focusing
on how different uh groups of people uh within social cultural Community are
going to be affected by artificial intelligence systems and that's a paper that is going to be out soon and I will
printed soon so then I can also send that to excellent perfect thank you NS uh okay uh I want to ask you this one
last question although I'm uh not sure how he'll react to it are you familiar with the philosopher
slavo um I know is a an interesting figure not recently I've read uh I've
read his work many years ago so I'm not so sure okay so he has this uh
interesting take so he he had he wrote a book called Hegel in a wi brain and it's a fascinating book on just uh neuralink
and the idea of a lot of the things that you explore uh but he is a he's highly speculative because he's a heelan but uh
I'm I'm wondering if I show you a video by him where he kind of has this critique of AI what your thoughts would
be uh so is it okay if I just show you abely yes please he's asked this question about Ai and I'll I'll play it
here um and then I'm just curious to he what your thoughts on what he says hello
um how do I say this um I I partly apologize because this isn't something
that has been actually in discussion during this event but during the sort of summary at the beginning part of the
discussion points were the future of AI um intelligence you mean yeah yeah sorry
sorry yeah sorry um what are your thoughts particularly on cases of um AI
such as um large uh neural uh networks and large language models uh
specifically such as Google's Lambda AI that have been claiming sentients uh within themselves and ultimately is your
uh thoughts on the future of AI something that artificial sentients could eventually be something that could
come into fruition I uh it's difficult for me to give you a precise answer because again this is
minimally topic for another long talk so I can only give you sorry a a very
general answer I don't like this game of and I'm not accusing you of it but
generally in the debates on AI you know it's all about uh we people are
obviously limited will artificial intellig Ence become more intelligent
than we are and so on I to be as brief as possible I don't see the problem of
artificial intelligence in its being more bright than we but in not being
stupid in the way we humans can be what I think is unique for us humans is to be
stupid in a proper way so that you make something or say something stupid but
then you uh get the message through this very stupidity another dimension opens
up to you so I would rather say that uh of course we have now already computers
which can which are self learning change adopt to rules but they still take
mistakes as something to be overcome they don't see the let's call it the
productivity the capacity to open up a new space of
the mistake as such to make it a little bit clearer what I
mean uh I in my book on Hegel and the
wired brain I use this examples it's a disgusting movie I hate at the actors
everybody but you saw afraid to mention it for weddings at the funeral you know
but nonethless you know that scene when Hugh Grant declares love to Andy mcdell
I think and in his own fake way he gets confused stutters blah blah blah but in
this way he succeed in declaring CL if he were to say it clearly how
he loves her it would be a fake so you see how the mistake as such renders the
message now I enter a very complex domain of what John elster a pretty good
Norwegian theorist of rational action calls states which are necessarily by
products for example I wrote about this in a text that was published in one of
your philosophical monthly journals philosophy now or what if I say I have
dignity it's self-defeating because if I say this it's ridiculous I must so
display dignity through the way I act and the same goes for many of our
acts which you cannot it is self-defeating if if you
directly talk about them at this level I
try to circumscribe something that maybe
at least the way things stand now artificial
intelligence I think cannot do again I repeat not because we humans are
brighter but because we humans learned to use in a productive
way our stupidity our limitation itself but I'm sorry maybe now it would be too
much to to to go into this not sure if that made sense but what are your
thoughts in s wow so quite interesting uh perspective that uh D it brings in um
for sure I agree that artificial intelligence systems are not um the kind
of natural intelligence that we would think about uh when we think about uh
human beings or even non-human animals cognition um interesting that it brings
in stupidity indeed it it is part of uh of our practices and I think that's the
concept that here I would I would focus more is to I would bring more the the
difference of the ways in which you have artificial intelligence systems and you have um
uh natural intelligence let's call it like that um they differ in the ways
that natural intelligence systems they engage in practices they're highly situated with the world that allow for
certain kinds of mistakes to occur as well and learning from the mistakes because what because we are dealing with
a highly uncertain world and trying to adjust continuously adjusting to this
highly uncertain world and for some uh more um less complex systems uh like
non-human animals or plant cognition um those worlds can be uncertain from the
very natural sense of the environment that is uncertain so the uncertainty comes from that in our specific case
because we somehow developed this sophisticated form of intelligence that
uh separates us apart from non-human cognition which is like a capacity in which we have developed a whole
civilization with all of these institutions and organizations that we have built um that means that that comes
from highly sophisticated practices that we involve that we engage with uh and
we' have been able to navigate the uncertainties of the environment in in in quite refined ways which include
social cultural practices within all of these power dynamics etc etc so in a way
I think that I would say that uh we can be very stupid but we are also highly
sophisticated in the ways that we were able to build all of these institutional um institutions uh for us and around us
um so I would say that it is on our practices that resides that difference
yeah yeah and I think it connects a lot again to what we discussed about you know Simone de and embededness is
fascinating yeah thank you for humoring humoring me with that because uh it's uh je is an I find him fascinating I love
reading his books but of course to get to what he's saying it takes a bit of you know it takes I'd say being a part
of his language game to see where he coming from uh fascinating all right and there one last question and a completely
personal question because I I do need your advice here uh as we discussed before the podcast I am in many ways
trying to follow in your footsteps so uh what advice would you have uh for any
person who wants to go into the the research and philosophy of AI specifically
uh what are the big big topics right now in in contemporary philosophy of AI research that needs uh that needs
thinking that needs to be addressed uh in your view so um there are a couple of
course um I think that um and now I'm just going to speak to of course there's
a reason why I've defined this as my my field of research for the next couple of years is that I really think that we
need a very serious understanding or description of how of of the role that
AI plays in our social cultural settings
right because this is going to connect with everything else and all of the societal problems that we are facing I
um think that um or I'm always I've always been very motivated to think to
to do my philosophy work very connected and close to the real world right so I
think that there are a few very important questions that remain from uh
from many many many years ago uh in many different uh
philosophy um approaches uh within specifically cognitive science or philosophy of mind which is my my field
uh that still remain and we need to tackle them and continue to develop literature and develop theory on that
but I also think that I like to do that in connection with the real world um
aware of the real world um speaking to the real world and I think that in the
case of AI there is an objective necessity to do that because AI is uh
it's it is in a way it is a new uh aspect of our um of our in culturation
and the ways in which we um experience the world
uh it has been made more more prominent with the event of large language models
but I want to stress that AI has been around making decisions for you and I
about who gets the job what treatment do you get uh when you get sick AI has been around making all of the decisions for
us uh for a long time it's just that we were not very aware of it um so this is a real momentum and opportunity for us
to um think about develop understanding uh and descriptions about
what role uh is AI playing uh in our social cultural environments where does
it come from these AIS that we are creating and how are they impacting different people sitting in different
structures of the power dynamics as we discussed as we discussed so I find this a a very important um topic of research
that we do not have Clarity on either because one would take the computational the of mind and think that okay so if it
is the case that mind is a computer of the predictive computational capacity
then perhaps it would be the case uh it's very it's very it's very simple to
to do this this argument jump into thinking that well if large language models are also predictive uh um
computers or predictive computations then they may at some point sometime in the future become conscious and I'm
going to push back on that right because I think that's distracting right because while we are distracted on those uh very
um um esoteric philosophic exactly philosophical exoteric uh confusions as
viit canstein would have it then we are not doing anything that would actually bring some epistemic value and gain that
would allow now our best legislators our best ethicists to come in with a fully
clear description of the role that AI is plays playing and how it impacts
different people so then with that Clarity then we can have our ethicists coming in and helping legislate these
systems otherwise they will not they will go un legislated because the
governmental uh institutions they do not have the capacity without this Clarity
there is no capacity to understand the technology so you would not be able to legislate the technology itself and then
without this Clarity of how the technology is going to impact people then you will not not be able to legislate that impact so that's why I
think that this so to speak cognitive science of artificial intelligence that
takes into highest consideration inculturation and inculturated aspects of social cultural power dynamics is
really important to connect to the real world where we really need to legislate the impact of these systems into into
people yeah all right I think that ethical call to action is the perfect place for us to conclude thank you for
your time and S thank thank you so much for having me really really what a wonderful time thank you excellent it was a great shot thank you thank you