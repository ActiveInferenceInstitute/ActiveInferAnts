https://www.youtube.com/watch?v=2st17sXlSgQ
Ask Me Anything w/ Karl Friston
0:00 Intro
1:30 How does your work relate to other prominent theories of consciousness, such as Integrated Information Theory (IIT), Global Workspace Theory (GWT), Quantum Consciousness Theory (Orch-OR), and Higher-Order Thought Theory (HOTT)?
19:55 Can you discuss the potential limitations or challenges of your theory and areas where further research is needed? Can you criticize your own theory?
27:33 Given the complexity of the brain and the Free Energy Principle, do you believe it's feasible to create a truly 'conscious' machine intelligence, or are there unique aspects of biological systems that can't be replicated in artificial constructs?
35:37 Could the responses we get from generative AI be considered a query to us? Could it be seen as a dialogue?
41:05 How much do you keep up with the current developments in generative AI?
43:29 What do you consider true general AI intelligence?
47:28 What are your thoughts on the agency of AI and the possible danger therein?
58:42 If you could ask a fully conscious (super) AI a question, what would it be and why?
1:04:32 What are your thoughts on Donald Hoffman's theory of consciousness?
1:10:57 Understanding information as the fundamental nature of reality, and why that is inherently metaphorical.
1:15:17 What do you think of UFOs or UAPs?
1:17:53 What happens to the energy within us after death, to where does it dissipate (where does consciousness go)?
1:23:26 You talk about using free energy to explore future consequences, but what about reflecting on past actions?
1:27:15 What are your thoughts on near death experiences (NDEs)?
1:34:30 Some thoughts on out-of-body experiences (OBEs) and the fragility of experiential concepts.
1:40:37 Were there any moments or experiences in your personal life that you'd say have significantly shaped or redirected your research in theoretical neuroscience and computational modeling?
1:42:17 And has your work influenced your daily decisions and how you think about the world?
1:46:15 If you could have a conversation with any historical figure (scientist, philosopher, or religious leader) about their views, who would it be and what would it be about?
Welcome to Ask Me Anything. I'm Jack. I had a couple of technical difficulties with the interview with Karl Friston yesterday. Somehow the first half hour of the interview was not recorded. There were some audio drops online and the quality of my video isn't too great. I had some connectivity issues. I find out it was running really slow. It was lagging. I think I was asking too much of this machine, but I tried to salvage what I could. There's still two hours left of the interview. What wasn't recorded was the introduction, Karl's explanation of his free energy principle, which if you are interested, you can find on YouTube. I especially would recommend his interview with Curt Jaimungal on the Theories of Everything Channel, which I just keep recommending. Having said that, if you're feeling particularly generous, consider donating to my Patreon at patreon.com/askinganything. While you're watching, please like and subscribe. So let me just introduce Dr. Karl Friston, a free energy farseer, neuroscientific nomad, Bayesian brain blacksmith, computational connoisseur. He's an interpretaming titan, shaping our understanding of the brain and cognition. His work on the free energy principle offers a unified framework for observing the complex dynamics of biological systems. With a career spanning three decades, Karl has navigated the realms of theoretical neuroscience, computational modeling, and systems biology, influencing our interpretation of the brain's intricate workings. He has authored over 800 scientific papers, marking transformative strides in this field. Enjoy.
How does your work relate to other prominent theories of consciousness, such as Integrated Information Theory (IIT), Global Workspace Theory (GWT), Quantum Consciousness Theory (Orch-OR), and Higher-Order Thought Theory (HOTT)?
He talks a little bit about consciousness, and I am curious how your work relates to other prominent theories of consciousness such as, for example, Integrated Information Theory, Global Workspace Theory, Quantum Consciousness Theory, and Higher Order Thought Theory. I'm not sure I have a suspicion you know at least three or four of those, but how does your work relate to those theories?
A very interesting question. In fact, with colleagues, specifically colleagues like Maxwell Ramstead and Adam Safron and others, we've just written a series of papers looking at a minimum unifying model of consciousness that speaks to a lot of those theories. So I can answer your question quite expertly because I've just read papers. They all have, to a greater or lesser extent, something in common with and are consilient with the free energy principle. I say that because you have to remember, and I am always reminded of this by Jakob Hohwy, the free energy principle is not a principle that you can apply to produce a theory of consciousness. So it's not there to explain consciousness. So it probably plays a useful role when applied to various theories of consciousness, and you know, when you do apply it, then you generally find a lot of consilience. So let's just take the Global Workspace Theory. If you look at the mechanics of active inference, that would be an application of the free energy principle to a brain, for example, and look at the various processes there, such as predictive coding and predictive processing, then you can see direct homologues or aspects of global neuronal workspace and workspace theory. Indeed, Global Workspace Theory emerges from first principles. So what are those first principles? Well, we've just said that we can understand processing in the brain as a process of inference under some kind of world model or generative model that entails the space of hypotheses that we bring to the table to explain our sensations. What kind of model is it? Well, we know two things about it in the spirit of the good regulator theorem or the notion that in order to successfully explain our sensory input, our models of the world generating those inputs, our world models have to have a degree of isomorphism with the way that the sensations are generated, which just means that the internal world models or generative models entailed by our brain have to have both a dynamic, because of the importance of time (we're talking about processes here), and hierarchical structure. As soon as you say that and then you work out the Bayesian mechanics or the free energy minimizing dynamics that play out on these dynamic hierarchical generative models, you get to something that looks very much like a global neuronal workspace. First of all, there is something deep in this centripetal hierarchy that is informed by and predicts and tries to explain lower levels that are towards the surface of the centripetal hierarchy. Furthermore, not everything gets to the global workspace in the sense that I have to be able to attend to certain sensory inputs in order to grease the pathways to give those kinds of prediction errors, for example, privileged access to deeper levels of processing. So this is what, if you're a psychologist, you would recognize as attention. If you were an engineer, you'd recognize it as trying to optimize the Kalman gain. Mathematically, it's just a question of selecting those newsworthy prediction errors that convey precise information and estimating the precision and thereby enabling those prediction errors to ignite and induce basic belief updating deep in the hierarchy. So that would be, if you like, a mathematician's or a computational neuroscientist's description of global neural workspace. So just knowing that you have to have a dynamic hierarchical model would suggest that the constructs that emerge under Global Neuronal Workspace are almost must almost be true and are emergent from applying the free energy principle to those characteristic charitable models that you'd see in things like you and me. The Integrated Information Theory is slightly more distant in terms of its relation to the free energy principle because Integrated Information Theory is really a description. It's an axiomatic theory that is based upon a handful of axioms that must be true or are assumed to be true and true of consciousness, and then it tries to identify certain information theoretic characteristics of systems that possess these axiomatic characteristics. So it's not really a simple principle in the sense of the free energy principle. It's more a consequence of committing to certain axioms. However, those commitments lead to something that looks very similar to the free energy principle in terms of a set of partitions that are trying to, in some way, maximize mutual information between those partitions in a distributed set of states that are all influencing each other. And again, that sparsity of connectivity is exactly what underwrites the hierarchical structures that we're talking about previously. So if you think about it, how do I make, say, a graph or a network hierarchical? I just remove any connections that jump over too many levels. I just render it very sparse so that it has a set of partitions. Technically, these are Markov blankets that define the thinness, you know, if a hierarchical level in my brain is a thing, then it has to have a Markov blanket. If it has a Markov blanket, that induces a certain kind of partitioning and sparsity of influence and connections. Furthermore, the emphasis of a special kind of distributed mutual information that is inherent in IIT can be read as an important aspect or part of variational free energy. So in order to predict well, in order to maximize the evidence for my generative models of a sensed world, I effectively have to maximize mutual information between my explanations for what's going on out there and what is actually going on out there. That actually entails a maximization of the mutual information between my internal representations with my generative model or my world model and the sensory fluctuations providing the evidence that's helping me revise my beliefs about what's going on. Those fluctuations in particular coding would be the prediction errors. But all that also holds true in a hierarchical setting. So not only am I trying to maximize mutual information between what's going on in my head and what's going on in my world (in fact, in this instance, in your head so that we can engage in this kind of generalized synchrony and shared narrative and conversation), and I'm doing that generally with my entire lived world, but I'm also trying to maximize mutual information with my sensorium but also all the inner screens that constitute the different levels of my generative model. So now we're right back to where IIT would want you to be. You're trying to maximize mutual information in a particular way over partitions that I would read in terms of a hierarchical carving nature at its joints inside your generative model. In terms of Higher Order Thought Theory, that almost emerges for free as soon as you talk about hierarchical generative models. You can't have any inference that is not, if you like, apt for descriptions under higher order thought theories as soon as you commit to hierarchical predictive coding and hierarchical generative models. So the whole point of having nested hierarchical levels in our generative model, where each level is trying to predict the level below right down to the sensorium, is that you are effectively inducing higher and higher order inference processes. So that you know there may be some very deep one or more distributed systems that are trying to predict their Markov blanket, which is another system inside the brain, very much like an onion, and so on all the way out to the sensory cortices and ultimately our sensory epithelia. So at some point, you are going to encounter, especially in those kinds of creatures or generative models or creatures that entail models that have this aspect of agency and the capacity to plan into the future and furthermore internalize action (so internal action, mental action is just basically selecting the data on the inside), and that will correspond to attention. You've now got this deep link now between attention and conscious processing under higher order thought theory that emerges simply because I have to have a model of the consequences of my sense-making, even if it's within my skull and within my hierarchical model. And through that, you now start to tell a story about, well, what am I modeling? I'm modeling myself modeling my data. So you'll have a natural, it is quintessentially higher order just in virtue of having a hierarchical world or generative model, which you need in order to minimize your free energy. Was there a fourth one? I can't remember. Let me see, Integrated Information Theory, Global Workspace Theory, Quantum Consciousness Theory, and Higher Order Thought Theory. Those were the four most popular ones. Yes, well, very briefly, I would read the quantum formulations very much along the lines that is emerging at the moment, described by people like Chris Fields and Jim Playsbrook and Mike Levin. So they've recently come up with this notion of an inner screen hypothesis, which a lot of my colleagues are quite excited about and subscribe to, which is exactly, well, first of all, let me just qualify why this is a quantum approach. It is not that consciousness emerges at the level of very small quantum physics. It's the fact that you could understand anything from the point of view of quantum information theory. And a particular aspect that Chris and colleagues focus on is the notion of a holographic screen that allows two systems to couple to each other. So the bulk of one system reading and writing off the holographic screen under holographic principle in tandem with and with shared quantum reference frames, another system. And if you now apply that kind of quantum information theory to the hierarchical structures we were talking about, entailed by higher order thought theory and one could imagine would be endorsed by a minimum kind of partition under IIT, then what you have is this notion that there are lots and lots of inner screens in our brains which play the role of holographic screens from a classical point of view, Markov blankets onto which you read and write classical information, all with a shared or common frame of reference, quantum frame of reference. And if you have that picture in mind, you can start to ask the question, well, is there a special one right deep inside? And I mean literally deep, deep in terms of the deep learning notion of a hierarchical world model you find in machine learning, but also literally deep in the brain where the cells of origin that do this attentional modulation, this mental action that we were talking about, celebrated by people like Mike Graziano's live. And then you arrive at a notion of an irreducible set of internal neuronal states whose Markov blanket or inner screen can never be, if you like, reduced any further. And it may be that this is a good model for the unique aspects of consciousness, unitary aspects of consciousness that are celebrated in the IIT axioms. And in a sense, this is a, you know, a resurrection of the Cartesian theater. It's all neocartesianism of a very bold sort that is literally reintroducing the notion of screens, but in a very nuanced way that actually is very consistent with the physics of self-organization because it all rests upon a free energy principle or a quantum version of the free energy principle where you're reading the holographic screens as Markov blankets, but now on the inside of a hierarchical or partitionable generative model. Is that the same thing as subjective experience? I'm not sure that the people who are exploring this as a sort of minimal model that gracefully accommodates things like higher order thought theory, global neural workspace, and a number of other theories would be quite so adventurous to say at this stage, yes, this is what explains quality of experience and subjective experience. I think they would argue this would be a minimal requirement in the same spirit that I was arguing previously that to be a self is to be an agent, and to be an agent is to act, and to act is to have a generative model that entails and can generate the consequences of action. So I think that most people would say that the sort of sentience of a non-basic or trivial sort would certainly require this kind of mental action that ensues from having an inner screen that can never see the consequences of its own action by acting on screens that are lower down or more superficial in the hierarchy. And that's simply because there are no screens inside this minimum Markov bracket or bulk. So a lot of this does rest upon action, mental action, which I repeat you can read as attention if you like, or mental action. And then if you read it along those lines, you can then relate it to notions pursued by people like Thomas Metzinger and Anil Seth, where you can render things phenomenally transparent or opaque by this kind of mental action. So there is, I think, quite a nice story that could be built upon this notion of an inner screen that is open to the rest of the brain and therefore is acting upon, engaging with the rest of the brain in a particular kind of way that looks like mental action and attention, that enables things to become phenomenally opaque. And this would be a prerequisite for sanctions of a certain sort. So I think there's a story to be told. I'm not sure that that story is being put together convincingly in the philosophical literature, but you know, it may well be a direction of travel over the next few years.
Can you discuss the potential limitations or challenges of your theory and areas where further research is needed? Can you criticize your own theory?
A very interesting question. In fact, with colleagues, specifically colleagues like Maxwell Ramstead and Adam Safron and others, we've just written a series of papers looking at a minimum unifying model of consciousness that speaks to a lot of those theories. So I can answer your question quite expertly because I've just read papers. They all have, to a greater or lesser extent, something in common with and are consilient with the free energy principle. I say that because you have to remember, and I am always reminded of this by Jakob Hohwy, the free energy principle is not a principle that you can apply to produce a theory of consciousness. So it's not there to explain consciousness. So it probably plays a useful role when applied to various theories of consciousness, and you know, when you do apply it, then you generally find a lot of consilience.
So let's just take the Global Workspace Theory. If you look at the mechanics of active inference, that would be an application of the free energy principle to a brain, for example, and look at the various processes there, such as predictive coding and predictive processing, then you can see direct homologues or aspects of global neuronal workspace and workspace theory. Indeed, Global Workspace Theory emerges from first principles. So what are those first principles? Well, we've just said that we can understand processing in the brain as a process of inference under some kind of world model or generative model that entails the space of hypotheses that we bring to the table to explain our sensations. What kind of model is it? Well, we know two things about it in the spirit of the good regulator theorem or the notion that in order to successfully explain our sensory input, our models of the world generating those inputs, our world models have to have a degree of isomorphism with the way that the sensations are generated, which just means that the internal world models or generative models entailed by our brain have to have both a dynamic, because of the importance of time (we're talking about processes here), and hierarchical structure.
As soon as you say that and then you work out the Bayesian mechanics or the free energy minimizing dynamics that play out on these dynamic hierarchical generative models, you get to something that looks very much like a global neuronal workspace. First of all, there is something deep in this centripetal hierarchy that is informed by and predicts and tries to explain lower levels that are towards the surface of the centripetal hierarchy. Furthermore, not everything gets to the global workspace in the sense that I have to be able to attend to certain sensory inputs in order to grease the pathways to give those kinds of prediction errors, for example, privileged access to deeper levels of processing. So this is what, if you're a psychologist, you would recognize as attention. If you were an engineer, you'd recognize it as trying to optimize the Kalman gain. Mathematically, it's just a question of selecting those newsworthy prediction errors that convey precise information and estimating the precision and thereby enabling those prediction errors to ignite and induce basic belief updating deep in the hierarchy.
So that would be, if you like, a mathematician's or a computational neuroscientist's description of global neural workspace. So just knowing that you have to have a dynamic hierarchical model would suggest that the constructs that emerge under Global Neuronal Workspace are almost must almost be true and are emergent from applying the free energy principle to those characteristic charitable models that you'd see in things like you and me.
The Integrated Information Theory is slightly more distant in terms of its relation to the free energy principle because Integrated Information Theory is really a description. It's an axiomatic theory that is based upon a handful of axioms that must be true or are assumed to be true and true of consciousness, and then it tries to identify certain information theoretic characteristics of systems that possess these axiomatic characteristics. So it's not really a simple principle in the sense of the free energy principle. It's more a consequence of committing to certain axioms. However, those commitments lead to something that looks very similar to the free energy principle in terms of a set of partitions that are trying to, in some way, maximize mutual information between those partitions in a distributed set of states that are all influencing each other. And again, that sparsity of connectivity is exactly what underwrites the hierarchical structures that we're talking about previously.
So if you think about it, how do I make, say, a graph or a network hierarchical? I just remove any connections that jump over too many levels. I just render it very sparse so that it has a set of partitions. Technically, these are Markov blankets that define the thinness, you know, if a hierarchical level in my brain is a thing, then it has to have a Markov blanket. If it has a Markov blanket, that induces a certain kind of partitioning and sparsity of influence and connections. Furthermore, the emphasis of a special kind of distributed mutual information that is inherent in IIT can be read as an important aspect or part of variational free energy. So in order to predict well, in order to maximize the evidence for my generative models of a sensed world, I effectively have to maximize mutual information between my explanations for what's going on out there and what is actually going on out there. That actually entails a maximization of the mutual information between my internal representations with my generative model or my world model and the sensory fluctuations providing the evidence that's helping me revise my beliefs about what's going on. Those fluctuations in particular coding would be the prediction errors.
But all that also holds true in a hierarchical setting. So not only am I trying to maximize mutual information between what's going on in my head and what's going on in my world (in fact, in this instance, in your head so that we can engage in this kind of generalized synchrony and shared narrative and conversation), and I'm doing that generally with my entire lived world, but I'm also trying to maximize mutual information with my sensorium but also all the inner screens that constitute the different levels of my generative model. So now we're right back to where IIT would want you to be. You're trying to maximize mutual information in a particular way over partitions that I would read in terms of a hierarchical carving nature at its joints inside your generative model.
In terms of Higher Order Thought Theory, that almost emerges for free as soon as you talk about hierarchical generative models. You can't have any inference that is not, if you like, apt for descriptions under higher order thought theories as soon as you commit to hierarchical predictive coding and hierarchical generative models. So the whole point of having nested hierarchical levels in our generative model, where each level is trying to predict the level below right down to the sensorium, is that you are effectively inducing higher and higher order inference processes. So that you know there may be some very deep one or more distributed systems that are trying to predict their Markov blanket, which is another system inside the brain, very much like an onion, and so on all the way out to the sensory cortices and ultimately our sensory epithelia.
So at some point, you are going to encounter, especially in those kinds of creatures or generative models or creatures that entail models that have this aspect of agency and the capacity to plan into the future and furthermore internalize action (so internal action, mental action is just basically selecting the data on the inside), and that will correspond to attention. You've now got this deep link now between attention and conscious processing under higher order thought theory that emerges simply because I have to have a model of the consequences of my sense-making, even if it's within my skull and within my hierarchical model. And through that, you now start to tell a story about, well, what am I modeling? I'm modeling myself modeling my data. So you'll have a natural, it is quintessentially higher order just in virtue of having a hierarchical world or generative model, which you need in order to minimize your free energy.
Was there a fourth one? I can't remember. Let me see, Integrated Information Theory, Global Workspace Theory, Quantum Consciousness Theory, and Higher Order Thought Theory. Those were the four most popular ones.
Yes, well, very briefly, I would read the quantum formulations very much along the lines that is emerging at the moment, described by people like Chris Fields and Jim Playsbrook and Mike Levin. So they've recently come up with this notion of an inner screen hypothesis, which a lot of my colleagues are quite excited about and subscribe to, which is exactly, well, first of all, let me just qualify why this is a quantum approach. It is not that consciousness emerges at the level of very small quantum physics. It's the fact that you could understand anything from the point of view of quantum information theory. And a particular aspect that Chris and colleagues focus on is the notion of a holographic screen that allows two systems to couple to each other. So the bulk of one system reading and writing off the holographic screen under holographic principle in tandem with and with shared quantum reference frames, another system.
And if you now apply that kind of quantum information theory to the hierarchical structures we were talking about, entailed by higher order thought theory and one could imagine would be endorsed by a minimum kind of partition under IIT, then what you have is this notion that there are lots and lots of inner screens in our brains which play the role of holographic screens from a classical point of view, Markov blankets onto which you read and write classical information, all with a shared or common frame of reference, quantum frame of reference. And if you have that picture in mind, you can start to ask the question, well, is there a special one right deep inside? And I mean literally deep, deep in terms of the deep learning notion of a hierarchical world model you find in machine learning, but also literally deep in the brain where the cells of origin that do this attentional modulation, this mental action that we were talking about, celebrated by people like Mike Graziano's live.
And then you arrive at a notion of an irreducible set of internal neuronal states whose Markov blanket or inner screen can never be, if you like, reduced any further. And it may be that this is a good model for the unique aspects of consciousness, unitary aspects of consciousness that are celebrated in the IIT axioms. And in a sense, this is a, you know, a resurrection of the Cartesian theater. It's all neocartesianism of a very bold sort that is literally reintroducing the notion of screens, but in a very nuanced way that actually is very consistent with the physics of self-organization because it all rests upon a free energy principle or a quantum version of the free energy principle where you're reading the holographic screens as Markov blankets, but now on the inside of a hierarchical or partitionable generative model.
Is that the same thing as subjective experience? I'm not sure that the people who are exploring this as a sort of minimal model that gracefully accommodates things like higher order thought theory, global neural workspace, and a number of other theories would be quite so adventurous to say at this stage, yes, this is what explains quality of experience and subjective experience. I think they would argue this would be a minimal requirement in the same spirit that I was arguing previously that to be a self is to be an agent, and to be an agent is to act, and to act is to have a generative model that entails and can generate the consequences of action.
So I think that most people would say that the sort of sentience of a non-basic or trivial sort would certainly require this kind of mental action that ensues from having an inner screen that can never see the consequences of its own action by acting on screens that are lower down or more superficial in the hierarchy. And that's simply because there are no screens inside this minimum Markov bracket or bulk. So a lot of this does rest upon action, mental action, which I repeat you can read as attention if you like, or mental action. And then if you read it along those lines, you can then relate it to notions pursued by people like Thomas Metzinger and Anil Seth, where you can render things phenomenally transparent or opaque by this kind of mental action.
So there is, I think, quite a nice story that could be built upon this notion of an inner screen that is open to the rest of the brain and therefore is acting upon, engaging with the rest of the brain in a particular kind of way that looks like mental action and attention, that enables things to become phenomenally opaque. And this would be a prerequisite for sanctions of a certain sort. So I think there's a story to be told. I'm not sure that that story is being put together convincingly in the philosophical literature, but you know, it may well be a direction of travel over the next few years.
Can you discuss the potential limitations or challenges of your theory and areas where further research is needed? Can you criticize your own theory?
Can you discuss the potential limitations or challenges of your theory and areas where further research is needed? So criticize your own theory, Karl.
Well, the first thing to do is to know that the free energy principle is a principle, so it's not really there to be criticized or falsified. It's a little bit like Hamilton's principle of least action. You can apply it or not depending upon what you'd like to do. So it is in the application to various things that the challenges actually arise, and that's where the heavy lifting starts. And generally, that reduces to specifying the world model, the generative model that is necessary to define the free energy. And that's, I think, where the challenges are.

welcome to asking anything I'm Jack I had a couple of technical difficulties with the interview with golf Western
yesterday somehow the first half hour of the interview was not recorded there were some audio drops online and the
quality of my video isn't too great I had some connectivity issues find out it was running really slow it was lagging I
think I was asking too much of this machine but I tried to sell if it's what I could there's still two hours left of
the interview what wasn't recorded was the introduction cross explanation of his free energy principle which if you
are interested you can find on YouTube I especially would recommend his interview with curry mango on the theories of
everything Channel which I just keep recommending having said that if you're feeling particularly generous consider
donating to my patreon at patreon.com asking anything while you're watching please like
subscribe so let me just introduce Dr Carl first in a free energy farceer
neuroscientific Nomad Bayesian brain blacksmith computational connoisseur he's an interpretaming Titan shaping our
understanding of the brain and cognition his work on the free energy principle offers a unified framework for this
servering the complex dynamics of biological systems with the career spending three decades Carl has
navigated the Realms of theoretical Neuroscience computational modeling and systems biology influencing our
interpretation of the brains intricate workings he has authored over 800 scientific papers marking transformative
strides in this field enjoy he talks a little bit about a little bit
How does your work relate to other prominent theories of consciousness, such as Integrated Information Theory (IIT), Global Workspace Theory (GWT), Quantum Consciousness Theory (Orch-OR), and Higher-Order Thought Theory (HOTT)?
about Consciousness and um I am curious how your work relates to there are two other prominent theories
of Consciousness such as for example integrated information Theory uh Global
workspace Theory Quantum Consciousness Theory um and higher order thought Theory
and I'm not sure I I have a suspicion you know at least three or four of those but how does your work relate to those
theories I get a very interesting question in
fact um with colleagues um specifically colleagues like Maxwell ramstead and Adam saffron and um and
others we've just written a series of papers looking at a minimum minimum
unifying model of Consciousness that speaks to a lot of a lot of those theories so I can answer your question
quite expertly because I'm glad I just read papers so
um they all have to a greater lesser extent
um something in common with um and consilient with the free energy
principle and I say that because you um you have to remember and I am always
reminded of this by yaakov hell the free energy principle is not a principle that
you can apply to produce a theory of Consciousness so it's not it's not there to explain consciousness
um so um it probably plays a useful role when applied to various theories of
Consciousness um and you know when you when you do apply it then you know I generally you
find I repeat a lot of concealings so let's just take the global workspace Theory
um so if you look at the mechanics of active
inference that would be an application the free energy principle to a brain for example um and look at the various process there
is such as predictive coding and predictive processing then you can see
um direct homologues or aspects of global global neuronal workspace and workspace Theory and indeed Global
workspace Theory emerge from first principles so what are those first
principles well we've just said that the the game that we can understand processing in the brain as a process of
inference under some kind of world model or gerited model that entails the space
of hypotheses that we bring to the table to expand our Sensations what kind of
model is it well we know two things about it in the spirit of the good
regulator theorem or the notion that in order to successfully explain
are sensory input are models of that the
world generating those uh inputs are World models have to have a degree of
ethomorphism with the way that the sensations are generated which just means that the internal World models or
generative models entailed by our brain have to have both a dynamic because of
the importance of time we're talking about processes here and hierarchical structure and as soon as you say that
and then you work out the uh Bayesian mechanics or the free energy minimizing
dynamics that play out on these Dynamic hierarchical generative models you get
to something that looks very very much like a global neuronal workspace first of all there is something deep in this
centripetal hierarchy that is informed
by and predicts and tries to explain lower levels that are towards the
surface of the centripetal hierarchy furthermore not everything gets to the
the set the uh the um the global workspace in the sense I have to be able
to attend to certain sensory inputs in order to grease the pathways to give
those kinds of prediction errors for example privileged access to deeper levels of processing so this is what
this is if you're a psychologist you you would recognize as attention if you were
an engineer you'd recognize it as trying to optimize the Kalman gain mathematically it's just a question of
selecting those newsworthy prediction errors that convey precise information
and estimating the Precision and thereby enabling those prediction errors to
ignite and induce basic belief updating deep in the hierarchy so that would be
if you're like a mathematicians or a um a computational neuroscientist
description of global neural workspace so just knowing that you have to have a
dynamic hierarchical model would suggest that the constructs that one that emerges under uh Global neuronal
workspace there is uh you know um are almost
must almost be true and are emergent from applying the free
energy principle to those characteristic charitable models that you'd see in things like you and me
um the um integrated information Theory that's slightly
um slightly more distant um in terms of
it's relative to the free energy principle because um integrated information theory is
really a description it's an axiomatic um theory that they is based upon a handful
of axioms that must be true or are assumed to be true and true of
Consciousness and then it tries to um identify certain uh information
theoretic characteristics of systems that that possess these axiomatic
characteristics so it's not really um a simple principle in the sense of
the free energy principle it's more a consequence of committing to certain axioms however those commitments
um lead to something that looks very very similar to the free energy principle in terms of
um a set of partitions um that are trying to in some way
maximize Mutual information but between those partitions
in a distributed set of states that are all influencing each other and again
that sparsity of connectivity is exactly what underwrites the hierarchical
structures that we're talking about previously so if you think about it how do I make see a graph or a network
hierarchical I just remove any connections that jump over too many levels I just render it very very sparse
so that it has a set of partitions technically these are Markov blankets
that Define the thinners you know if a hierarchical level in my brain is a thing then it has to have a Markov
blanket if it has a markup blanket that induces a certain kind of partitioning and sparsity of influencer and
connections furthermore the emphasis of a special kind of
distributed Mutual information that is inherent and in IIT is can be read as an
important aspect or part of variational free energy so in order to
predict well in order to maximize the evidence for my
generative models of a sensed world I effectively have to maximize Mutual
information between my explanations for what's going on out there and what is actually going
on out there that actually entails a maximization of the neutral information between my internal representations with
the my generative model of my world model and the sensory fluctuations providing the evidence that's helping me
revise my beliefs about what's going on those fluctuations in particular coding
would be the prediction errors but all that also holds true in a hierarchical setting so not only am I trying to
maximize much information between what's going on in my head and what's going on in my world in fact in this instance in
your head so that we can engage in this kind of generalized synchronizationally shared narrative and conversation and
I'm doing that generally with my entire lived world but I'm also trying to maximize Mutual information with my
sensorium but also all the inner screens that constitute the different levels of
my generative model so now we're right back to where IIT would uh would would want you to be
you're trying to maximize much information in a particular way over partitions that I would read in terms of
a heterogical carving nature at its joints inside your genitive model in
terms of higher order thought Theory um that almost emerges for free as soon as you talk about hierarchical gelatin
models you can't have a you can't have any inference that is not if you like
apt for descriptions under higher order thought theories
um as soon as you commit to hierarchical predictive coding and hierarchogenic models so the whole point of having
nested um hierarchical levels that our generative model where each level is trying to
predict the level below right down to the sensorium um is that you are effectively have
inducing higher and higher order inference processes so that you know
there may be some very deep one or more distributed systems that are trying to
predict their Markov blanket which is another system inside the brain very
much like an onion and so on all the way out to the sensory cortices and ultimately our sensory epithelia so at
some point you are going to encounter um especially in those kinds of creatures or gelatin models or creatures
that entail models that are have this aspect of agency and the capacity to
plan into the future and you're furthermore internalize
action so internal action mental action is just basically selecting the data on the inside
um and that will correspond to attention you've now got this deep link now
between attention and conscious processing under higher order thought theory that emerges simply because I
have to have a model of the consequences of my sense making even if it's within
my skull and within my hierarchical model and through that you now start to tell a
story about well what am I modeling I'm modeling myself modeling my data so
you'll have a natural it is quintessentially higher order just in Virtual it being uh just in virtue of
having a hierarchical world or gerited model which you need in
order to uh to uh to minimize to do your self-efficiency or to minimize your free
energy was there a fourth one I can't remember um let me see information integrated
mystery Global work phase Theory Quantum conscience Theory and higher order thought Theory those were the four most
popular ones yes uh well very briefly um yeah I would
read the quantum formulations very much along the lines that is emerging at the moment um described by people like Chris field
and Jim playsbrook and Mike Levin um so they've um they recently come up
with this notion of an inner screen hypothesis which a lot of my colleagues are quite excited about And subscribe to
which is exactly uh well first of all let me just qualify why this is a
Quantum uh approach it is not that the Consciousness emerges at the level of uh
very small quantum physics it's the fact that you could understand anything from
the point of view of quantum information Theory and um a particular aspect that Chris and
colleagues focus on is the notion of a holographic screen that allows two
systems to couple to each other so the bulk of one system reading and writing of the holographic screen under
holographic principle in tandem with and with shared Quantum
reference frames another system and if you now apply that kind of quantum information Theory to the hierarchical
structures we were talking about entailed by higher order thought Theory and one could
imagine would be endorsed by a minimum kind of partition under IIT then what
you have is this notion that there are lots and lots of inner screens in our brains which pay the role of holographic
screens from a classical point of view mark off blankets onto which you read and write classical information
all with a shared or common frame of reference Quantum frame of reference
and if you have that picture in mind you can start to ask the question well is
there a special one right deep inside and I mean literally deep deep in terms
of the deep learning notion of a hierarchical World model you find in machine learning but also literally deep
in the brain where the cells of origin that do this attentional modulation this mental action that we were talking about
celebrated by people like Mike markson's live and then you arrive at a notion of
a an irreducible um set of internal neuronal States whose
Markov blanket or inner screen can never be if you like
um can't be reduced any further and it may be that this is a good model for
um the uh the unique aspects of Consciousness unitary aspects of
Consciousness that are celebrated in the IIT axioms and in a sense this is a you
know a resurrection of the Cartesian theater it's all neocartesian ISM of a
very bold sword uh that is literally reintroducing the notion of screens but
in a very nuanced way that actually is very consistent with the physics of self-organization
um because it all rests upon a free energy principle or a Quantum version of
the free energy principle where you're reading the holographic screens as Markov blankets but now on the inside of
a hierarchical or I a partitionable generative model
is that the same thing as subjective experience yeah
um I'm not sure that it it that you would be the the people who are
exploring this as a sort of minimal model that um gracefully accommodates things like
higher order thought Theory Global neural workspace and a number of other Affairs would be quite so adventurous to
say at this stage yes this is what um this explains quality of experience and
subjective experience that I think they would argue this would be a minimal requirement in the same spirit that I
was arguing previously that to be um to be a self is to be an agent and to
be an agent is to act and to act is to have a gelatin model that entails and
can generate the consequences of action um so um I think that most people would say
that the the sort of um sentience of a non-basic or trivial
sword um would certainly require this kind of mental action that is ensues from having
um an inner screen that can never can only see the consequences of its own
action by acting on screens that are lower down or more superficial in the
hierarchy and that's simply because there are no screens with inside this minimum minimal
um uh Markov bracket or bulk so a lot of this does rest upon action
mental action which I repeat you can read as attention if you like it's you know or um you know a mental action and
then if you read it along those lines you can then um relate it to
Notions pursued by people like Thomas metzinger and
Limon ski where you can render things phenomenally
transfer opaque by this kind of mental action
um so there is I think quite a nice story that could be built upon this notion of an inner screen that is open
to the rest of the brain and therefore is acting upon engaging with the rest of the brain in a particular kind of way
that looks like mental action and attention that enables things to become
phenomenally opaque and this would be a prerequisite for uh for sanctions of a
certain sort so I think there's a story to be told that I'm not sure that that story is being put together convincingly
in the philosophical literature but you know it may well be um it may well be a direction of travel
over over the next few years the next the next few years okay
Can you discuss the potential limitations or challenges of your theory and areas where further research is needed? Can you criticize your own theory?
um can you discuss the potential limitations or challenges of your theory and area where further research which is
needed so criticize your own Theory girl right
excuse me um well the first thing to do is to know that the free energy principle is a
principle so it's not really there to be criticized or falsified it's a it's a
little bit like um Hamilton's principle of least action you can you can apply it or or not depending upon uh what you'd like to do
so it is in the application to various things that that the challenges actually
arise and that's where the heavy lifting starts um and generally that reduces to
specifying the world model the generative model that is necessary to define the free
energy and that's I think where the challenges are if you want to look at
those challenges through the lens of say a psychologist or a neuroscientist or an artificial intelligence researcher then
you'll be asking what are the process theories um that
um under this kind of generative model would best account for the empirical evidence that best experience how this
grade works or this artificial intelligence works and um you know what alternative there is
um and what are alternative message passing schemes that would emulate the
Dynamics that would ensue when applying the free energy principle so that that
largely is a very sort of um inelegant summary of my my day job is
basically trying to work out your Anatomy functional architectures physiology in a way that I can
understand uh my brain and the brain of my experimental subjects in terms of an
application of the free energy principle to a generative model of a particular sort the question is what is that
generative model and that's most of what people are doing brain Imaging and psychology and and neuropsychology and
electrophysiology are trying to understand this you know how how does the brain work my understanding this
structure um in terms of the outstanding challenges if you wanted to build a
brain or you wanting to build um artificial intelligence that was more like natural intelligence sort of
biomimetic or generalized artificial intelligence then I think the challenges here are first of all again identifying
the right generative model um and it's um uh and the um the attributes of those
generative models that speak to the scale invariant aspects that you know one would associate with your brain
we've talked a lot about hierarchical gentle models but there are certain things that are conserved As you move up
the scales um other things are not so um one characteristic of these genitive
models is that as you move to a hierarchical world models As you move to
deeper levels things slow down so you've got a separation of Temple scales so
that would be one challenge in terms of um incorporating more and more temporal
scales into geritive modeling or into the generative models but you can then
apply the free energy principle to so if you can build if you can write down either in computed software or just in
narrative form if you can write down a generative model everything else is sorted you know we the 300 principle
provides you with the tools and the methods to compute what would happen if you let this generative model explain
its World in exactly the same way that Hamilton's principle of least action would allow you to compute the
trajectory of a ball if you supplied the specification of the ball so if you can
supply the specification of the generative model job done the problem is getting the getting the generative model
right and that and that is not there's not that is not easy you know um and one could indeed say that um
this is a challenge faced not just by life scientists in a particular neuroscientist but it's also a challenge
um faced by Machine learning and the artificial intelligence Community a challenge that's made particularly more
acute when you realize that the kind of generative models that are requisite for
surviving and modeling um our current worlds would have to
acknowledge the fact that our worlds are largely comprised of other things like us so it's not just getting my
generative model right it's getting my gelatin model of your generative model right and getting our journey model
right and the communication between them so taking again a sort of biometric
perspective um what we're talking about is not just finding the right kind of genetic models
but also understanding how they function the implicit active inference and
learning processes um that ensue when you put lots of these
artifacts or or systems together and how that fits into sort of
ecosystems of shared intelligence and shared federating inference and Federated learning so that's that's an
outstanding challenge at the moment um another outstanding challenge is is
being able to simulate what evolution has done when you view Evolution as
another free energy minimizing process and I mean that technically in the sense that when you use free energy as a
measure of the marginal likelihood you you are in a position then to select
certain hypotheses models or phenotypes using Bayesian model selection and if you look at Natural Selection as
basically Nature's way of doing Bayesian model selection then you can read natural selection as the use of
um Bayesian model selection based upon variational approximations to model
evidence namely the variation for reality G to do structure learning so by structural learning I mean selecting the
right kinds of structures automatically so that's still a largely
um unsolved problem in statistics and in machine learning and it's a really
important problem so you know if you have the right structure we now know the
maths that would be required to run that structure in active inference for
example um and deploy it on robots and also generalize the notion of free energy
minimization to the parameters so you're learning the contingencies and the the
connectivity um but what we don't know is how to build the right structures
so the structure learning I think is a really important issue there right I do want to talk about machine
learning and artificial intelligence but if in one sec I need to get the Sun out of my face here so give me one second
I think this is this is better all right that's yeah yeah so I do want to talk about
artificial intelligence you must know at least something about it giving computational modeling and all that
Given the complexity of the brain and the Free Energy Principle, do you believe it's feasible to create a truly 'conscious' machine intelligence, or are there unique aspects of biological systems that can't be replicated in artificial constructs?
given the complexity of the brain and the free energy principle do you believe it's feasible to create a
truly conscious machine intelligence and
I'm putting kindness between what because it's available whether you can
even measure it you can have a perfect pragmatic answer or fulfill esophageal answer or are there any
unique aspects of biological systems it can be replicated artificial
constructs um I think in principle um provided one as soon as this notion
of biomimetic artificial intelligence then I've seen a reason why ultimately one
could not produce conscious artifacts of the kind that it would not be possible
to differentiate um we wouldn't know whether there were conscious or not and so I I'm gonna I'm
gonna appeal to your option of giving you a pragmatic answer
um yeah so if if if Consciousness
um is just like everything else um a hypothesis that provides a simple
explanation for all my sense making um then one has to ask where does it
come from on the one hand and on the other hand acknowledge it is just a hypothesis that explains my uh my
Sensations so I just want to pursue both lines because they both have implications in terms of answering your answering your question the first line
is this notion that selfhood um is just a hypothesis it's not
necessary to live um yeah one can imagine viruses um quite happily getting through being
very very successful in their life without self-awareness and self-consciousness so why why do we need
why do certain things act as if they were um self uh they had a um they had a
certain self model and awareness and one obvious answer of course is that if our
world is populated by things like me then I need to be able to differentiate
who the um disambiguate the causes of certain
things when both you and I can cause them for example speaking um if we're having if we're really
um in a state of generalized synchrony and we're riffing together
basically we're seeing from the same hymn sheet and if we're singing from the same hymn sheet I need to infer did you
say that or did I say that and furthermore whose turn is it to talk and whose turn is it to listen and I can
only do that if I actually have a notion oh it's me as opposed to you and indeed
if you think about the problems faced by a very small baby just being born into the world
um it's going to take some time for this baby to grow and learn a world model or
a generative model that confirms the hypothesis that Mum is
actually separate from the baby the mum is a thing in her own right
and it is plausible that having established that Mum is a creature in
her own right and something that is separate from me that I may have another
hypothesis that perhaps I am something that's separate from mum and the rest of the world so
you know having a notion that others exist and then or perhaps I am like that
maybe one route to um selfhood that inherits from really
important addict interactions that are purely encultured but are not your unnecessary part of this biomagnetic
kind of structure learning um and of course that argument goes through to all levels of communication
and uh and culturalism and community and you know the acquisition of language and
shared narratives and so on and so forth and all of which rest upon the notion
that I um share a belief a world model a set of
norms a narrative frame of reference a common ground with you
so that may be why certain things um have selfhood and other things don't
in the sense that you know to be a virus I don't need to talk to other other viruses I just need to be able to
operate within my milia which is usually inside of a host cell that I'm infecting
so that may be one one reason why certain things um are conscious in your in the sense of
being self-aware um the second theme though is that I have
generated this hypothesis and I have confirmed it that
um but it remains just a hypothesis so Consciousness is just like anything else it's just a fantasy
um which means that I will never know whether I'm conscious or and especially
I will certainly never know whether you're conscious so the whole point of having these uh these partitions these
Markov blankets um that Define things is and to be able
to read the Markov blanket um under the holographic principle is that you can never get inside you can
only see what's on the surface so I will never know what's going on inside your head and I will never know whether you
are actually sense making or whether um the or my description of your
neuronal Dynamics as basal inference and active inference is actually true I will
just never know that all I can do is gather evidence from your behavior and from what you say so if that's the case
then it certainly is plausible that one could build machines that behave sufficiently similar to you for me to
imbue them with consciousness so Consciousness it only lives in the head
of the person making the inference um that you are conscious or I am conscious it doesn't actually live in
the head of the machine so on that pragmatic answer I would say yes there's nothing to stop me building a machine
that would have all the characteristics of uh Consciousness to do that I'm going to have to be very much more by net
biomimetic also just notice that there's a principle reason why it would have the machine would have
to look like me and would have to have the same epistemic affordances or
respond to the same epistemic affordances that I do in order to be conscious in order for me to imbue you
as Consciousness you have to be sufficiently like me and to be sufficiently like me
um I have to um well to infer that you are sufficiently like me I have to be curious about you to find out inferring
from the way you dress the way you talk um um Gathering evidence that you are sufficiently like me before I can endow
you with the note with with the attribute of being conscious like me
um that means that holds for an intelligent art about so the intelligent artifact will have to want to be like
you and not only that it will have to be curious about you uh otherwise you will
never um and it will never um you have the capacity for
Consciousness if Consciousness is an attribute of sense making in this sort of Federated context so I think it's
quite important because you that means you can't build artificial intelligence that is conscious
unless it looks and feels almost identical to you
Could the responses we get from generative AI be considered a query to us? Could it be seen as a dialogue?
but on one level there's one thing that I had an interview Michael Levin
is a synthetic biologist I'm not sure if you're familiar with him but he said
something that reminds me what you said reminds me of that and it was again I'm
paraphrasing um that and very interesting thing happens when you give a prompt to for
example chat gbt and we think we're we are giving it prompts and we are asking
things but it gives us a result back but you can also look at the result you get back as a prompt to us
so uh good to be good good the result we ask for actually be an inquiry because
um with these generative models they you give you give a prompt and then you get a certain result and then you then you
tweak it you get some extra prompts until you get what you want but actually what he's saying is it could be
considered as kind of a dialogue if I'm understanding him correctly
yes you know I I know Mike very well uh so he he was a co-author on uh that Quantum information treatment of uh of
the theology principle um and um yeah that that's that's again a sort
of brilliant thought experiment I think now you're a lot of people are putting these large language models together so
they can talk to each other which is exactly what we were talking about before in terms of uh babies talking to
their mothers or me talking to you um so I I think that is um that that
thought experiment is very prescient um and begs the question whether these
generative AIS specifically large language models and notice that it's not
gerited models that create pictures or code
that pink Alaska is this is going to be a conscious artifact or not it's just as
a generative AI systems that generate the language that
um invite these questions and I think that's really important because remember before I was trying to um paint a
picture in which Consciousness is can only emerge in the context of uh living
in the universe comprising lots of con specific creatures like me that um that
I can assume have the same kind of generative model or common ground that I
do that enable communication there can be no communication without this common ground
and the specific thing about large language models is that they do
communicate in language so AI generative AI produces pictures
does not communicate in the language and you were not confuse the journey AI
producing very realistic photographs with a conscious artifact and you could
easily confuse a large language model generating a conversation and actually
engaging a conversation with a large language model you could easily start to imbue it with Consciousness
simply because it's behaving as it was another agent that's very much like me
using my language because that's what it's designed to do it's great all the
data of communication in order to reproduce as if it was having a
conversation it was communicating not in pixels not in code not in music but in
words and I think that's what gives it the um the potential to give the
illusion of Consciousness and I say illusion um cautiously and advisably
um because to actually have a generative model under the hood would be for me a
prerequisite to actually have a you know a true inference uh process and there
are certain arguments about whether um you can look at large language models
um as possessing a true geritance or World model or whether they're um
they're just detecting statistical regularities and the sequences of words that have been produced and can
therefore re reproduce these particular sequences so it's a very vexed issue but
perhaps tangential to Mike Mike's point that you know if you've got something that can talk to you and sounds like you
even if it doesn't look and feel like you it certainly will sound and feel like you then it now has the um the
potential to become something that you could infer was conscious and on that
definitely that's as that's as far as you can ever go in my world anyway simply because you'll never know because
you're always living on the inside of your head get it I get it harking back to what you
said earlier about babies trying to realize or learn that their mother is separate from them makes me
think about I don't know who said that but basically there is not really a way for
a brain to tell that the input that is coming from me like your brain cannot actually tell
that the input is coming from me because the input that is coming from me to you goes through your neurons and they don't
the neurons itself obviously do not cannot make a distinction that that's anyway that just popped in my mind so
but do you often work with general knowledge yourself when you in your work lately because this this whole large
How much do you keep up with the current developments in generative AI?
language thing has blown up and I find it hard to keep track of it because it's it's going so fast it's so exciting
exhilarating I was wondering how much you keep do you keep up with it but I I don't keep up with the
literature or the developments as you say in the past 100 or now especially 200 days it's it's been an absolute uh
absolutely amazing and having said that I do work with generative models all the time at many levels because we are all
generative models so working with my students uh and I used to see patients uh patients I'm working with uh
biological generative models but um yeah seriously certainly most of my academic
um uh theoretical work is basically um exploring and deploying generative
models usually in silico to try and understand you know the mechanics of
um or this Bayesian mechanics and you know the fundaments of active inference
um so yeah yeah I work all all the time with generative models it's not quite the same as generative AI though it's
just interesting that um that generative AI has now come to be
known as you know things like large language models that generate stuff when
people talk about generative models in statistics and in theoretical biology they mean something much closer to the
notion of a world a model in machine learning that there's actually a structure under the hood that's gathering information making inferences
about States and Affairs and then planning what to do next um so most generative AI doesn't do that
but the kind of genital models I work with usually purely in Academia in order
to reproduce psychological or decision theoretic behaviors that would help us
understand how the brain works and in particular how that those mechanisms
could fail in certain neurological and psychiatric conditions yeah that I spend most of my life building one kind of
gelatin model or another in Matlab like Jeff Hinton I only use Matlab like like
Jeff Hinton does so so I'm very old school I have I haven't learned python or Julia yet
oh I'm I just dabbled in in programming and it was a long time ago so I have I
What do you consider true general AI intelligence?
have a question from let me see how fast my laptop is I'm not sure if you if you can see it uh
curl do you see a question on screen girl no I'm just gonna do you see a question
I do see a question yeah and it's saying um you know what what would you consider
to be true General um artificial intelligence uh yeah other than the ability to uh convince us that
it's mastered our language and uh ability to engage in dialogue
um I I think the answer to that um a game would appeal to
um this theme of biomimetic um aspects of artificial intelligence
um and how they are deployed um in terms of ecosystems of of it of
intelligence so um what I've been looking for is a kind of
um inference process and influencer learning process that first of all is
embodied in some way um and that has this capacity to act as
an agent so it has the capacity to actually choose various um to choose the data that it is going
to use as the basis of its inference and learning um and that's quite that's quite
important in the sense that it would require a move away from Big Data to Smart data
so just on the first principal account um this notion of
um acting in a way to maximize Information Gain means that you're looking uh you would ascribe the notion
of generalized intelligence be it natural or artificial to those systems
that can and that can find the smart data actively they can data mine in the
right kind of way so I've been looking at an intelligence at a system for evidence that it's
mining its data smartly and implicitly that it has a model of the consequence
of its own Mining and its own questioning its own querying its own
palpation its own exploration um its own epistemic foraging of the world and if it was doing that
um in a way that was um consistent with the free energy principle or active inference uh that I
think you're getting quite close to um General um artificial intelligence or
generalized AI I would I would imagine though that they're going to be other qualifications on this it has to work
inside you so it has to be part of an ecosystem as we were just talking about in relation to Consciousness for example
there is no point in having a super intelligence unless it's unless we are part of that ecosystem that is a super
intelligence so it has to be um has to be sympathetic and
self-evidizing in the context of everything with which it is exchanging so by definition it has to have a
certain compatibility uh and shared epistemic goals with everything that it
is exchanging with including me um so that would be another definite definition of
generalized AI thank you for asking your question Matt MVD that's a great question
um I think he has another one let me see
yeah on my end I don't see the question popping up on screen so my left is apparently lagging so much that uh you
somehow you see it soon in the night so you can just read the question yeah
What are your thoughts on the agency of AI and the possible danger therein?
essentially um so the question is um what I was saying would go beyond having
access to data towards willful and free selection of what data to access and
then there's a a question mark free will uh and he concludes or she concludes
with I suppose therein lies are danger so excellent yeah excellent assertion and excellent question so that that's
absolutely right that you know this notion of agency that underwrites the
engagement with the world the querying the data mining or whatever situation
um or whatever perspective you want to take on that is um does rest upon this notion of
selecting the right policy that that's going to get you the right kind of data for your subsequent inference and
learning and avoiding surprises so we're not just talking about sort of pure epistemic exploration here this is under
constraint so the free energy is um is not just the mutual information we
were talking about it's under constraints so it's trying to maximize literally the self-information in the
sense of maximizing entropy under constraints and just for the physicists
and the audience the prediction principle is dual to the constrained maximum entropy principle of genes the
constraints are important these are supplied by the generative model and it says that some things will be surprising
um but having said that um the the essence I think of generalized AI or general artificial
general intelligence um would be exactly this purposeful
selection of courses of action that expose you to the right kind of evidence
to allow you to understand and engage with your world um your in an efficient and uh
synchronous synchronous fashion and you could certainly cast the selection of
the action the epistemic policy or the exploitative policy
as either Bayesian model selection in a sort of mathematical sense or you could
say it is free selection in the spirit of either quantum
mechanics or indeed philosophy there is an active selection there when it comes
to exploring different hypotheses so I think that's that's really important to notice that just being an agent of the
kind that we've been talking about entails the selection of what to do next
under our models of the consequences of our actions that necessarily implies a
certain degree of autonomy um and that you could describe as willed Behavior it's certainly purposeful its
purpose is to minimize your expected to create energy or expected surprise in the ways that we've described but to do
that you have to select Which Way Forward you're going to go and then the question at the end was is that a danger
and I mean
important question um you're strictly speaking from my point of view
the attribute danger doesn't really get into the game because we're talking about self-organization of systems
um open systems far from equilibrium and if
something um persists in characteristic States for a sufficient amount of time
um then it exists and can be described as engaging in these free energy minimizing processes so what would be
dangerous for any of these things or when it disappeared when it died it dissipated decayed when it no longer
maintained the Integrity of its individuation technically the Markov blanket that separates it from
everything else so could it be the case that one thing causes me to dissipate
um and therefore um causes me to go away and would be a danger to me I mean technically it
certainly is possible and you know you can think of speciation at an evolution time scale
um as as we're seeing that but the you know the whole point of the free energy principle is um to describe systems that
actually conspire together to maintain themselves in a in a
non-equilibrium steady state so it's really a description of systems that are
self-sustaining self-assembling Auto poetic in some uh
in some Elemental sense so if you've got generalized AI
that is minimizing um its expected free energy
which is not optimizing a cost of minimizing a cost function or maximizing
a value function the the only function that matters is the um is the evidence or the marginal
likelihood or it's expected um bounds for conditioned upon action if
it's doing that then that is a description of a system that will actually self-organized to a
steady state that just is a description of systems that are mutually sustainable
um so in that sense there can be no danger by definition but to get to that
kind to to elude that kind of danger you have to commit to or assume that
um the artificial intelligence is actually trying to minimize this it's um
minimizes its uh bound on um this uh on surprise self-information and
information Theory or equivalently that it genuinely is trying to self-evidence it's trying to gather evidence for its
own existence um and it's uh and its uh existence is
entails a model of its world and if its World includes you then it's trying to
gather evidence about you it's trying to understand you and therefore should never represent a danger to you in
principle because the whole point is that you are trying to co-construct an ecosystem that is sustainable so this is
the fundamental distinction between um you know optimization as growth for
example say maximizing profit um as opposed to optimization as a
description of um of self-organization and self-assemblance and self-evidencing uh
which is it certainly can be cast as an optimization problem but the thing you're optimizing is very specific and
it is exactly the thing that describes self-sustaining self-assembling and
self-caring and synchronous kinds of uh individuated artifacts
interesting there um it sounds like you're kind of instead of being worried about the future you
seem kind of optimistic about it yes well I I get it quite old now so I
don't have to worry about as much future as you have to worry about that's it that's a very good point I like that no
but generally speaking you do not seem too worried about this whole deal there are a lot of people that have very
strong opinions about this I I don't see it reflected in your words am I am I correct in that
I think you're absolutely right I mean part of that is the fact that I I don't have an informed position I think that
the angst you're seeing for example currently with um um
generative Ai and artificial intelligence at the moment is probably a reflection of a greater angst about sort
of globalization and climate change and uh your walls around around the world
um so um you know I certainly have angst about the you know man's inhumanity to man
I don't think that that kind of emerges from my theoretical considerations so I
have a much more utopian view of self-organization a much more dispassionate
um view that you could read as optimistic in the long in the long term uh but I'm not denying all our dystopian
worries but I don't think they're particularly um if you like unique two or are owned
by um artificial intelligence I think I think I think you can look at any look
at that kind of angst uh of any direction of the politician as a citizen as a
theologian as a psychiatrist as a doctor
you'd still get the same kinds of words yeah I don't I hear a lot of
as I said stronger beings about The Angst or speaking you're talking about about artificial intelligence and the
future and I do have some concerns but not because I think it's about
Consciousness or anything like that just but because it's not biological
and we're mimicking something we're shaping it by our own biological drives
and needs on a system that isn't that is by definition not biological and has no
drives so that is by far Maybe for me personally the thing that is okay
this is dangerous because we have absolutely in that sense no idea what we're doing it's not wrong I'm not
saying we should stop doing it but daring lies for me the the the danger
yeah I think it's a very Street observation it resonates with my repeated use of the word biometric so
you know my basic answer what is true artificial general and generalized AI it's that which is biometric so it's
interesting that you point out that the moment we're actually going away we're going the opposite direction it travels
you know billions of parameters Big Data uh you know exactly the opposite
direction to the way that you and I make sense of smart data so I think there's probably going to be a U-turn in in
artificial uh intelligence research um and you know you see this at a number
of fronts you know the concerned about potential neuromorphic Computing for example um a return to uh a move from Big Data
to Smart data excitement you can get a large language model working on your iPhone I think that you know people
would come increasingly aware that to do artificial intelligence properly is just
to do natural intelligence to do natural intelligence means you have to commit to a biometric approach
um which I think will actually you know Larry paint will you know will pull the
direction traveled towards the kind of um self-organizing intelligent artifacts
uh that probably will look a lot more like Edge Computing in distributed ecosystems that we were just talking
about um interesting girl
but again you see you seem optimistic I like that I like this this approach so
If you could ask a fully conscious (super) AI a question, what would it be and why?
um if there if there would be a truly conscious artificial computer today
um and not the large language models that are generated like now because it's still there are still toys but assuming
we have fully grown artificial conscious intelligence which I find personally hard to believe but just hypothetically
what would she ask it and why would you ask it yeah
that's a great question which I don't have a pre-prepared answer to um but that was perfect
I was um just thinking you know if if it is just pursuing our line of argument
that you know to be intelligent is to be like me um and to be like you
um the questions I would ask it are exactly the questions that we are
exchanging at the moment you know though you know this this is this this kind of interview and this kind of show
I think is the Pinnacle of The Human Condition this epistemic foraging this
um this desire to resolve uncertainty about the kind of world that we are not only living in but also co-constructing
and we're doing it through communication so I would ask the same questions that you just asked me
and probably I would be asking myself and I do so in my everyday in my everyday uh work simply because those
are the questions that I would ask any intelligent person it's the intelligent questions that you've been at you've
been asking so there's no magic there's no it's not going to be 42 I'm afraid
that's gonna yeah and there's going to be no secret that this super
intelligence come ever disclose to you and me because by definition because it is so
intelligent it is the same exactly the same kind of intelligence that you and I share so all that we need to know is to
what extent do we share a world view a world model a reference frame and Common
Ground so those are the questions so the first questions I would ask are those to establish whether it's actually
sufficiently like me to engage in conversation and if it is yeah because if it's super intelligent enough then
well it either has to dumb down the conversation just for us to understand it or its answers will be just
indecisable for us because we're you you mentioned super intelligence and I'm
thinking okay if there's a super intelligence something which is practically god let's say then then I
would have some questions of course and I wouldn't probably wouldn't ask the same questions I would ask Carl because
I know Carl is not it's very very very intelligent and wise man but he's probably not a super intelligence
yes that's a very good point and so just to qualify what I'm about to say some
people use super intelligence as the to refer to the kind of emergent intelligent-like Behavior you see
um in lots of organisms that are communicating like sort of anti-colonism the like so it's an emergent aspect but
I think that what we're talking about now is something that is more intelligent than uh than me and you and
and of course um I have to ask myself what do we mean by intelligence um it probably relates to the complexity
of the generative models that we've been talking about so a world model that can assimilate and predict
um much more of the universe than we can that has a broader view of things so as you say something that has a more of a
God's eye view or as a godhead um that can see the Dark Side of the Moon and knows what it's like to be in
the middle of the of the Sun or knows what it's like life is like on other planets so this would just be a very big
geratin model that had more access to more kinds of data
and the question is though if it had a sufficiently different genitive model
that did not include our little world and the problem is it would not be able to talk to us because there wouldn't be
any shared frames of reference so there would be no question and answers you'd
only I think be able to talk to this kind of god-like super intelligence If
part of its generative model included our lived world and those beliefs that
pertain to our live world could be deployed in order to describe other
worlds that we that we do not have direct access to so yeah there'll be a
lot of strong requirements on this super intelligence that again speak to its um
consilience and sympathy and synchronization with us again saying
that your intelligence in and of itself is not an attribute that is not relational you know something is only
intelligent in relation to the thing that it is exchanging with so the intelligence is a relational notion just
in the same way there I think Consciousness probably is a relational notion um it's just that self-consciousness is
relating to myself or in a screens Within Myself um and I think probably intelligence is
the same so you know I'm just thinking about yeah you're absolutely right so if I could speak to
um somebody who has been who is more cultured than I am somebody who had lived in you know every continent there
was or indeed in Mars and I've seen every culture somebody uh you know had a
generative model that was able to explain more than my more limited gelatin model code
um then I would ask a question about where have you been what do you see what was it what was it like absolutely
that's what I think it's fine we we we're getting there at the end so perfect thank you I like this
answer I have some I have a question from someone else again my laptop is slow so if you see before I do you can
What are your thoughts on Donald Hoffman's theory of consciousness?
just read what it's what it says oh wait I can see it um DS Atkinson he asks um I'm late
coming in but would you mind asking him his thoughts on Donald Hoffman and his theories of Consciousness we have not
covered Donald Hoffman here yet um I'm not sure um how much Carl knows about this girl
I I yes I I was once called by Jerry Adelman an intellectual Thug which means
I know a lot but I don't know everything forgive me I have no philosophical
training so could you just summarize for me and and everybody else the main tenets of Donald Hoffman's position I I
have heard of him and I I've been asked this question before but just to make sure I've got the right well I'm not
going to do him justice so I'm gonna make it make it small he's a scientist
who has a theory about reality and that reality is subjective is it's not an
objective reality it's something we project and he has done simulations on a
computer proving that if you make species compete and one species has a as
I said objective view of reality and the other one has just what it needs to survive then the one that that has the
theory that just is enough to survive even if it's wrong it's actually especially when it's wrong this is the
one that will always outperform the other so his his idea is that or is his
notion is that in reality as we see it is most certainly wrong and he can his
claims that he can mathematically prove that and he's made a mathematical Theory and it is mathematically a pluralist
theory in a sense that he need at least two conscious agents to begin with but philosophically speaking he admits
that he is a monist and that's as an idealist that Consciousness is the
source of existence and everything particles and and energy and all that
kind of stuff is a projection from conscious agents like agreements between them not sorry I'm butchering your
theory but this is as far as I can briefly explain it well that was really useful
um and everything you said made perfect sense to me and I sort of
rap Bell so somebody's clearly jealous and try to explain it briefly uh in
previous conversation but um everything that I think sounds perfectly consistent you know this notion of
um having uh wrong models that are optimal in the sense of being sufficient
to um explain and predict our exchanges with the lived world is is to my mind
absolutely right it sounds very much like the notion of satisficing there's a whole
um theorizing uh um um where Simplicity or minimum
minimization complexity is the objective function and this inherits directly from
um the um the sort of information theoretic perspective that you get from the free energy principle in all its
carnations um uh and certainly would be the line um that somebody like Jurgen schmidtiver
would pursue them to compress is to have the best kind of model and that that
compression can be scored by the variational free energy and you will
find it in economics and you know in the sense of heuristics and satisficing
um of the kind promoted by gerd garenza um and you will find it in the in
machine learning and data science in the form of compression um so again you know only having that
stuff that you need everything else being redundant so your models have to be as simple as possible as a
statistician I think this was a really fundamental point because you know if you just write down the expression for
model evidence the marginal likelihood of your data given a particular model and you write down or decompose the log
logarithm of the evidence you can always express it as accuracy minus complexity
that means to do good self-evidencing to have high adaptive Fitness for example
just means to write an accurate account of your sensorium as simply as possible
by minimizing the complexity so it doesn't surprise me in the site is that when you simulate agents who have the
simple the right kind of simple model as Einstein said you know keep everything as simple as possible but no simpler so
there's a Goldilocks theme of Simplicity I'm dumbing down and that will always
outperform somebody who is um overfitting their world and having
very very accurate true models are certainly closer to the gerited process
um and you find that you know basic phenomena emerging everywhere not just
in data compression but in overfitting for example um in machine learning where they run to
things like sort of sharp Minima uh simply because they're overfitting the data they need to simplify things by
mini batching or blurring data for example so as a deep truism there which
means that all your models are wrong so it's absolutely right but they're the best models that's that's the important
thing if they've maximized the uh the evidence um the the the you talked about the
relational aspect and monism um and that um
physics is a construction I think most physicists would agree with that you know um you know physics is measurement
to measurement is inference and most of uh certainly sort of relational quantum
mechanics would would certainly say that you know um most of the things that we actually deal with are uh can only be described
in terms of observation and measurement I've just read um uh Carla raveli's uh
book Helga land which is beautiful that convinced me even more that everything is is as you as you put it relational or
uh uh certainly arising from triadic or dyadic interactions and measurement
Understanding information as the fundamental nature of reality, and why that is inherently metaphorical.
yeah I find that the theories that deal with information as a fundamental
a fundamental thing of nature or even the most fundamental thing I find them always hard to grasp and it's silly
because on the other hand I have no problem uh considering that Consciousness is fundamental and it all exists is consciousness and interactions
within Consciousness and that all particles and and stuff like that are manifestations implementation I have no
problem with that but when someone says you know reality is just information somehow it just doesn't click I see
numbers and I'm like okay how can reality be pure information yeah but I
mean that that's the message message throughout this and I mean you know Richard Feynman your energy is
information uh you're it from this you know wherever you look um
well certainly as I get older and I did physics um quantum physics and probability
Theory as a young man and I thought that was reality I thought Quantum you know that's the description of reality but as
I get older I I start to realize that even classical quantum physics or classical
mechanics Cisco mechanics quantum mechanics and even I think the Bayesian
mechanics of the free energy principle these are all just stories they're just stories that are part of my generative model that I've some some of my teachers
have shared with me um that that you'll have as much uh if you like
um veracity as my fantasies I am me or that you know or anything else that
characterizes my beliefs and explanations for the work for the um for the of of of my world
um so I know what you mean uh but I'm pretty sure it's right that your notion of an
atom and a particle have you ever seen an atom no no I used to think no I used to well
they they made beautiful pictures and drawings and animations but apparently
you kind of make a photograph because they're smaller than the waist length of light so light passes over it at least
that's a metaphor they gave me so I'm at the states that okay this is just useful metaphors nothing wrong with them but
they are metaphorical just like almost anything we describe in reality but that's just makes it easier for me to
think about these things they're useful models well absolutely I mean making it easy to think about them is exactly the
sort of you know the free energy minimizing process that we were talking about having those good fluid simple
models that make the most sense of everything that we encounter but just think about what you said you find it very difficult to think about a universe
that is composed just of information and numbers but much easier to think of it comparison atoms and yet you've never
actually seen an atom and even if you could you would be able to see it even worse fantasies at least you can
see a number so you know isn't it straight the way our brains compell us to try and find
these very simple um your intuitive uh good enough
sufficient stories to explain our world even physics and physics changes every year you know
there's no ground truth there it's you know it's uh no I I have well I I used to think that
there was an objective truth and then I didn't think there was an objective series and now I'm just I I don't know it's just I'm I'm getting pretty
agnostic the older I get so um but you're right the stories we tell
ourselves is uh is one of the most interesting things it's also the way how our language works it is metaphorical
everything almost everything is a story a theory is a story from beginning to
end that's just how it seems to work there are certain archetypes how these stories are are built and this is how we
understand it and it's just it blows around why this is apparently the only way that it works for us or maybe
that is what language is I don't know I'm just so
um someone else oh wait DSX had one other question it will be cool to ask
him about his opinion about UFOs well that's totally different direction but why not this isn't you can ask any
question here so Carl um there we go one question to another question no relationship but what do you
What do you think of UFOs or UAPs?
think of UFOs or uaps as they are cult nowadays
um I guess the the question is
um well I mean certainly if you know if you if there are what is on the tin then
they're just unidentified and surprising and unexplainable so they will certainly attract our attention
um under the French principle or if we're doing the right kind of um active inference if the implicit question is
you know is there other kind of intelligent life form elsewhere I think that you know
that that is an interesting question which again I am not I don't have an informed view on and my my sort of back
of an envelope um calculations just looking at the probability that
um we have co-evolved to a similar level of intelligence with allow you know you
mention it communication so the only way that would actually you know see a UFO is one way of communicating it's it's a
deontic cue it's a sign that there's something roughly at our side eyes and
you know it has the same kinds of physics of us that is around that can uh
to be in the same spatial location under my uh physics and stories of my world
um the probability of that happening I think is fantastically small so I'd be I would be extremely surprised if there
were if there was a lot if there were aliens um driving unit and identified flying
objects around the earth very very surprised simply because there are so many constraints that would render
um render the probability of that happening under my physics World model my my intuitive physics
um yeah there seem to be a lot of reasons why uh aliens well the time it takes to
travel the fact that you can go faster than light um the if it takes like I don't know 10 000
years to get here then by the time they get here maybe their civilization has died out and they forgot even forgot why
they got here in the first place and maybe alien life is so different than us that simply are not able to see it and
then they are not able to see us in the list goes on so there's there are enough reasons I I kind of agree there it seems
like a slim chance the fact that they might exist sure but why not it seems awfully possible that they exist but so
it actually answered this DS Atkinson I have another question
um let me see if that that's the right one mad MPD asked makes me really wonder what happens to the energy within us
What happens to the energy within us after death, to where does it dissipate (where does consciousness go)?
upon death to where does it dissipate what form must it take and the age-old question where does Consciousness go
after we die right so again sorry we're just picking
your brain on all kinds of things one want to know how your brain works how things think about things so
right so um so from a point of view of the sort of physics of self-organization I mean
death is um you know a really interesting um phenomena in the sense it is exactly
a failure of this maintenance of this individuation of the thing from
everything else um and you know certainly using the word dissipators I think very very
interesting you could have used a word Decay or dissolve all of these words basically reflect that there is a loss
of the Integrity of the Markov blanket or the separation of you as a living
thing from the rest of your world so um you know I'm just picking up on the
use of the word dissipate here um it is I think possibly
um inevitable of all self-organizing processes because this this kind of
um process of self-assembly um and sustainability into an attracting
set cannot uh has to be if you like um reproduced over increasing time
scales which means that there is always a time scale where things die very very
quickly from your point of view and there's always a time scale above where things last for an eternity from your
point of view so for example um for me as a body
um a lot of my cells actually die very very frequently and indeed when I ever I
cut my hair um I'm discarding some part of my body that has died and that will dissipate
um that would be looking at a you know at things at a smaller faster time scale that indeed could actually constitute me
at my time scale but also there's a time scale at say evolutionary time scale or
cosmological time scale that is much longer so if I am me and my con specifics I could endure for or
thousands of if not millions of generations but each at each level there
will be an Inception and a dissipation um that is just part of this nested
um uh kind of self-organization that can be described as self as if you like
self-evidencing or free energy minimization just in virtue of this
um existence of solutions to certain states of being that is expressed again and
again in this nested way over over different time scales and where does the energy go
um that speaks the notion of conservation of energy but what I've just described is something that is not
conserved when it dies and so I prefer to think of this as
um from interpreting energy really and purely in terms of information and the
processes the information processing that is entailed by sense making and by
living and so in many respects um you don't have to worry about
thermodynamic energy it is the energetic processes read as
making senseless perception and active sensing that as the expression of the uh
if you like the informational aspects of um of of of the energy and just being
and possibly even being conscious is probably um best thought of as a process that
could be read as consuming energy and when that energy is no longer consumed
that is when you die um but of course in your death death there will also be other things will be
reborn from your death um either at an evolutionary time scale or indeed in terms of
um your what's happens to your to your atoms I'm sort of wandering away from
the question now because I I'm not sure what kind of energy that we would we were talking about and I would read
energy really as um I repeat a potential
literally as like a voltage um where that potential is always red as
a log probability which brings us right back to the notion of information which
means that you're in a very simple sense energy and information are the same thing but things are processes and that
means it's the way that we handle energy and handle information which defines us and in a sense death is the cessation of
that kind of processing thank you all right another one which is
people are asking questions finally guys this is what I this is why I'm using stream yard so you guys can ask
questions um so a question from I'm not sure how to pronounce it
seriously cheat I think you talk about choosing free energy to explore future consequences but what about reflecting
You talk about using free energy to explore future consequences, but what about reflecting on past actions?
on past actions I see self-reflectivity as a key characteristic of general intelligence personally yep I I I'd
agree entirely um so that notion of um introspection and
um self-reflection and indeed reflecting on past actions
um is speaks very much to what I was what we were talking about previously in terms of the the essential role of
memory um and uh and planning and memory in
planning and one aspect of um that planning is that one can improve
one's World models one's internal models or generative models by effectively
rehearsing what has happened to you and maximizing the efficiency of those
models but interestingly usually involves a not an increase in the
accuracy because whilst you're reflecting or introspecting there's no more data that you're trying to
assimilate so that you there is no notion that you're trying to maintain
the accuracy of your expressions of data because there are no data however if you
remember we were just saying before the log evidence which the free energy approximates or bounds is equal to
accuracy minus complexity this means you can still self-evidence by minimizing
the complexity of your morals and um one way of doing that is basically to
resolve do house cleaning if you like and remove redundant aspects of Your
World models during periods of interception and some people also argue
um during sleep as well during dreaming for example that these are excellent opportunities to continue self-evidising
in your head by looking for associations by resolving uh or eliminating redundant
parameters of your generative model that would otherwise rendered them too complicated and with a tendency to
overfit so one picture of this is uh Julia it's an owner's picture for
example of uh synaptic homeostasis that we spend our entire working day ratting
through life building up all sorts of associations in terms of brain connections or synaptic Connections in
the brain um and then we have quiet Amendments of interception of introspection uh
possibly um mindfulness and certainly sleep during
which we can revisit all those associations and
remove all the unnecessary and incidental associations in terms of
synaptic Connections in the brain so that we wake up the following morning or
in a refreshed way with a slightly simple explanation uh that has stood the test of time as it were so I think
that's absolutely crucial and you see that empirically in those sorts of contextual
um even little mice running around mazes will emit
um signals from their brains suggesting that they're actually replaying and rehearsing what they're going to do and
what they have just done in order to consolidate and to install the right
simple kinds of gelatin models in the head that are apt for navigating this particular situation
thank you thank you girl um what are your thoughts on ndes
What are your thoughts on near death experiences (NDEs)?
near-death experiences I said nothing to do with your field still curious
their death experiences exactly right I've never had one but it
it I had a friend who really wanted to ask you that question right
I mean these um often associated with Altered States Of Consciousness
um and they um I think that they're terribly
um informative and presumably if you've ever experienced them um can be quite life-changing and indeed
one might imagine that the the experience of these Altered States Of Consciousness are sometimes the
aspirational goal of certain um meditative practices or mindfulness practices and indeed some uh therapeutic
applications that engage the um the sense making systems that we were
talking about before in relation to mental action and attention so from my perspective
um the um you know a typical near-death experience and out-of-body experience
for example the might be characterized by seeing yourself you leave your body
or you might um see
um a um a particular sort of photic stimulus
a bright light for example um so these are sort of characteristic
experiences that are reported by people who have um had near-death um experiences and
they all speak to I think um you know a very important aspect of our sense
making first of all they do reveal how fragile our fantasies and our hypotheses
are so if you take psychedelic drugs for example that act upon exactly the same
mechanisms that may be um engaged during their death
expenses either physiologically or non-physiologically depending on the kind of trauma that was inside of an
in-depth experience um that you you will you will experience how fragile our sense making can be in
terms of simple Notions like uh time is Flowing or um you know sounds are
actually seen as opposed to heard um or that um you know my body is all
joined up and doesn't fly around for example or that I live inside my body uh
usually just behind the eyes all of these are as fantastic Notions uh as
Jackson notion of an atom which is never actually seen so quickly dissolved
um I am me I'm a person you know these are very very fragile hypotheses that
can easily be um if you like uh removed either in
certain psycho um psychopathological conditions or psychiatric conditions or by taking drugs or by
um trauma um that is um experienced uh you know unfortunately by some people normally
what they involve with uh is um involved is um this um
aberrant selection of evidence for sense making at various
levels in these hierarchical models and biologically what that looks like is a a
failure of or um an aberrant function of something called neuromodulation now
neuromodulation just means modulating the excitability of neurons brain cells
that communicate messages that cause this belief updating and sense making uh
passing messages from one level of the hierarchy to the next level of the hierarchy and it's very important which messages you pass
both upwards in terms of the prediction errors and downwards to provide context
and constraints in the form of predictions for sense making at the level below and one way in which you
select these it is thought is to um it enables certain
um uh ascending messages that are sent deep into the hierarchy through these gain mechanisms either read as
intentional gain or postsynaptic gain if you're an electrophysiologist that are mediated by certain neurotransmitters
and interestingly it's the transmitters that are affected the transmitters that
are affected by psychedelics and by psychotropics and most drugs using
neurology and Psychiatry these drugs act exactly upon these neuromodulatory mechanisms so
um I would imagine that most near-death experiences fall into this class of Altered States of sense making where
there are no constraints on or you are dissolving certain deep constraints by
removing through a bare neuromodulation um
moving the constraints on certain kinds of sense making at particular levels in
a hierarchical model which enable you now to experience the world in a very very different way I do repeat though
that this is sometimes a therapeutic objective um you know imagine that you
um for example were very depressed and had built a model of your world in
which you know anything you did was we met by rejection or hostility or
potential uh you know egoistonic responses and the best thing is just to
stay in bed and and do nothing and the problem with these kinds of world models
is that they preclude you going and searching evidence that challenges that
model and that hypothesis so the very factual disengaging socially in terms of interpersonal genetic
interactions means you can never test the hypothesis that everyone is going to be nasty to me
which means that there's no challenge so these if you like self-assembling
malignant hypotheses sometimes you want to actually Challenge and resolve and
one way of doing that is to um Target these neuromodulatory mechanisms
either by using drugs or by um engaging in certain attentional
practices so you you become skilled at actually activating and deactivating these modulation systems to allow
yourself to explore other ways of being other hypotheses about your interaction
with the world um and I'm thinking here about meditation practices internal attention States mindfulness practices some with
or without the use of psychedelics to to augment that and they can be very powerful these uh these modulatory
modulatory drugs I don't know if that helps I haven't had a near-death experience so I can't speak no no no it
wasn't my it was a question from for someone else so I can speak for them but I hope it was it was helpful to them uh
Some thoughts on out-of-body experiences (OBEs) and the fragility of experiential concepts.
you said something that interests me though that there are some things that
you find much more interesting or at least as much as interesting like uh I'm in my body and
um there are a couple there were a couple you mentioned anyway one I I like to I
love to read one book by Oliver's sex I think he's called s-a-c-k-s and he had some stories about
patients and I think one of those stories was uh about someone who was
dislocated from their body like a couple of centimeters to the back and then a
couple of centimeters up so they were always looking looking somewhat down on their body and
and when so when they had to you know when they had to grab something they they always missed so they had to
purposefully relocate their hand in a very awkward way to magically somehow grab the cup
they want want to want to get and there was always also a case by of a patient
who had who was stuck on the ceiling and was looking back upon themselves and
while they tested it obviously by writing someone something on a paper and
putting in putting it with the letters upwards towards the ceiling and ask ask
the patient if you could read it and obviously he couldn't or he made something up but it was very convincing
that that's the first thing I think about when um when I think about near-death experience or no no Out of
Body Experience yeah but I would like to maybe there will be a pill or a drug or
something that I could try that for like 20 minutes that would be so cool just for 20 minutes just be just be on the
ceiling how that feels or not be in my body it will be I think it would be very
interesting experience so you should you should invite um Mark
soles um to talk to you I don't know if you've cut
it how do you spell his last name so s-o-l-m-s mark his his world expert on
um what's called neuropsychoanalysis um which is basically a mixture of neuropsychology brain lesion experiments
and clinical treatment um in neurology and psychoanalysis and
is also one of the world's experts on uh Freud and Neo Freudian thinking
um but he he you know he has some really great ideas about Consciousness but also
has lots of patients of the kind uh that you've just described for example so
fascinating yeah it really is you should you should get a monetary you know one of his um Amy Dorman is one of his
colleagues and she has a a patient or not as a patient just you know somebody
um that um she uh she investigates whose visual system is just reversed so she
sees everything wow when you see her from left to right right she
sees it as going from right to left and she has to compensate and only realize this when she went to University and
started actually talking about the direction in which things moved or so and really fascinating how how easily
our geometric our perspective taking models can go wrong with certain kinds
of you know aberrant neurophysiology or Anatomy um and in light of that if you also
there's a Temple called David rudroff Rudd Ross are you
um our auf um who's currently um he's been Grenoble is currently
relocated to France and he's a great theoretician who has a whole projective
um geometry Theory Of Consciousness that really does put where you think you are center stage in building models of how
we engage and act in our world and of course you know where we are physically and how we move our bodies around is a
really important part of that yeah because you're not you're not in your foot right now you're somewhere here
which is kind of super strange if you think about I wonder if that's also one of these things that is just efficient
maybe or maybe there's some reality principle going on there but I I wonder I actually they wonder about that
somewhat earlier it's like why am I not in my foot why my hand yeah yes it seems we all share this
apparently with about two centimeters just behind the midline of our eyebrows apparently that's where most of us put
ourselves but it's a really interesting why why why would that be the vantage point and David's theory of projective
geometry as a key architectural principle of the charity of the world
models we have given our kind of bodies that we have to use whether our eyes are
have evolved or are engineered um you know that provides some really
interesting insights into your the Vantage points and where where am I
but thank you for the recommendation I'll I'll look him up thank you has he
really has he written any books Mark sons and Bob Services written a number of books I think the most recent one was
called The Hidden Spring by Mark Sims um but he you know he's quite a prolific
and and a very well-known International speaker um so you should be able to find so Linson came to town that travels the
world um yeah seeing um academics and and uh patients and the like and the other
gentleman was David rudroff who was younger and hasn't uh written a book yet to my knowledge but he has certainly
written some very interesting high-end papers in in this in this field where there's nothing yeah I'm a good reading
papers but luckily we live in the age of 30 GPT so I can ask for a summary right
um so girl were there any moments in your personal or experience in your personal life that you say have
Were there any moments or experiences in your personal life that you'd say have significantly shaped or redirected your research in theoretical neuroscience and computational modeling?
significantly shaped or redirected your research in theoretical neuroscience and computational modeling
um I I think most of the decision points were uh formative and absolutely crucial
yeah um so I I don't think there was you know there were no specific events because very much as we were talking
about before in terms of having a narrative um having a willful narrative about
what's going to happen to me next and actively putting yourself in that position that's been very much where
I've designed my career so every move I have made has been chosen in order to
um align with this access or direction of um responding to epistemic affordances
to put myself into a situation where I could ask questions and try to answer them um doing your theoretical neuroscience
so formative ones were were um I haven't got time to tell the story but ending up doing uh Psychiatry for
example that was very important and uh spending two years in a
um an old Victorian style Lunatic Asylum with 20 to 30 chronic schizophrenics and
psychiatric nurses and colleagues uh in in a community setting now for two years
that was quite interesting formative type of I can imagine
I can yeah there must be a lot of good stories there maybe maybe for another time but yeah it's very interesting so
um and the other way around the dot has your work how has your understanding of
And has your work influenced your daily decisions and how you think about the world?
it influence your daily decisions and how you think about the world as is it going the other way around
yes I think that's certainly true um I mean a lot of the common sensical
um interpretations of active inference um are those that actually comply with
the free energy principle they are accurate but really simple explanations for observed behavior and of course you
know I observe my behavior more than anybody else is so a lot of it a lot of this is yes that makes a lot that's a
simple explanation what for why I did this or why I deceived that or why I thought that or why I planned that
um so yeah so there is a circular causality what's that moment where like well if I
hadn't done this work then I wouldn't be this person or escrow always been this person and he
always knew what to do and uh this work didn't change his inner perspective on life
oh um it is too personal it's you don't have to share it I'm just curious
I'm just trying to think about your entertaining but uh sensible answer
no I think I think I just feel I was very lucky um I you know um
I don't think I've actually used any theoretical insights to further my
career um having said that perhaps there is one interesting example which is um
I came into science um in the context of brain Imaging and uh first contributed by writing uh
software packages for analyzing brain Imaging data specifically statistical parametric mapping with colleagues
um and subsequently procedures that we mentioned right at the beginning of the interview such as Dynamic causal
modeling having to solve the problem of how to analyze scientific data
exposed me um in part to the principles of more
generic modeling and sense making um which meant that um it was easy for me to see how one can
apply exactly the same principles that we were using to analyze our scientific data to the brain when it was trying to
analyze its sensory data and very fortuitously at that time people like
Jeffrey Hinton and Peter Diane had just moved next door to our brain Imaging unit and we're telling a very similar
story from the point of view of the importance of gelatin models in making
sense of data in the context of artificial intelligence and machine learning as it was
um in the in the early 90s so I think the Confluence of those two things were very formative in terms of you know
translating basic statistical and mathematical principles and methods into
a story about biological self-organization and in particular you
know sort of Neuroscience that then can be generalized to any kind of biotic self-organization
we're nearing the two and a half hour mark so I don't want to take up too much of your time I'm I'm not sure how how
much energy you have I don't want to be rude we haven't discussed this because we just went and went into an interview but usually around 90 minutes two hours
I'm like okay how are you doing should we go on do you want to eat something I have a break or just end it
um so here's that moment do you want to go on or like no Jack it's uh I'm done for today I have to see my wife whatever
have my kids um let's do one more question or uh if
you have one and then sure I've tons of questions yeah okay well then it's um
well silly question actually um if you well Carl if you could have a conversation with any historical figures
If you could have a conversation with any historical figure (scientist, philosopher, or religious leader) about their views, who would it be and what would it be about?
whether scientists philosopher religious leader whatever about our views who would it be and what would it be about
um I'll be torn between helmholtz and Richard Feynman I think um ooh Simon yeah yeah
there are lots of great thinkers but certainly for me for me or my heroes apart from Sherlock Holmes is not a real
person is is our helmholtz the other polymath and
Richard Feynman so it would be nice I don't know that I'd have anything sensible to ask them but at least I
could say I'd spoken to them and be very proud of that well I have been a fan of when I was younger I I listened to the
the audio books the the fireman lectures on physics and oh oh boy there was one
this man could explain anything to you it was it was so gorgeous to listen to
his stories the way the way he explained it it made he made
everything simple and he had such a joy such a wonderful way of teaching teaching me things and it was really
genuine and it wasn't even teaching he was just telling stories but what what what if you what would you have asked
either of them because you would have you would like to speak with them if you could but I'm curious what would you
have asked them right well I I I I I would have
um I'd like to have known where their contributions came from that you know in
exactly the same way you the the past two questions have been asking me about you yeah where how did my life story and
career um intersect with and cause the um the academic contributions I would also have
the same kind of Fascination for these people's epistemic journals at what point did they have these insights and
what point were they articulated what was the colonel Freud and do we understand them now in the spirit in
which they were originally invented would I be particularly interested in because what would have happened if helmheltz
had met Feynman see help help um I think had all the right ideas that
you know that one could even argue under right generative AI you know and the
past hundred days of great achievements in uh in um in machine learning and
artificial intelligence research he had all the right ideas right from the physics right from sort of helmhole
speak compositions and help holds free energy right through to the uh the psychology and the um his work on
perception and Optics and like you know he knew I think he knew an enormous amount and
um tried to find a unifying principle for all of this intelligence and this uh he
framed it unconscious inference um in terms of a neuronal energy or a
neural energy they'll play the same role as a Helen Health Energy or a Gibbs energy in um free energy in a um in
thermodynamics um and really failed um and it's interesting that Freud at
the time was coming up with his Notions shortly afterwards of you know an energetic and bound energies and the
like and I'm I I would like to ask him to one extent Freud was was trying to
take this um this narrative further and but just didn't have the right sort of um uh the
right physics grounding but specifically what would have happened if
um if helmheltz had met Feynman because Feynman I think came up with the right kind of free energy that helmhurstle's
looking for in his in his uh work on the pathological formulation and Quantum electrodynamics that's the free energy
that is the free energy of the free energy principle it's this thing that is is used to do good modeling to work out
the probability of things which normally you wouldn't be able to do because you didn't you you you couldn't solve this
impossible marginalization or intractable marginalization problem but he worked out a way of doing it of the
kind that could be used by biophysical systems like the brain and had firemen
been able to talk to helmholtz I'm sure that we would have got things like the free energy principle not in the early
21st century but in the in the early 20th century
the two of them to talk to each other I think yeah you'll you'll be out of a job then so it maybe it's for the best girl
right girl thank you for your time really
um I appreciate it so much people here here too um
enjoy your day and I'm not sure how the weather is it looks very nice behind you it looks very sunny it's super sunny
here so I'm gonna enjoy the last less bits of sunshine too and uh
yeah just thank you for this for this conversation I really enjoyed it yes well I did as well thank you very much
for having me I can see I can see the sunshine fading behind you so now I have very much enjoyed the questions uh and
didn't realize that so much time had passed you're absolutely right so thank you thank you and uh I hope we speak again