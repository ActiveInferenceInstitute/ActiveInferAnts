https://www.youtube.com/watch?v=2v7LBABwZKA
Karl Friston: The "Meta" Free Energy Principle
00:00:00 Introduction
00:02:45 Balancing work and life with an h-index of 200+
00:04:33 Daily routine
00:05:55 How to choose which problems to work on?
00:10:13 Defining "deflationary" and "self-evidencing"
00:14:33 Equilibrium vs non-equilibrium steady state
00:20:52 Why is it called the Free Energy Principle?
00:27:20 What is the Free Energy Principle? (two answers)
00:41:15 Is causation and time required for the FEP?
00:46:03 FEP incomplete because it doesn't incorporate relativity? 
00:57:21 Schr√∂dinger, entropy, gradient flow, and life
00:59:01 Why is the Free Energy Principle infamous for being esoteric?
01:01:00 Is FEP a TOE? A theory of everything?
01:03:20 Do atoms have "beliefs" in a Bayesian sense?
01:04:54 List of different fields FEP has implications for (physics, biology, AI, etc.)
01:17:47 On Occam's Razor and Artificial Intelligence
01:25:38 Newcomb's paradox
01:29:05 FEP - a Law of Nature or a different way of compressing?
01:36:50 Jordan Peterson's "order and chaos" and the FEP
01:50:51 Using brain structure to infer about the world
02:07:12 On hierarchies and modelling different "things" (tools don't behave like apples)
02:13:59 The importance of "shared narratives"
02:18:37 Religion as aiding "shared narratives"
02:22:43 Politics needs 50 / 50 splits on issues
02:25:53 The existence of free will and definition of it
02:28:43 Self fulfilling prophecies
02:31:37 Schizophrenia, Curt, and Karl
02:45:48 "You are your own existence proof."
02:48:03 Can you think yourself into non-existence?
02:51:33 Definition of generative model
02:54:06 Donald Hoffman's consciousness model
02:54:34 Quantum consciousness and Penrose's Orchestrated OR
02:59:41 What does FEP say about consciousness?
03:09:48 The meta-Hard Problem of Consciousness
03:15:22 Anna Lukomsky: Idealism vs Physicalism
03:28:13 Joanne Dong: Explain the meaning of life via the FEP
03:34:23 Monotheism vs Polytheism in terms of FEP and psychology
03:38:50 Faraz Honarvar: Do our actions matter to the world?
03:47:20 Final words on Schizophrenia and existential anxiety from studying different metaphysics
This is the longest interview I've ever done because they are such intriguing questions. But yeah, the fact that I'm still here is testament to the fact that I had a great time. I don't think we'll talk to our next exchange. Carl Friston is considered by his peers to be the top neuroscientist that exists, probably that ever existed. Now obviously he won't say that, he'll rebuff that because he's a humble British chap who doesn't like to draw undue attention to himself, but I give him that accolade. He has a principle called the free energy principle which is infamously inscrutable, but we try to make it as simple as possible. Please keep in mind that while there is plenty of technical jargon in this podcast, it's important that you stay with it. Once you're at the end, you'll probably have a better understanding as to how to interpret what he said at the beginning. This is one of the longest conversations, if not the longest conversation with Carl Friston that exists. And not that size matters, but you can use the duration or the length of a podcast as a proxy for the interviewee's interest. And that's great for me as an interviewer, because hopefully the rapport comes across and influences whether or not you can absorb the information or influences the rate at which you can absorb it and possibly even the comfortableness that me and Carl have with one another aids your understanding. Perhaps the integration of this information so that you can assemble your own Veltan Shaum that is your own theory of everything. These podcasts are extremely difficult to produce because they require quite a bit of preparation. And if you're interested in supporting conversations like this or seeing more like this, or you have other ideas as to who I should interview, and you'd like to support this channel in some way, shape or form, then please do consider going to patreon.com slash Curt Jaimungal literally every dollar, every donation, every patron helps a tremendous amount, not only financially, but it also helps with encouragement. It helps show me that this is something that people are people like and are willing to support voluntarily. Thank you to all the existing patrons. And just so you know, the best way to view this podcast in spite, like I said, it's inscrutable nature as to what exactly the free energy principle is. The best way to view this podcast or listen to it is by re listening to it. By the end of it, you'll have a better understanding as to what Carl Friston means when he says certain terminology. And then when you rewatch or revisit certain parts, you can look at the timestamps revisit and hopefully gain a better understanding for those listening and not watching. There is also a YouTube channel. And for those who are watching and not listening, there is a iTunes, Spotify, Google Play, we're on pretty much every platform, you can look at the description to get the links for that. Thank you so much and enjoy. Sir, it's a pleasure. I have been looking forward to this for quite some time. As I started
Balancing work and life with an h-index of 200
researching you, I found out that you're not only one of the top neuroscientists that are living, but you may be the greatest neuroscientist to ever exist. I'm just going by the approbation from your own colleagues as well as your h index, which is another reflection of colleagues approving of you and your citations, which is in the six digits, if I'm not mistaken. So how about first we start off with just how is it that you balance work and life? Very badly. I should say that I'm certainly not the greatest neuroscientist. I think that's more a reflection of the fact they invented the h index a few years ago. So it gives me an unfair advantage. And the balance is, is, is very poor. So most of my life I spend pursuing academic commitments. In fact, in the past, in the past year, also commitments I've taken on in relation to the coronavirus outbreak in terms of modelling. So on the other hand, I love what I do. So for me, life is a bit of a holiday. Anyway, I think many people who suffer are my family in terms of my improper work life balance. Does your family get upset that you're constantly thinking about work? Or are you distracted when you're spending time with them? Because something else is on your mind? I think they've got used to it. And I have to say that they also have their preoccupations and their sort of the things that they invest in. So I think they are as guilty as I am in not
Daily routine
paying proper attention to the life side of the work life balance. Do you have a daily ritual? Or do you meditate? Or do you eat a certain type of meal, go to sleep at a specific time, wake up at a specific time? What's the structure? I am certainly a creature of habit. And I guess we'll come back to why that is possibly the case. I should be the case for most creatures. So no, I don't meditate. But it's an interesting question. Because my daily routine does involve a long period of thinking in the morning. So and it's alone. So I generally joke, perhaps not joke that I don't like talking to other human beings before lunch before 12 o'clock. So my day typically will start with at least an hour, if not two hours, sitting and contemplating on the problem at hand, usually in my conservatory, smoking my pipe, just drilling down without any aid, without a computer or without any pen and pencil, just to boil down the simplicity of the problem at hand, and try and see the architecture of the solution. And then it's a question of buckling down to emails or then doing coding or mathematical derivations and writing something up for the rest of the day.
How to choose which problems to work on?
And when I start talking to other people, you sit without a pen and a paper and you just think with your eyes closed? Well, I actually enjoy looking at the garden whilst thinking but I do get distracted. Yeah. Yeah. And if you see me close my eyes, I'm often thinking deeply about what you're saying. I don't want you to think I'm distracted or sleepy, just so you know. This just sounds extremely British of you to have a pipe. And do you drink tea? Are you sitting with biscuits? Do you have a breakfast? Well, no. In the morning, it's coffee and then tea would be for the afternoon. Without without biscuits, but certainly coffee in the morning, tea in the afternoon. How do you choose which problems to tackle? Because I assume that maybe 80% of the reason for your high H index is the problem selection. Yeah, absolutely. And, you know, I often have heard it said that the other mark of a great scientist is not the the answers that they offer. It's really the questions that they ask. And I have to say that most of the questions that I'm obliged to contend with are those that are proffered either by colleagues internationally and most of the time by the younger people that I work with or supervise. So it's really I spend most of my time in response mode, just trying to formulate and resolve questions that my international, usually younger team, bring to the table. So 90% of my work is just basically helping other people solve problems. About 10% of it when I have time is sort of focusing on, you know, on my particular hobby, which in latter years has become the free energy principle. That's a somewhat rare opportunity. Most of the time you're working on other slightly more practical problems. How has learning mathematics, new mathematics, new physics, whatever it may be, how's that changed in your later years compared to younger years? The it's well, practically, I'm on the sounds that question is, it's much easier now. Because of things like Wikipedia, and the electronic age. I mean, certainly, I, I had the conviction, which I think is a proper conviction that to make any real formal difference, you had to be able to articulate things mathematically. So you're made a particular point of choosing an early career and education that covered physics and maths and probability theory and the like, but probably not not dissimilar to your early career structure. And then forgot it all until I returned after a studying as a doctor with a psychiatrist to maths via data analysis in imaging neuroscience. So it was extremely useful having had that early physics sort of degree level education. Although I'd forgotten everything, at least I had the confidence to relearn those bits that you need to know to make something work. So it was very much on one of the situations of sort of see one do one teach one, where very quickly you need to solve a problem. And then you went to, you know, in latter days, at least you went to Wikipedia, you got the right equations, and you put them together, implemented it in code, and then proceed on to the next problem. So yeah, I have possibly an undue respect or reverence for the utility of maths, not you know, not just in relation to its unreasonable efficacy, but also as a language for communication, as a calculus that every like minded academic, or indeed industrial partner,
Defining "deflationary" and "self-evidencing"
will at some point, subscribe to and drill down on and understand. So I think it is the ultimate language, which, you know, effectively are most of what I say in words or write textually, inherits from and is always guided by the underlying the underlying mathematics. Before we get to the free energy principle, which I'm going to ask you to explain as simply as you can, and then you can go as complex as you can later. But before we get to that, I found that there were a few words that you use in the different interviews that I've seen of you, that I'm unsure as to what you mean precisely when you say them. So deflationary is one. What do you mean when you say deflationary? Because I'm sure that will come up over and over here. Right? Yes. You're right. That's one of my favorite words at the moment. And just taking if you want an honest answer, I use it in the sense of just taking the hot air out of something. So in some instances, one sees what an over interpretation of certain things. So there is always a simpler explanation for various phenomena or behaviors or constructs. So for me, a deflationary explanation is a better thing in the sense that it provides a simpler, more parsimonious account of something than was on offer before that simpler account came along. So philosophically, I think I'm using it in the sense of what my friend Andy Clark, who's one of the world's more accomplished philosophers, refers to as a sort of Quinean desert landscape. So this inherits from Quine, who conceived of a set of explanations that was so simple, there was nothing left, hence the desert landscape. And a lot of the aspirations of our theorizing actually points in that direction. A little bit like natural selection. I mean, natural selection is such a wonderful idea, probably the greatest biological idea, certainly in the past few centuries. And yet it is inherently tautological. It just almost goes away when you think about the essential tautology of natural selection. So for me, it's a beautiful idea that is deflationary. It explains so much with hardly anything. When you're saying that natural selection is tautological, do you mean to say that survival of the fittest? Well, you're defining fitness by survival anyway. That's exactly. Yep. That's exactly what I mean. Yep. Okay. Okay. Now self evidencing. Self evidencing is a philosophical term, which I think has been around for some time. But I was introduced to it by my other philosophy friend, Jakob Hoey, who's currently in Melbourne, as a nice perspective on the one take on what we do or what the imperatives, existential imperatives behind our behavior and our dynamics, if you're a physicist, which is to maximize the evidence for your models of the world. So in maximizing the evidence, sometimes described perhaps poetically as acting to garner evidence for your own existence, you can be said to be self evidencing. I have to say, it's a slight play on words from the point of view of a mathematician, because nearly every interesting formulation of self organizing systems has self in. So you start off with self organizing systems of the sort you might see, say computational chemistry through self assembly. Sometimes in the biological sciences, people refer to auto poesis, which is again, Greek for self creation. And you start off just thinking about the information theory that would underwrite that kind of self organization. The first thing I come across is self information. The following that through, you can sort of spin off all sorts of other selves in terms of self serving behaviors that you can write down in terms of
Equilibrium vs non-equilibrium steady state


This is the longest interview I've ever done because they are such intriguing questions. But yeah, the fact that I'm still here is testament to the fact that I had a great time.
I don't think we'll talk to our next exchange. Carl Friston is considered by his peers to be the top neuroscientist that exists,
probably that ever existed. Now obviously he won't say that, he'll rebuff that because he's a
humble British chap who doesn't like to draw undue attention to himself, but I give him that
accolade. He has a principle called the free energy principle which is infamously inscrutable,
but we try to make it as simple as possible. Please keep in mind that while there is plenty
of technical jargon in this podcast, it's important that you stay with it. Once you're at the end,
you'll probably have a better understanding as to how to interpret what he said at the beginning. This is one of the longest conversations, if not the longest conversation with Carl Friston that
exists. And not that size matters, but you can use the duration or the length of a podcast as a proxy
for the interviewee's interest. And that's great for me as an interviewer, because hopefully the
rapport comes across and influences whether or not you can absorb the information or influences the rate at which you can absorb it and possibly even the comfortableness that me and Carl have
with one another aids your understanding. Perhaps the integration of this information so that you
can assemble your own Veltan Shaum that is your own theory of everything. These podcasts are
extremely difficult to produce because they require quite a bit of preparation. And if you're interested in supporting conversations like this or seeing more like this, or you have other ideas
as to who I should interview, and you'd like to support this channel in some way, shape or form, then please do consider going to patreon.com slash Curt Jaimungal literally every dollar,
every donation, every patron helps a tremendous amount, not only financially, but it also helps
with encouragement. It helps show me that this is something that people are people like and are willing to support voluntarily. Thank you to all the existing patrons. And just so you know,
the best way to view this podcast in spite, like I said, it's inscrutable nature as to what exactly
the free energy principle is. The best way to view this podcast or listen to it is by re listening
to it. By the end of it, you'll have a better understanding as to what Carl Friston means when he says certain terminology. And then when you rewatch or revisit certain parts,
you can look at the timestamps revisit and hopefully gain a better understanding for those listening and not watching. There is also a YouTube channel. And for those who are watching
and not listening, there is a iTunes, Spotify, Google Play, we're on pretty much every platform,
you can look at the description to get the links for that. Thank you so much and enjoy. Sir, it's a pleasure. I have been looking forward to this for quite some time. As I started
Balancing work and life with an h-index of 200
researching you, I found out that you're not only one of the top neuroscientists that are living,
but you may be the greatest neuroscientist to ever exist. I'm just going by the approbation from your
own colleagues as well as your h index, which is another reflection of colleagues approving of you
and your citations, which is in the six digits, if I'm not mistaken. So how about first we start
off with just how is it that you balance work and life? Very badly. I should say that I'm certainly
not the greatest neuroscientist. I think that's more a reflection of the fact they invented the
h index a few years ago. So it gives me an unfair advantage. And the balance is, is, is very poor.
So most of my life I spend pursuing academic commitments. In fact, in the past, in the past
year, also commitments I've taken on in relation to the coronavirus outbreak in terms of modelling.
So on the other hand, I love what I do. So for me, life is a bit of a holiday. Anyway,
I think many people who suffer are my family in terms of my improper work life balance.
Does your family get upset that you're constantly thinking about work? Or are you distracted when you're spending time with them? Because something else is on your mind?
I think they've got used to it. And I have to say that they also have their preoccupations and
their sort of the things that they invest in. So I think they are as guilty as I am in not
Daily routine
paying proper attention to the life side of the work life balance.
Do you have a daily ritual? Or do you meditate? Or do you eat a certain type of meal,
go to sleep at a specific time, wake up at a specific time? What's the structure? I am certainly a creature of habit. And I guess we'll come back to why that is possibly the case.
I should be the case for most creatures. So no, I don't meditate. But it's an interesting
question. Because my daily routine does involve a long period of thinking in the morning.
So and it's alone. So I generally joke, perhaps not joke that I don't like talking to other
human beings before lunch before 12 o'clock. So my day typically will start with at least an hour,
if not two hours, sitting and contemplating on the problem at hand, usually in my conservatory,
smoking my pipe, just drilling down without any aid, without a computer or without any
pen and pencil, just to boil down the simplicity of the problem at hand, and try and see the
architecture of the solution. And then it's a question of buckling down to emails or then
How to choose which problems to work on?
doing coding or mathematical derivations and writing something up for the rest of the day.
And when I start talking to other people, you sit without a pen and a paper and you just think with your eyes closed?
Well, I actually enjoy looking at the garden whilst thinking but I do get distracted. Yeah.
Yeah. And if you see me close my eyes, I'm often thinking deeply about what you're saying.
I don't want you to think I'm distracted or sleepy, just so you know. This just sounds extremely British of you to have a pipe. And do you drink tea? Are you sitting
with biscuits? Do you have a breakfast? Well, no. In the morning, it's coffee and then tea
would be for the afternoon. Without without biscuits, but certainly coffee in the morning,
tea in the afternoon. How do you choose which problems to tackle? Because I assume that maybe 80% of the reason for your high H index is the problem selection.
Yeah, absolutely. And, you know, I often have heard it said that the other mark of a great
scientist is not the the answers that they offer. It's really the questions that they ask. And I
have to say that most of the questions that I'm obliged to contend with are those that are proffered
either by colleagues internationally and most of the time by the younger people
that I work with or supervise. So it's really I spend most of my time in response mode,
just trying to formulate and resolve questions that my international, usually younger team,
bring to the table. So 90% of my work is just basically helping other people solve problems.
About 10% of it when I have time is sort of focusing on, you know, on my particular hobby,
which in latter years has become the free energy principle. That's a somewhat rare opportunity.
Most of the time you're working on other slightly more practical problems. How has learning mathematics, new mathematics, new physics,
whatever it may be, how's that changed in your later years compared to younger years?
The it's well, practically, I'm on the sounds that question is, it's much easier now.
Because of things like Wikipedia, and the electronic age. I mean, certainly, I,
I had the conviction, which I think is a proper conviction that to make
any real formal difference, you had to be able to articulate things mathematically. So you're made a particular point of choosing an early career and education that covered physics
and maths and probability theory and the like, but probably not not dissimilar to your early career
structure. And then forgot it all until I returned after a studying as a doctor
with a psychiatrist to maths via data analysis in imaging neuroscience. So it was extremely
useful having had that early physics sort of degree level education. Although I'd forgotten
everything, at least I had the confidence to relearn those bits that you need to know to make something work. So it was very much on one of the situations of sort of
see one do one teach one, where very quickly you need to solve a problem. And then you went to,
you know, in latter days, at least you went to Wikipedia, you got the right equations, and you put them together, implemented it in code, and then proceed on to the next problem.
So yeah, I have possibly an undue respect or reverence for the utility of maths, not
you know, not just in relation to its unreasonable efficacy, but also as a language for communication,
as a calculus that every like minded academic, or indeed industrial partner,
will at some point, subscribe to and drill down on and understand. So I think it is the ultimate
language, which, you know, effectively are most of what I say in words or write textually,
Defining "deflationary" and "self-evidencing"
inherits from and is always guided by the underlying the underlying mathematics.
Before we get to the free energy principle, which I'm going to ask you to explain as simply as you can, and then you can go as complex as you can later. But before we get to that, I found that
there were a few words that you use in the different interviews that I've seen of you, that I'm unsure as to what you mean precisely when you say them. So deflationary is one.
What do you mean when you say deflationary? Because I'm sure that will come up over and over here. Right? Yes. You're right. That's one of my favorite words at the moment. And just taking
if you want an honest answer, I use it in the sense of just taking the hot air out of something.
So in some instances, one sees what an over interpretation of certain things. So there is
always a simpler explanation for various phenomena or behaviors or constructs. So for me, a deflationary
explanation is a better thing in the sense that it provides a simpler, more parsimonious account
of something than was on offer before that simpler account came along. So philosophically,
I think I'm using it in the sense of what my friend Andy Clark, who's one of the world's
more accomplished philosophers, refers to as a sort of Quinean desert landscape. So this inherits
from Quine, who conceived of a set of explanations that was so simple, there was nothing left, hence
the desert landscape. And a lot of the aspirations of our theorizing actually points in that direction.
A little bit like natural selection. I mean, natural selection is such a wonderful idea, probably the greatest biological idea, certainly in the past few centuries. And yet it is inherently
tautological. It just almost goes away when you think about the essential tautology of natural
selection. So for me, it's a beautiful idea that is deflationary. It explains so much with hardly
anything. When you're saying that natural selection is tautological, do you mean to say that survival
of the fittest? Well, you're defining fitness by survival anyway. That's exactly. Yep. That's
exactly what I mean. Yep. Okay. Okay. Now self evidencing. Self evidencing is a philosophical
term, which I think has been around for some time. But I was introduced to it by my other philosophy
friend, Jakob Hoey, who's currently in Melbourne, as a nice perspective on the one take on what we
do or what the imperatives, existential imperatives behind our behavior and our dynamics, if you're a
physicist, which is to maximize the evidence for your models of the world. So in maximizing the
evidence, sometimes described perhaps poetically as acting to garner evidence for your own existence,
you can be said to be self evidencing. I have to say, it's a slight play on words from the point of
view of a mathematician, because nearly every interesting formulation of self organizing
systems has self in. So you start off with self organizing systems of the sort you might see,
say computational chemistry through self assembly. Sometimes in the biological sciences,
people refer to auto poesis, which is again, Greek for self creation. And you start off just
thinking about the information theory that would underwrite that kind of self organization. The first thing I come across is self information. The following that through, you can sort of spin off
all sorts of other selves in terms of self serving behaviors that you can write down in terms of
Equilibrium vs non-equilibrium steady state
information theory. And for me, the simplest and most, the prettiest is this notion of self
evidencing. What about equilibrium state versus a non equilibrium steady state? So that was not
idiosyncratic to you. Right? No, no, no, heavens no. And again, remember, I'm a bit of an amateur
physicist. You're trained as a physicist as a young man, but haven't haven't really been in that field
throughout my career. But my reading of physics, as it applies to the kinds of systems that we have
to deal with, can be read as sort of 20th century physics where you're dealing with closed systems
at equilibrium. And then the 21st century, people got much more interested in the physics of open
systems that are far from equilibrium or non equilibrium. And what can you do with these kinds
of systems? Well, you can you can write down their dynamics, their density dynamics, you can
formalize the behavior of the probability distribution over the various states of these systems and how they would unfold from any given initial condition to some steady state distribution.
For me, though, it is the steady state distribution, which is interesting because that provides you with a well defined probability distribution. And once you've got that, then you can go forward in
terms of the information theory and spin off everything that you might want to in terms of inference and the like. So the non equilibrium part is absolutely crucial in the sense that it
defines a set of questions about systems that are in exchange with a world out there. So that
there is from the thermodynamic point of view, an exchange of energy and entropy between the system
in and of itself and the rest of the universe. From a mathematical point of view, the non
equilibrium aspect is inherited from the prevalence of circular flows, solenoidal flows,
the sort of flow which if you were a machine learning would destroy detailed balance and that
would have a lot of technical implications. But what I'm talking about is sort of the fluctuations
that you get in classical mechanics, like the orbits of heavenly bodies or the circular
fluctuations you get in predator prey relationships or Red Queen dynamics. Wherever you look at sort
of interesting systems that persevere over time, you see this sort of solenoidal circular
oscillatory like behavior. And it is that which characterizes real dynamical systems
that are, I repeat, not isolated from the rest of the universe or are not carefully
enshrouded in a heat bath like an idealized gas, but they actually have to contend with
an exchange with the outside world. So that's what's encapsulated by a non equilibrium system.
The steady state means that if you leave it alone for long enough, it will self organize
into some recognizable configuration that you can describe probabilistically with a probability
density function, or in terms of some attracting set of pullback attractor,
whatever your preferred kind of calculus or maths would be. So steady state refers to it over time, being somewhat stable, but then the non equilibrium
means that it can ramify can go between here and then it may jump here and then it may jump here, but between three only instead of one would be equilibrium.
No, I think that's a very nice description. So yes, absolutely. So the steady state
just means that the system has settled down to some attracting set of states.
But within that set of states, there is exactly what you were referring to. There's an itinerancy,
there are different sort of regimes or sub manifolds of an attracting set, which gives
it an itinerancy or a wandering. So it moves around from one part of the attracting set to another part of the attracting set. So the example I like to use when trying to get this notion in
play is, at every level of self-organization in me, you see this phenomena, whether it's very,
very fast fluctuations in electrophysiological potentials in one part of my dendrite of one
cell in one part of my brain, you're fluctuating at say the gamma frequency,
or whether it's my heartbeat, unfolding during the cardiac cycle, or whether it's me getting
up in the morning, having a cup of coffee, do my emails, or whether it's the annual cycles that we
all enjoy sort of Christmas, Easter, summer holidays, every one of these instances of an
open system at some kind of non-equilibrium steady state has in common the fact you keep
revisiting certain states of being. And it's that revisiting that defines this attracting set
and the steady state aspect. So exactly as you are doing with your fingers, you are moving around
from sort of one part of the manifold to another part of the manifold. If you're a physicist who
did dynamical systems theory, you might think of this in like a heteroclinic cycle where you're
moving from one unstable point to the next unstable point, but you're always ultimately coming back to the same attracting set of unstable points. So it's that non-equilibrium.
So we're not at a fixed point. We're not all aspiring to be at thermodynamic equilibrium.
There's an itinerancy and a complexity and a richness to the behavior. But on the other hand,
it's a behavior that evinces the same kinds of states, the neighborhood of places in state space
Why is it called the Free Energy Principle?
time and time and time again, for the duration of the existence of that particular system or
particle or person in question. Why did you call it the free energy principle? When I first heard,
well, I heard about it quite a few times, then I kept dismissing it because I thought it was referring to perpetual motion or the extraction of energy from vacuum fluctuations.
I understand that it has something to do with free energy in the physics term, but what led you to calling it the free energy principle? And have you heard of other people?
Have you heard of the case of mistaken identity from other people? Or is it just me? No, no, I've certainly come across that, but not so nicely articulated or gently articulated.
And so, yeah, for me, in my world, the free energy was the most natural and obvious thing
to call it, because the kind of free energy that we're dealing with, or would I say we,
people in either Bayesian statistics or latterly what we know now as machine learning,
would always refer to this quantity, this variational free energy as a computable
objective function for any inference or estimation problem. So whether you're doing sort of
classification of machine learning and you're using restricting belts of the machine and you're using, or let's make it more current. So you're doing, you're using high-end deep learning,
using a variational autoencoder to try and recognize some sequence of images, then the
weights that you are optimizing in that deep learning setting, in that particular variational autoencoder setting, are optimized with respect to a variational free energy. So this variational
free energy plays a central role, has done for more than half a century now, in the way that
we've been doing it for more than half a century now, in optimization problems. Its origins are
actually really quite interesting. Historically, again, this is not really my field, but from what I gather, there are two ways that the free energy sort of came into play. The American route,
and this starts with Richard Feynman, as with most things. So he had the problem of basically
wanting to express simply, evaluate the probability distribution over all the paths
an electron, say, could take. And he realized that that was an intractable integration problem. He
couldn't work out the sort of the normalization constant to make sure that probability distribution summed to one. So he was faced with an intractable, effectively integration problem
in quantum electrodynamics. So he solved it by converting that integration problem into an
optimization problem. And the way he did it was to introduce a variational free energy that was
always greater than the quantity that he wanted to minimize, or was less than the quantity that
he wanted to maximize, which in this instance is just the marginal likelihood or the likelihood distribution of various paths, say a small particle might take. So that's where I learned
about free energy, essentially a Feynman-esque free energy that was provided a bound approximation
to something that you actually wanted to maximize or optimize. And in my world, that thing you want
to maximize is the model evidence or the marginal likelihood, because back to self-evidencing,
but also the marginal likelihood sort of indicating that this is a central notion in physics,
in Bayesian statistics as well. And that quantity, that variation of free energy
has been in play now for not quite a century, but certainly many, many decades.
Currently known as an ELBO, an evidence lower bound. So that evidence lower bound
underwrites all of high-end machine learning. And certain simply reduced cases of it,
I would actually suggest probably all of machine learning at some point refer to, or can be
seen as a special case of this. The other route inherits more from the Russian side.
This is notions of algorithmic complexity underlying universal computation via
Karbala-Grof complexity and Solonov induction. So the big drive there is again formulating
universal computation as basically communicating or articulating or encoding
some structure in the simplest way possible by introducing a bound on the thing that you want to
optimize or minimize or extremize. So you can also find the free energy
and in the context of sort of a more Shannon-esque like take on communication and
optimization. And David McCabe sort of originally brought that perspective to the table, a perspective
that was well understood by people like Wallace in Melbourne, who themselves had taken it from
the Russian literature and Solonov. I think he was an American, but also
taking this algorithmic complexity. So it's a very long answer to actually say that the free
energy principle or the principle of minimizing free energy has underwritten universal computation,
practical approaches to quantum electrodynamics and machine learning since the 1950s. So that's
what the free energy means. It's not that the energy is costless. It's just borrows from
What is the Free Energy Principle? (two answers)
the formalism of a thermodynamic free energy, either Gibbs or Helmholtz free energy.
Okay. This sounds like a great time to explain what the free energy principle is. I know you touched on it, but for the people who aren't aware. Right. So we're asked to do this. I'll
give you a choice. You can either take the high road or the low road. So the high road
would start with a consideration of what it is to exist, to be something, and then unpack that in
terms of physics. And then ultimately you get to a picture of things that exist as things that look
as if they are trying to minimize their free energy. And you can interpret that in terms of
action and perception, sentient behavior, effectively a physics of sentience, where
everything entailed by a particle that could be a sort of small particle, it could be a person
or a plant, anything that exists can be seen as, or understood or characterized as trying to
optimize or minimize a free energy through changes in internal states or through action
upon the world. That will be the high road. And we can take that if we choose that option. The low road would be sort of building up a sense of there being just one imperative
from the notions that probably can be found in the students of Plato throughout philosophy,
through Kant, through Helmholtz, through modern day psychology and subsequently machine learning,
would appeal to a story, a narrative about prediction and inference. And that we are all
effectively prediction machines, where in this setting, the existential imperative
is basically to reduce prediction error. So by prediction error, I simply mean that
we have in mind a model of the way that the world works, and that we can leverage that model
to produce predictions about the sensory evidence at hand, and the disparity or the difference
between our predictions and our actual sensory samples can be called prediction error. And it
turns out mathematically that the sort of the high road and the low road converge because the
prediction error is just the gradient of the free energy that you're trying to minimize. So I'll come
back to you, which would you prefer, the high road or the low road? Okay, first, when you say sentient,
do you mean the capacity to feel pleasure or pain? Or how are you using that word? Yeah, just a sense,
just to not so much the affect aspect, not the sort of the pleasure and the pain, just being able
to represent and infer. So to have in mind a notion of what caused your sensations.
So I'm using it in a deflationary way. So some systems
may or may not have the kind of sentience that you'd associate with, say a person or a pet.
So, you know, does a plant is a plant sentient? Let me ask you, do you think a plant is sentient?
Does it does it have, can it in an elemental way feel its way around the world or have some
internal representation of, of the world that it inhabits? I would say it's a scary thought
to think of plants as extremely sentient because you crush them constantly. And even if you're a vegetarian, so I'm unsure if I think that they can feel pleasure or pain, it does seem like it's
clear that they respond to the environment and that they take in sensory information and act on it. Yes. Yeah. I think that's absolutely true. In fact, interestingly, they, they have the same
sort of electrochemical message passing that we have with our axons, you know, in the brain,
it unfolds at a much slower timescale. But the, you know, the physics of the message passing the
internal, the internal states of a plant to actually comply with various similar kinds of
computational architectures that your brain and mind is. I would say a plant is sentient, but
not to the extent that it has notions, emotions, or even a sense of self. You know, there are lots of
graded, very, you know, sort of ladder. There are lots of steps on the ladder of sentience right
through to self awareness and pleasure and pain. But I'm talking about a very elemental sort where
there's something going on in the inside, that is caused by and causes stuff that's going on
on the outside, that you can read as a kind of representation, or an inference about the causes
of sensations. Okay, so when you ask this question as to which explanation would I prefer the high
road or the low road, I imagine that as top down versus bottom up. And when I say that, please let
me know if I'm understanding it correctly. When you say the bottom up, it's something like looking at what exists and seeing that it does act such that it minimizes some quantity or it wants to
minimize error in some way versus the top down, which looks like if I was to sit in an armchair
with my eyes closed and think what exists, okay, what would have to be the case if it were to
exist? What properties would it have to have? So one is, is that correct? Am I? No, that's my optus. No, that's brilliant. Yeah. Okay. Let's start with the top down. Let's just do the top
down because we have quite a few questions. So let's start from the armchair. So okay,
I'll do the top down with a little nod to the bottom up so we don't we don't miss out on anything. So you've just said what, you know, basically the strategy you start off, okay, I want to explain
anything, a theory of everything. So what's a thing? Well, the first thing you have to contend
with, well, how do I differentiate a thing from no thing or nothing or something else? So that
immediately implies that you're splitting or carving or partitioning the states of some universe
into states that belong to the thing and states that don't belong to the thing. And when you think
about what that means, you have to, well, you're compelled then to consider the statistical
dependencies that demarcate something from nothing. And when one drills down on that,
you come across this notion of a Markov boundary or Markov blanket, which is effectively a set of
states that separate or insulate internal states on the inside from external states on the outside.
So you have this picture of transactions mediated by standard dynamics by, of the sort you'd see in
physics with a Langevin formulation, the kinds of equations of motions that everybody uses to,
you know, to build their favorite physics, whether it's sort of quantum mechanics or classical mechanics, statistical mechanics, they all start with the notion of there being some
dynamics out there. And the special kind of dynamics that you, that we're interested in,
in terms of talking about anything, is, applies to systems that have this partition.
So as soon as you put this partition into play, which is basically a partition where internal
states influence external states, this direction through the blanket states, and then external
states influence internal states in the other direction, and vicariously through the Markov blanket, you have this notion of a sort of generalized action and perception that, you know,
the inside influences the outside. So somehow the thing is acting up on the world, but at the same
time, through the blanket states, the outside is acting upon the inside, you know, and we normally
divide the blanket states into sensory and active states. So in this instance, the outside external
states impress themselves upon the sensory states, and then the sensory states influence
the internal states. And so there's a sort of circular causality implied by this partition.
Now, all you do then is say, well, look, let's just look at the long-term behavior of any system
that you can describe in terms of the dynamics or the rate of change of the probability distribution
over states or density over states. And note that because we are interested in systems that have
attained a non-equilibrium steady state, the probability density is not itself changing.
And when one does that, when one looks at the solution to the density dynamics,
in the context of the Markov blanket, you get a particular kind of mechanics. And that mechanics is exactly the same as quantum mechanics or statistical mechanics,
but with one key difference. Now it applies in the setting of a Markov blanket. And that's where
the interpretation of things as self-evidencing comes from, because you can always
write down the flows that maintain this steady state as effectively trying to minimize their
prediction error or minimize their self-information or minimize their what's known as surprise and
information theory, which mathematically is just the same thing as what statisticians like to call
Bayesian model evidence or the log of the probability of these sensory states, given my implicit model encoded by the internal states. So what you end up with is a description
of anything defined stipulatively in terms of it possessing a Markov blanket defined by its
non-equilibrium steady state density, whose dynamics or flows must have this property
that the internal states and the active part of the blanket states must be performing a gradient flow
on this self-information. And then you make a further move and say, well, this self-information
can be written down as a free energy functional or the free energy, if I interpret the internal
states as encoding Bayesian beliefs or probabilistic beliefs about the external states.
So now you have a mathematical image or a picture of existential dynamics that inherit from
having a Markov blanket where you can say that the dynamics of the internal states look as if
they're trying to maximize their model evidence or trying to minimize their free energy or
prediction error. And that's basically the story. So a story that rests really upon what physicists
would understand as dynamics and average flow at non-equilibrium steady state, and in particular
the gradient flows. So perhaps it would demystify this to say that, and coming back to Helmholtz,
who was a key architect of these ideas on the low road to describing. So what, you know,
among the many things that Helmholtz brought to the table was you can always decompose the flow.
For example, let's take the flow of a fluid into two parts. There's one that's flowing
up or down gradients, say concentration gradients. And then there's another circular flow, which
flows around the isoprobability contours or the isogradient, the isocontours of any function.
So what we're talking about is the gradient flow part of it, not the solenoidal, which is the other
circular part of the flow that we were previously talking about in terms of
defining non-equilibrium as opposed to equilibrium systems. And, you know, that gradient flow then
can be now read as a gradient flow on a variational free energy, which is wonderful
from the point of view of people like me in neuroscience, because now what you've got is a
description of neuronal dynamics. So you've got now a first principle account of how neuronal
activity or states change as a function of their state over time. And you can write that down now
as a gradient flow on this one quantity, this variation free energy that endows that gradient
flow, that dynamics with an interpretation that they're trying to maximize the evidence for
Is causation and time required for the FEP?
their model internally of what's going on on the outside.
Okay, let's zoom out. And we see in your model, most of the time when you're presenting with the PowerPoint slides, I see nodes, and then they have arrows. And so the nodes are connected with
different arrows. And then that's what affords a Markov blanket. I have a couple questions. The
arrows represent influence, which to me is a synonym for causation. So I'm wondering, is
causation necessary for this model, because some people argue that causation is an illusion. So for
example, Sean Carroll may say that. And I'm, well, first of all, let's tackle that. Does your model
presuppose causation? Yeah, in a deflationary sense, yes. So
Deflationary. So in the sense, I'm not quite sure what Sean has said, but I want to agree with whatever he said.
So this is a very trivial causation that is implicit when you write down any random differential
equation or stochastic differential equation or Langevin expression. If you just write down
a universe in which there are states that change with time as a function of those states, plus say
some random fluctuations to make it a random or a stochastic differential equation, then what you
are saying is that the flow of those states, the rate of change of those states is caused by those
states. That's the only causality that is in play here. So it's causality of a rather sort of
elemental and trivial sort that I often refer to, sorry, not me, but people often refer to as
causality in a control theoretic sense, that the system is causal in the sense that there is just
motion or dynamics that is caused by a state. So the causality here inherits just from writing
down differential equations that interestingly are only expressed in motion over time. So there's a
deep link behind this trivial causality and time because you're just writing down a differential
equation. After that, there's no causality. There's nothing else after that. The sort of
the causal inference that would be of the kind, say that people like Pearl in his causal mechanics
talk about, I think that's much more a product of inference, but you'd have to actually work
right up through the free energy principle to actually understand what it means just to
measure things, let alone have ideas about did this A cause B? You first of all got to even
work out how would you measure, how would you infer the existence of A out there and B out there?
So the free energy principle starts at a very, very low level and then with baby steps works up
to higher order notions of things like causality. Does that answer your question about the other?
Yeah. Does time always have to be the parameter or can it be something else? Because then it presupposes time as well.
Yeah. I mean, in our work, yeah, it is always time. But of course, you can generalize that,
just treat time as another coordinate if you wanted to. I personally haven't found that a
very useful move. I all have an enormous respect for people who can think like that and completely
generalize this, get all gauge theoretic sort of understandings of the underlying geometry.
For me, I have to say, I just start with a random differential equation and then everything else
follows from that. And in particular, you keep connected to useful things of the sort that do
rest upon dynamics. If you don't treat time as a special, if you like, coordinate or
aspect of some space, then it's less easy and a straightforward way to connect it to things like
entropy production or even things like sort of information entropy and information length
in dynamical systems. So I personally do, you know, time starts off with a privileged
FEP incomplete because it doesn't incorporate relativity?
position in the formulation, in the sense that it underwrites the meaning of a differential equation.
Do you see that as then meaning that the free energy principle as it's currently formulated is incomplete in some manner, given special relativity, let's say that or any relativity
says that time and space must be on some equal footing. And if you're saying that time has some
privileged position, then what position needs to have a equally privileged position?
Right? Yeah, that that question is above my pay grade. I personally don't know you can easily
get dynamics or mechanics out of a Langevin formulation that has time baked into the very
core of it. You know, at the beginning, we just write down a Langevin, you can work the whole way thing up, the whole density dynamics up at non equilibrium steady state, you can write down
quite a simple potential function that describes general relativity. So I don't think I didn't know
that. Okay, because when I was looking at some of your notes, I know you call it the Langevin
equation. I can never pronounce that. So I always call it the coma gara forward equation. For some reason, that's easier for me. But whatever the Langevin Is that correct? Langevin? Yeah, that's
how I say it anyway. Yes. Okay. Let's just say like that for now. Right. Okay. So the Langevin
equation, it can, it can imply Newtonian mechanics, I saw that you were showing that in one of your
slides, as well as quantum mechanics, as well as some aspect of thermodynamics. And then I forget
the fourth one, but then I didn't see special relativity or non relativistic quantum mechanics, you're saying that you can tweak some of the parameters to derive general relativity?
Yep. And it all rests upon the way that you configure the, the,
the gradient flows that have a dissipative, the lender system and dissipative aspect
versus the solenoidal flows that characterize more conservative systems. So when we're talking
about special, sorry, general relativity, for example, excuse me, we're almost
considering the limiting case where the random fluctuations are attenuated by being averaged away that we're talking about sort of massive bodies moving around. So it's just a question
of looking at the various functional forms you would get out of the solution to the Kalman-Roth
forward equation under the limit that gamma is, is, is, is very, sorry, the amplitude,
the random fluctuations is very, very small. So the gradient flows almost disappear. So then it's
just a question, look at the functional forms and with a few nonlinearities here and there, you can, you can quite, you can quite, you can quite easily write down something that, that
general relativity would be quite comfortable with. There are some interesting twists here,
but if you start putting back the random fluctuations into the sort of general solution
to the, the Fokker-Planck equation or the Kalman-Roth forward equation.
And sorry, just for the people listening, the Fokker-Planck equation, and then the Langevin equation and the Kalman-Roth forward equation are all synonyms.
Yes. Well, or the special cases of one another. Yeah. Well, the Langevin equation is, is just the,
the underlying equation that describes the, the flow of the system as a function of the state.
But if you, if you know that, and you know, the amplitude of any random fluctuations on that flow,
then you can do, you can equivalently write that down as a Fokker-Planck equation or a Kalman-Roth
forward equation. I see. I could also say, incidentally, you can also write it down equivalently in terms of a path
integral formulation. You know, all of these could be thought of as different ways of just articulating the same thing. So, but the density dynamics most transparently inherits from the,
you know, from the, the Fokker-Planck or the Kalman-Roth formulation, which is explicitly
about how the probabilities over the states evolve over time. So one example of that would be the
time independent Schrodinger wave equation, you know, which is, you know, one version of a,
of a Fokker-Planck equation. What they have in common is describing the dynamics of,
of systems in terms of the probability density over the states, or if you need quantum mechanics
you know, sort of the, I would say the wave function of states. So at steady state,
in fact you don't need to go to steady state, but certainly once you've written down
the Fokker-Planck equation and solved it for the flow and then use the Helmholtz decomposition
to split the contributions to flow into the solenoidal and gradient flow parts,
then that provides a sort of a nice way of looking at limiting cases. So the gradient flow
is realized by the random fluctuations. So the, you know, for people who are not physicists,
I often use the following analogy that, you know, imagine that I placed a drop of ink in a cup of
water and the ink for dissipative systems or a dissipative ink will disperse itself throughout
the solvent as a random molecular fluctuations cause the ink molecules to diffuse down
concentration gradients until you add a maximum entropy dissipated, dissolved
sort of equilibrium within the sort of the heat bath or the boundaries supplied by the glass.
That's not the kind of system that we're interested in. That's the 20th century sort of equilibrium physics. What we're interested in is special kinds of ink
that seem to gather themselves up again into a little globule. And that gathering up
and that gathering up in the context of, so you stirring the glass of water
can always be written down in accord with the Helmholtz decomposition into two kinds of flow.
One kind of flow is up concentration gradients. So it's, this is the gradient flow I was talking
about. And so the molecules are gathering themselves together, paradoxically, if you like,
looking as if they're flowing towards each other or to the highest concentration, the highest
probabilities or log probabilities. And it's that gradient flow that is
responsible for this self-assembly, this sort of the emergence of this attracting set of a small
number of states that I keep visiting. And then the solenoidal flow is this sort of circular flow
around the iso, in this instance, the concentration
profile, the iso concentration lines, whereas the gradient flow is going to the
maximum concentration or the maximum probability density. So that's non-equilibrium steady state.
Crucially, that gradient flow is exactly balancing the dispersion due to the random fluctuations.
So put that another way, the gradient flow that keeps things glued together, as it were,
that keeps things pointing towards that attracting set, that pullback attractor, that
states that have a high non-equilibrium density is exactly offsetting the dispersive
dissipative effects of the random fluctuations, which means that the random fluctuations realise
the gradient flow. So you have to have random fluctuations before you can have at non-equilibrium
steady state, the gradient flow. So what would happen if you took them away? Well, what would
happen is there will be no gradient flows and things would just have solenoidal orbits. And then we have basically Lagrangian mechanics. We have a mechanics app for describing large bodies,
heavenly bodies, moons and earths and the like. All they can do is move around in circles. So
they've just got solenoidal flow. That's because there aren't all the random fluctuations are
averaged away. So they're effectively zero. So they can't realise the gradient flows. So they don't
fall towards each other with a suitable potential energy that would define the
gradient flows or the form of that non-equilibrium density. On the other hand, you could say, well,
look, I'm more interested in systems that are hot and fast, really fast, like quantum fast,
where the solenoidal bit can be ignored. I'm just going to focus in on the random fluctuations,
the impact of those on the density dynamics. And then you can ignore the solenoidal flow.
We return to systems that have detailed balance and we can write down certain, all our favourite
thermodynamic laws and derive all the integral fluctuation theorems and derive generalisations
of those laws. So from that perspective, classical mechanics, where general relativity might live,
for example, lives at one end of the spectrum, very large, cold, no random fluctuations.
And then quantum mechanics lives at the other end, where it's dominated by random fluctuations,
very fast gradient flows. And in the middle is where we live, where we've got both the,
so we're neither committed to just orbiting for eternally, orbiting
some centre committed to a periodic orbit for the rest of our lives, nor do we dissipate or behave
in a sort of, in a quantum way, but we're sort of halfway between, we're at that right sort of scale, where there's lots of solenoidal, there's lots of
oscillations that we are exposed to impose from a larger scale, such as tides, that we generate
ourselves, such as oscillations in our hearts and our physiology and our brains. But at the same
time, we do have to contend with the random fluctuations. So we spend a lot of our time
doing our gradient flows, gathering ourselves up, planning homeostasis, keeping ourselves in,
Schr√∂dinger, entropy, gradient flow, and life
you're actively keeping ourselves within certain bounds within that attracting set.
And this moving up the gradient flow, is this analogous to what Schrodinger talked about when he said that life resists entropy in some way? Yeah, I think that's absolutely right.
You're asking as if you didn't know. That's exactly right. So, you know, in the presence of these,
for at equilibrium, you're certainly enclosed systems that don't have
sort of low entropy pullback attractors, then you will get the second law, you know,
in the usual way where all the random fluctuations eventually dissipate, hence you get dissipative systems and dissipative dynamics. And yet somehow we,
in our existence, we have an existence proof that that's a violation of that kind of behavior. And that's basically where the free energy principle starts. It just says,
there are things out there that have to be explained that seem to resist the second law.
So, Schrodinger framed it in terms of negative entropy. That's right, right, right.
You know, to frame it in terms of resisting those, that entropic dissipation
by this gathering up behavior, and it is those gradient flows that are responsible
when you just write down the dynamics in terms of the Helmholtz decomposition for providing that balance between the dissipative effects of random fluctuations
and the self-organizing dynamics that exactly balance those dissipative effects to give you
Why is the Free Energy Principle infamous for being esoteric?
this non-equilibrium steady state. Professor, when I was first researching the free energy principle, I kept coming up to cautions
about how intellectually formidable it is. And if one was to just go by the,
just the warning signs, one would think that it was more abstruse than particle physics or
general relativity. And I'm curious, why do you think it has this reputation? Here's an example,
when you search general relativity or particle physics or quantum field theory, or the standard model, or any grand unified theory, I don't think I've ever read a single sentence, except on
quantum mechanics that says, this is a difficult theory to understand. However, on the Wikipedia page for the free energy principle, it says this is notoriously difficult to understand.
Yeah. So I just try to think of other examples that...
I'm not saying that it's easy to understand. In the least, what I'm wondering is, why do you think it has this reputation?
I see. Yes. I think it's largely because somebody slipped in that Wikipedia,
that sentence in Wikipedia, to be quite honest. So it becomes a self-fulfilling prophecy? Absolutely. It's entertaining. And of course, it's... I mean, I know it's not as hard as
quantum physics and thermodynamics, because I used to do those. And I can tell you the free
energy principle, the maths is much simpler than quantum physics or general relativity.
It is much simpler, but it is mathematical. But if you're in dialogue with psychologists who
don't do mathematics, then there can be this sort of inflationary reification of the ideas.
And then there's a mystery, because you don't see the simplicity that is inherent in the
Is FEP a TOE? A theory of everything?
mathematical formalism, the functional forms that you're dealing with. But I quite like that. I
think it's quite funny, really. Keep that in the Wikipedia page. Okay. So the free energy principle,
do you see it as being a potential theory of everything? First of all, you have to decide what are the desiderata of a theory of everything. But the way that I... one of the reasons I'm
interested was from seeing that slide about the Langevin equation or the Kolmogorov, whatever, that equation, and seeing that it... when you tweak the parameters, you can either generate
Newtonian mechanics or general relativity, at least you're saying that now I haven't seen that, and the quantum mechanics and so on. So then that to me means it's a more fundamental principle than
those which makes it a candidate for a theory of everything. But then I just heard you say, well, there's the quantum mechanical world, let's say high fluctuations, then there's low
fluctuations of general, we live in the middle. So then is the free energy principle simply a principle of the middle and not the one that generates all three? Or do you see it as being
a theory of everything itself? So that's a very good question. Right, which deserves two completely
different answers. I think the thing that the free energy principle brings to the table is
it is only licensed by the presence of a Markov blanket. So basically,
the way I look at this is this is applying box standard variational calculus of the kind that
people have been using for centuries, well not centuries, but... Two centuries at the most.
Right. To get at formal formulations of classical mechanics and quantum mechanics and
statistical mechanics or strictly speaking stochastic mechanics, thermodynamics. So it
uses exactly the same maths. The only thing that's special about it is that it applies that maths in
the context of a Markov blanket or a particular partition into inside and outside and separated
by blanket states. That's the only thing that it brings to the table. And in that sense,
if you allow me to interpret everything as every space thing, then thingness as defined
Do atoms have "beliefs" in a Bayesian sense?
stipulatively by a Markov blanket that allows you to demarcate a thing from not thing,
is it certainly a theory of everything by definition, but in a very deflationary way. Right, right, right. So when you say deflationary, see, to me, the way that you use it
is different than how you described it. Unless I'm misunderstanding it, the way that I hear you using the term is like, there are concepts that we have a colloquial understanding as to its
connotations, but you use it in such an abstract manner that it coincides with the colloquial only
seldomly. And so we shouldn't take it too seriously. For example, when someone says surprise, or belief, it doesn't mean that that Adam has a belief. That's the way that I understand
deflation. Am I misunderstanding deflationary? No, well, not at all. No, you're certainly
understanding my use of the word, but it is quite likely that I'm using the word,
I'm abusing the word, or at least misusing it. But that's exactly what I meant. Yes. Yeah. And so
it's getting under the hood, and not reifying and not associating all the folks psychological
interpretations. So yeah, I get that a lot. I have to suddenly pause and say, when I say abasing
belief, I of course, do not mean something you can talk about that you have a conviction about. These are just conditional probability distributions. So you always have to sort of say,
look, we're talking about something much simpler here than you might think. And I think that may in part be an explanation as to why people think that the free energy principle is difficult to
understand. It's not, it's just they think it is because they're, they're reading it using
List of different fields FEP has implications for (physics, biology, AI, etc.)
folk psychological or possibly, from my point of view, over reifying, reifying, reifying the
mathematics. I see, I see. When I first started learning free energy principle, when I first
started learning it, what struck me was its connection to disparate fields of biology,
physics, machine learning, and so on. And it reminded me of in mathematics, there's modular forms, which keep coming up over and over. And there are problems which previously were intractable
that when you recast them in terms of modular forms, they become easier to solve. Do you mind listing some of the applications of the free energy principle that, let's say reformulates
previously convoluted complex problems into something more simple and the different fields
maybe I can even when I'm editing this, maybe I'll even list like physics, and then here's how it
helps physics. Here's how it helps biology. Here's how it helps machine learning. So do you mind going through a couple examples? You can go through this quickly, because I'm sure you've done this
many times. And I'm mainly interested in a list. Well, that's a very interesting question. No, no, I haven't. So, but you're absolutely right. So, you know, the theory of everything that's,
which is, you know, I use in a rather cheeky way to interpret everything and it's thingness, which
is the theory is also, I think, claimed by this free energy principle in the sense you're
hinting at that it provides an explanatory framework, although albeit deflationary,
for many different disciplines. And you see that in terms of it really being the underlying maths
behind all kinds of explanations for behavior of a purposeful or systematic sort. So, for example,
you can interpret this quantity either cast as a variation of free energy, or the thing that it
provides an approximation to or a bound on, which is the log probability of being in attractive
states. You can interpret that in many different ways. And you spin off different kinds of
approaches in the life sciences and the physical sciences that suddenly are seen as just different
ways of expressing the same underlying mechanics. So, a particular instance here would be interpreting
the free energy as a value function, a negative, a loss function. Yeah. So, then you can write down
reinforcement learning, you can write down expected utility theory in economics,
you can write down optimal control theory in engineering. So, all of these things have in
common the notion that you want to have controlled dynamics that optimize some loss function. But if
the loss function is just the negative evidence or the free energy, you've now got an explanation as
to why all of these takes on interesting behaviors of the kind that economists and behavioral
psychologists and control theoreticians study, they're looking at exactly the right kind of
dynamics because all of these systems have to possess this fundamental property. And then you can not only, if you like, provide a unifying framework that you can now start to understand,
well, where does the Bellman optimality principle come from? Well, you can actually cast it as a
limiting case of a principle of stationary action, Hamilton's principle of stationary action,
when applied to a Markov blanket, which is just a free energy principle. So, if you wanted me to say in one sentence, what is the free energy principle? It is the application of Hamilton's
principle of stationary action to a Markov blanket. That's interesting. That's interesting.
So, where do you get the Bellman optimality principle from? Well, if you take away lots of uncertainty from the probabilistic treatment on offer from the free energy principle, you end up
with the Bellman optimality principle. So, that provides a unifying take on things like Bayesian
decision theory. When you put the uncertainty back in again, you get something which is now a mixture
of Bayesian decision theory and optimal Bayesian design, sometimes known as active learning in
machine learning. So, now you have a principle, first principle account of the so-called exploration
exploitation trade-off, which just dissolves in the free energy principle. The free energy has two bits to it. I won't go into the details, but in the same way that a good statistician is always
trying to optimize the evidence, the marginal likelihood of, or the evidence for, or the
variation of free energy associated with their model, they're just trying to provide an accurate
account of the data at hand that is as simple or minimally complex as possible. So, we come back
to algorithmic complexity under the hood here. So, in the same way, you've got these dual aspects
to the good inference, again, complying with Occam's principle, possibly even James's principle
of maximum entropy applied to belief structures or posterior beliefs, so Bayesian beliefs.
You've got this sort of dual aspect to what is a good inference, which has this sort of
accuracy on the one hand and the complexity on the other hand. And when you apply this in an inactive setting where you have to have to make moves and decisions and consider not just, you
know, me as a sentient organ absorbing sensory states, but I actually also act and choose where
to look, you get this dual aspect, which is basically exploration and exploitation. I want
to minimize surprise or prediction errors by sampling those things that I predict I should
sample by being warm and happy and befriended. But at the same time, there's also another aspect,
which is this epistemic aspect, this resolving uncertainty. So, if surprise and specifically
self-information, surprisal, if expected self-information is entropy, then expected
surprise is uncertainty. So, in minimizing surprise and in minimizing prediction error,
in expectation on average under particular decisions or choices I make, I'm also compelled
to minimize my uncertainty about the world out there generating my sensations. So, there's this
epistemic part that comes into play, which, you know, in the same way that the accuracy and the
complexity add together to give you the model evidence or the free energy, these two sort of
exploration, exploitation things just add together to give you the expected free energy. So, that to
my mind provides, you know, another example of the unifying aspect where you can, from a first
principle account, put together two seemingly completely separate strands of Bayesian theorizing.
On the one hand, Bayesian decision theory, which is all about making the right decisions under some
priors or some loss function. And on the other hand, good experimental design that, you know,
could be read as a sort of preparing approach to the scientific process or possibly beyond. But they're just two sides of the same coin. So, that's a nice unification that I repeat dissolves
things that I see as living in the 20th century, like the exploration exploitation dilemma. There
is no dilemma. It's just how precise are your preferences that drive that sort of,
that technically what is actually a risk. So, the complexity, when you take the average
complexity of the free energy under some expected outcomes before you've actually made a move on the
world, that becomes a KL divergence between what you anticipate will happen and what a priori you
expect to happen. So, that's risk in economics and in engineering, sometimes known as KL control.
Mm-hmm. And what does KL stand for in the divergence? Sorry, Kullback-Lieber, which, so it's just a particular, well, it is just a relative entropy.
It's just a measure of, in fact, it's not a measure, that's, I should, it's a way of
quantifying the divergence between two probability distributions. Mm-hmm. It's a measure in the deflationary sense.
Well, actually, no, no, that's very clever, but technically wrong. The reason I caught myself was
the KL divergence between A and B is not the same as between B and A. So, it's not a metric measure,
which is why I can't use the word measure. So, it's not a measure, but it's like a measure. So,
that's why it's called a divergence. So, it's just a relative entropy. It's a way of quantifying
how much you, you know, if you read a Bayesian belief as a state of mind, how much have you
changed your mind? And the key thing at the heart of, if you like, applications of the
free energy principle to inference and active inference and Bayesian decision theory and the
like is the divergence between your beliefs before seeing some sensory evidence and afterwards.
So, if you're a Bayesian statistician, this would be the KL divergence between the prior and the posterior. Literally, how much you've changed your mind or moved your beliefs in response to
assimilating some new data. Okay. Am I supposed to understand surprise as equivalent to a mismatch between what you predict and what actually happens? So, error?
Right. That's an excellent question. Is it more complex than that? Well, it's, if you want to get into the nitty gritty. So, surprise read as surprisal is a very
simple concept. It's just the self-information. It's the negative log probability of some outcome,
usually a sensory state of your Markov blanket. So, if something is highly improbable, or if the
outcome or your sensory state, say your physiological or sensed physiological state
is highly unlikely given what you are. So, the usual example here is a fish out of water,
for example. That has a lot of surprise. It just means it's just a euphemism for self-information
that scores the kinds of outcomes that would be characteristic of this self-organizing system.
So, it's just a way of writing down or scoring the probability of being in this state, if you're that kind of system or technically, if you have that kind of pullback attractor.
There's another kind of surprise, which is the Bayesian surprise, which is often confused with
that, which is, I think, closer to the notion that we're just talking about, which is the degree to
which something causes me to change my mind with the information gain, which is about the
complexity. So, the complexity, basically, if you're looking at this as a statistician, you're
given some data, and you had some prior beliefs about what caused those data before you saw the
data. And then you use Bayes' rule to combine the likelihood of those data, given your beliefs about
how they were caused with your priors, you come up with the posterior. So, posterior, after seeing
the data, this is now your belief. So, you start with your prior belief, and then you have your posterior belief, and then there's a movement. And that movement is this KL divergence that we're
talking about that scores the amount you've changed your mind. That just is the complexity.
It's the complexity cost that you have paid for providing a more accurate account or an accurate
account of the data that you've explained that has moved your beliefs from priors to postiors.
So, it is the cost of changing beliefs in order to do belief updating or Bayesian belief updating.
I'm going on about that because it's quite interesting, though, because, you know, via things like Landauer's principle and the Jasinski equality, that degree of movement
costs thermodynamic energy. So, that tells you that a good artifact, a good person or a good computer
On Occam's Razor and Artificial Intelligence
from the point of view of existential goodness as scored by minimizing free energy or maximizing
marginal likelihood on model evidence is the kind of person or computer or artifact
that when confronted with some new information will actually process and assimilate that in a
really thermodynamically efficient way. So, they'll do it with a very cool brain. They won't
use very much electricity or food and very little will change. And what that basically means is
their prior beliefs were already quite close to the posterior beliefs. So, they already had a good idea of what's going on. So, they were not surprised. And in not being surprised or trying
to minimize that complexity cost in terms of the price you have to pay for providing an accurate
account of some data, you are also maximizing the efficiency of your belief updating. So,
I think that's quite a nice thing because what it says is if you're going to build good artifacts, good artificial general intelligence, what you're looking for is a
really small thing that can be powered with a battery. That's the kind of thing that'll do the
best kind of belief updating. It's really tailor-made for the inference problem at hand.
So, we wandered away from your question about what surprises, but the other surprise is just
basically the implausibility of this happening to me, basically. Curt Jaimungal
When you were talking about what makes a good computer or a good person, and you're using good in a different manner, I assume you're using it in terms of adaptive or effective or accurate or
at least not using too much energy to accomplish its tasks. That to me sounds like
almost a restatement of Occam's razor that you want the minimal assumptions to account for the most data. Is that similar or no? Dr. Raghuram Rajan
Oh, no, it's exactly the same thing. So, that's excellent. Yeah, no, that's exactly so. You know,
the pressure to provide a simple account of the data is exactly getting this, paying the least
complexity cost possible for the accurate or the fitting. And that is exactly Occam's principle.
And if you don't know that that's important, and that's probably more important than the accurate fitting, then you will end up with machine learning artifacts and devices and
schemes that overfit. And if they overfit, they don't try to minimize the complexity of
the explanation at hand or effectively their inference. Then you will get an inference
and learning that does not generalize. So, inevitably, if you allow for overfitting,
then you overfit today's data and tomorrow's data are very difficult to explain because you've
over explained today's data. So, just practically what this manifests as is a problem of sharp
minima and difficult to solve optimization problems in machine learning. You get stuck
in local minima that have a very, very difficult. And that's because you haven't flattened the
minima by building into your objective function, this simplifying aspect, this complexity
suppressing aspect. And of course, once you have an objective function, which actually entails
that complexity minimizing imperative, then the minima by definition, the free energy minima,
are always shallow. So, that you've got a lot of latitude to wander around your minima. So,
you're not committing to a particular sharp explanation of over explaining the data. So, it's a really practically really important observation that I should say that when I talk
about good, I just mean minimizing free energy or maximizing evidence. So, that's the only good
for me, which is fit for purpose in this world, having a good model of this particular world.
Let me see if I can explain what I heard in another manner. Let's say you're playing roulette,
what you want to do is you want to have a minimization of your mismatch of prediction
versus actuality. But let's say you have a good reason to believe that 33 black is going to be hit.
You don't put all your eggs in that one basket because you could be wrong. So, you need to have some spread. It's not a direct delta function. It's not just that. And then that spread is
equivalent to entropy. Is that correct? Because there's a trade-off between you wanting to be
completely accurate, but then leaving one's options open. Yeah, no, that's absolutely right. So, that, well, you use that wonderful phrase,
leaving one's option open, having that latitude in play is a very important aspect of this
expected complexity, minimizing imperative that you get from, you know, sort of trying to minimize
the expected free energy, expected following a particular choice or action. So, just in that
particular instance, you know, if you are acting according to expected utility maximization and
you thought that the black 33 was the most likely outcome, then you put all your money as a delta
function on the outcome. That's not what KL control does. That's not what risk sensitive control,
it's not what the sort of the exploitative part of minimizing expected free energy does. It tries
to match your anticipated outcomes with your prior beliefs that incorporates exactly that kind of
uncertainty. And indeed, there may be situations where your behavior at the roulette table
is, doesn't look as if it's just about trying to maximize the amount of money that you'll get
following the bet. You may be sometimes compelled to engage in epistemic behaviors that resolve
uncertainty. So, say that you have the hypothesis that the roulette wheel was rigged, and it was
rigged in a way that depended upon the way that people placed bets, then you might actually place a bet just to see what would happen in terms of what the person who's in charge of spinning the
wheel does. So, you know, not every move is just about minimizing some or realizing some prior
preferences or minimizing some loss function. A lot of our moves are actually to resolve
uncertainty and disclose things that we don't know, resolve our uncertainty about the contingencies
under which we're operating. So, then you can get into some sorts of interesting paradoxes in terms of deceit and regret and making moves just to reveal what's going on
out there, and particularly in transactions with other people. So, that's another, you know,
just beyond the KL, the engineer's perspective on KL control, the matching behavior, which is in psychology, this, you know, you try to match the probability distributions
on, from which you sample your choices to the underlying payoff structure at hand.
So, that, you know, that would be one way of looking at the utility of a KL control or risk
Newcomb's paradox
sensitive kind of control. But beyond that, there's also explicit sort of uncertainty resolving moves
you can make, such as checking which is a fair gambling house and a non-fair one on Google before
you actually start, you know, commit to going to gamble in this house, as opposed to that house.
Yeah. Speaking of gambling, have you heard of Newcom's paradox?
Oh, okay. Well, look it up at some point. I'll say it here. But the paradox is, imagine you go to
a circus tent, and then someone says, here's a box, it's clear, and it has $1,000 in it.
That's box A, then box B is sealed, can't see it. But the fortune teller inside there says,
I think it's you can choose either the sealed box or both boxes. Those are your only choices. Now what's in the sealed box is $1 million.
Ah, I'm messing it up. You'll just have to look it up. It's something please let me spasmodically,
verbally vomit here for a second as I try and get it correct. Because it's actually it's an interesting paradox. And I wanted to know what your theory had to say about it. Now, obviously,
you can't answer that in real time, because you might have to think about it. But something like, okay, you have a sealed box, you have $1 million, $1 million may be in it, or it's not. I'm trying
to work through what the actual paradox is. The fortune teller says, I have predicted I'm 100%
correct. Maybe there's a sensor, you can say there's a sensor that analyze your brain, and it knows what you're going to do. And she either put $1 million in it, or didn't, depending
on if you depending on if you choose, ah, right. She says, if you're going to choose this single
box, just the box alone, the sealed box, then I've included $1 million in it. I've already predicted
which one you're going to do, by the way, but I'm just letting you know, if you just pick the sealed box, you get $1 million, I put $1 million in it. If you choose both boxes, because you're
greedy, I put nothing inside the sealed box. So then the question is, what do you do? Now you have
to make many assumptions, you have to assume she's telling the truth when she says that she's able to predict you with 100% accuracy. But even if it's 99% accuracy, the paradox still holds.
The question is, well, what do you do? You may say, okay, now that I'm there, she made that decision beforehand, the million dollars is either there or not, I might as well take both boxes. So
that's one way of reasoning through this problem. But another one is to think, okay, all the people
that just selected the sealed box, get 1 million. Because that's the way that she said it's worked.
She said, also that, hey, I've done this millions of times, and I've always predicted correctly.
So then what do you do? Do you risk taking both boxes? Or do you just take one? And it's,
it shows a difference in I forget what it's called either causal decision theory. And
there's another type of decision theory, one where you maximize evidential based decision theory.
So usually those two imply the same solution, but here they don't.
Anyway, I wanted to know what the free energy principle says one should do, because it's a famous paradox. Let's forget about that, then. I'm gonna have to go and Google that way.
It sounds even more complicated than the Monty Hall paradox problem.
So that sounds intriguing. So yeah, and so the paradox is, is basically the paradox that is
FEP - a Law of Nature or a different way of compressing?
confronted by you in this situation, as opposed to paradoxical behavior that people actually...
Right, right, right. You want to maximize the amount of money. So let's assume you're instrumentally rational, that is you want to maximize your your pleasure, whatever it is,
what do you do? Okay, so forget about that. Something I was wondering about the free energy principle is how much of it do you see as a principle like a law, like a law of physics,
versus a compression mechanism. So for example, what I mean by that is when you
look at Maxwell's original paper for his four laws, there are actually 26 different equations
or 24. It's two pages long, because he didn't compress it down to the four that we now use.
So these four aren't actually four equations, they're just code. And then I always wondered,
how much of our Lagrangians are... Sorry, the minimization of action is an actual principle
of nature, versus this compression mechanism that says here are your complicated equations of motion,
what you can do is you can package it into this simplified little Lagrangian that you then
put into the Euler-Lagrange equations, and you crank out the equations of motions. So it's not actually a principle in and of itself, it's more like a zipping of something
that's convoluted. So do you see the free energy principle as a law? Or do you see it as akin to
what I made an analogy about with Lagrangian mechanics and the Lagrangian? That is, it's just
compressing, could just be compressing? Yeah. I think that I see it as a law. But I think that
distinction is very nicely articulated. And I think it's really in play in my world in a slightly
different way. So I repeat, the free energy principle is just a variational principle of
stationary action, cast in terms of density dynamics of things that have Markov blankets
and by implication at steady state. So it plays a role, exactly the same role as Hamilton's
principles of stationary or least action. So it either applies or it doesn't. So it's not a theory
and in many senses, it's not very useful. It's just a way of writing down and zipping things
up as you nicely put it. And an internally coherent way that speaks to sort of, as all,
I think these useful principles do some symmetry or some invariance property.
For me, the variational principles of stationary action are the simplest and most graceful way of
expressing these symmetries. You can do it with gate theories or I'm sure there are other
formulations. But for me, the best way is just to use that principle of least action or stationary
action. So that's what the free energy principle does. But as you say, for the free energy principle,
what does that actually mean in practice? Well, it means that anything that exists can be understood
and simulated or built as a gradient flow on a free energy function, a function of what? Well,
the free energy is a function of the states, the data, the states of the Markov blanket
and the Bayesian beliefs about the posterior beliefs about the causes of those data that are
encoded by the internal states. So where does that, where does the, where do those beliefs
come from? Well, they're defined or the free energy is defined. If you think of the sort of
prediction error version or reading of free energy, they are defined by a generative model that
predicts the sensations that you would get if that model was right. So you have to have a generative
model. So, you know, there's going to be a universe of generative models you could plug into the
underlying gradient flows, the Helmholtz decomposition that we talked about that
basically describes all dynamics, you know, for systems that can be cast as a large valve
with Markov blankets. So the question is not so much now the free energy principle or the application of a variation principle leads to action, but really what is the generative model?
So at this point, I think then you move away from the principle and you start now to get into the world of process theories and hypotheses. So, and you can ask that question, or you can have
those hypotheses at a number of different levels. You could actually take a working system, a person, say if you're a psychiatrist, you know, somebody who might have an obsessive compulsive
disorder, and you may say, well, I want to understand them now as making decisions under
some model of their lived world, some generative model. I know their neural dynamics and I know the
principles that underwrite their choices, but what I don't know is their generative model and their prior beliefs. So I'm going to now reverse engineer on the basis of their behavior. What are their
prior beliefs? What do they actually believe is going on to best explain this behavior? So that
will be one application. Another application might be building artificial intelligence machine
artifacts, you know, where I now write down the prior preferences of a generative model,
the kinds of states that I want this system to aspire to. And I then just let it, you know, I just
equip it with active states and actuators and sensory states and sensors, and I make a little
robot and off it will go and it will go and epistemically forage, always with a mind to
learning about its world, but also under the constraint of its prior preferences, like keeping its battery charged. So that will be another instance. But in both applications, I've had to
either reverse engineer or commit to a particular generative model. And that's where I think we,
you know, you moved a long way away from principles. And if it's a question about,
does this person with obsessional compulsive disorder have this kind of generative model on that kind of generative model? And that's now a hypothesis that we falsified with respect to the
evidence. If it's a question of building an artifact, do I use a discrete state space
generative model or a continuous one, which means I'm now committing to different kinds of message passing. If it's discrete, it could be a variational message passing or belief propagation.
It's continuous, I'll be using things like linear quadratic control or Kalman-Busey filters.
So again, you're now in the mechanics of the processes that are realizing these gradient
flows. And of course, there are no principles or rules that tell you you're right or wrong.
These are all process theories that might work and that might not work. So, you know, I think the
zipping that you talked about is, from my point of view, it's basically unzipping the principle
to realize that under the hood, it is the generative model that supplies the free energy
gradients that drive the gradient flows. That's the big open question and getting the generative
model right is in most instances, scientifically or indeed in industry, and possibly even in
Jordan Peterson's "order and chaos" and the FEP
medical translation of these ideas in medical practice. It's all about getting the right
kind of generative model and your hypotheses about that generative model.
You said a couple of statements that reminded me of Jordan Peterson. Now, I'm not sure how much you follow Jordan Peterson at all, but he's a proponent of watching what someone does to
their beliefs. So that is okay, well, you're not yet so you understand what that means. And then number two, he also mentions order and chaos and the balance between them, which is Taoist that
you don't want the elimination of one or the predominance of another, you want a special
balance between them, which reminds me of what you said about surprise, and then I believe it's
KL divergence. Right? Okay, you don't want one to dominate, there's a delicate balance. Have you
heard Jordan Peterson speak on order and chaos? And do you see any correspondence between
the free energy principle and what he says about chaos and order? Yes, I think so. I mean, I would, I would put this, I mean, there are a number of different
routes one could take to that kind of issue. You could ask yourself, is there any first principle
account, for example, of self organized criticality? So you remember the edge of chaos
notions from the Stuart Kaufman and self organized criticality, that was the self I was trying to
remember before, but that's another one of these branches of physics, which starts off with self,
so SOC, self organized criticality. So this is a notion that it is inevitably the case that any
self organizing system will organize itself to a regime of critical slowing and dynamical
instability, which, you know, Stuart Kaufman might might might have articulated in terms of systems
moving themselves towards the edge of chaos. So towards separatrices, towards sort of bifurcation
into regimes, usually associated with multistability or metastability,
depending on the nature of the dynamical system, but this tendency to, to,
to put yourself in a state where you have a repertoire of dynamics available to you,
simply because you are near disorder, you're near chaos. So, but you never actually go chaotic,
you just increase the latitude of, of, of, or the repertoire of things, you know, of dynamics that
might happen to you. And that, from that perspective, then there are sort of, there are,
I think, a number of interesting things that the free energy formulation brings to the table.
The first we've actually already touched on, which was this building in to an optimization
perspective, shallow minima, to preclude the existence of sharp minima. And just by having,
effectively, Ockham's principle baked into your understanding of life, or indeed any kind of
self-organization, as you're trying to optimize this bound on evidence or marginal likelihood,
then you're necessarily saying that you want to have these low curvature minima, you want to
occupy low curvature minima. That if you, if you now ask, what would that look like in terms of,
you know, coupling between internal and external states in the context that the,
the gradient flows are informed when, when at free energy minima by very shallow gradients,
what do you get? Well, you get exactly this sort of, this latitude for excursions, which have a
long correlation length. So you get this, you know, the kind of critical slowing that is associated
with self-organized criticality. So often, so a heavy tail distributions in terms of, in terms of
sort of covariance functions, for example. So I think there's a simple and mathematically
and deflationary account of the balance between order and chaos, at least,
from a purely dynamical perspective that is on offer via the minimization of free energy with
gradient flows, simply because you are dealing with minima that don't trap you. They allow for
that latitude so that you avoid. I see. I see. Particular solution. Now sharp would be too much
order. Absolutely. Yeah. So you just get locked in. You get, you literally get stuck in a rut. You get locked into this particular explanation and any slight movement away from a very sharp
minima incurs an enormous penalty. Right. And you just don't make that move. But if you've got a
very shallow basin of attraction, if you like, and I repeat, I think the beautiful thing about
the sort of the free energy functionals or this free energy functional is that it's built to be
shallow. Perhaps an analogy would help here that if you think of a free energy landscape that
is paraded by a mountain landscape right from the high, the mountains in the Scottish Highlands,
right down to the estuaries at sea level, then what you typically tend to get is that very high
terrains of any landscape have lots of high frequency ravines and sharp valleys and sharp
minima. So there's a little stream at the top of a mountain will be carving its way through very sharp
trajectories and then meeting slower and slower and wider and wider streams as it comes down the
mountain. But also what happens is that as you come down towards sea level, as you get to lower
and lower free energy levels, the terrain itself becomes smoother. So all the minima now have
smaller curvature so that you don't get those sharp little landscape features that you saw high
in the free energy or high in the mountains anymore. What you get now, a much more gentle landscape where everything, because it's a lower altitude or a lower free energy, has to be
smoother. By Ockham's principle it has to have less of a curvature. And what that affords is
the latitude for the river now to start meandering around, sometimes following oxbow lakes and
features. This kind of meandering that you see as a large river starts to wander and oscillate
as it gets towards the estuary and gets towards the sea. And it's that sort of wandering around
which is, if you like, the sort of the permissive or the reflection of what can happen
with a low curvature free energy function or objective function. Which is in itself,
in the sense that if the system is trying to minimize its free energy and get to those estuaries so it can do its one slow wandering around, you get this critical slowing that you see dynamically
that characterizes all kinds of interesting behaviors from sort of avalanches in, neuronal
avalanches in the brain through to the markets. In the old days this might have been known as catastrophe theory. But it's the same notion that we're close to the edge of instability,
which means we have the latitude to explore different states on some objective function
that we wouldn't have if we were stuck in a rut and committed to a particular solution. We've overfit the data, for example, or we've got trapped in a local minima. So that's one thing.
There is another aspect though, which we haven't touched upon, which
I think nicely follows on from this notion of getting the generative model right.
So if you remember the free energy functional or the model evidence needs a model in order to have,
so the model can have the evidence. And of course, most of the time you're dealing with
models that have unknown states, such as models that underwrite things like Kalman filters,
unknown parameters, such as the generative models that might do weather forecasting.
But there's another level, which is the very structure of the model itself. So, even if I knew
all the states, the time varying unknowns generated by a particular model, and even if I
knew exactly all the particular connection strengths and rate constants and all the other parameters and contingencies, you would need to know to make this model predict the perfect data,
perfect explanation for this observed world. I may not know the structure of the model.
So if I was doing say deep learning, and I wanted to build a deep convolution network,
how many layers do I use? Two, four, eight, 16? So these are really important architectural
structural problems that are attributes of the model. But the model can always be scored given some data in terms of its free energy or elbow evidence lower bound, which means there's always
an answer if you can create a space of models to evaluate. So this is known as in cognitive
neuroscience by people like Josh Tenenbaum, structure learning. And it's the problem of
basically exploring the right structure of models by you're adding things in, taking things away,
collapsing things together. You talked about modularity before. That's a really important architectural aspect of these models, usually cast in terms of factorization,
exploiting conditional dependencies to get simpler models that you can have a modular
architecture in the generative model. So all of these structural, the hierarchical depth,
the degree of lateral factorization or modularity, the number of parallel streams,
the number of nonlinearities, all of these things need to be optimized to get the good model,
the free energy minimizing model. So how would you do that? And it's at this point that you come back
to disorder and chaos. So one really efficient way of exploring a space of models is to actually
exploit the chaotic dynamics that you get or at least stochastic dynamics that you get, for example,
in natural selection. You could take arguments from evolutionary theory and again, coming back
to Stuart Kaufman in terms of his formulation of selection for selectability. Have you come across
this second order selection? No, actually, the way that I encountered Stuart Kaufman was reading
about his expansion of Schrodinger's What is Life? And then Schrodinger posed three questions that
is how, whatever, he posed three questions and Stuart Kaufman answers the second two, so two and
three. All right. I didn't read much about him afterward. And I'll ask you about Stuart afterwards. But do you have to tell me what the questions were? That sounds very interesting. Yeah, sure.
I'm talking about his work on sort of more sort of artificial life that speaks to this edge of
chaos and the necessary role of disorder or chaos in any evolving system that needs to explore
different ways of being. So it's interesting because, of course, you can now, the degree of
chaos that you bring to the table, the degree of mutation, for example,
there will be an optimum degree of mutation that depends upon the volatility of the environment and the degree at which you exploit or leverage chaos now becomes subject to selective pressure.
And just as an aside, you can always recast selective pressure as basically a pressure to
minimize free energy if you read free energy as the adaptive fitness of any phenotype in a
natural, a set of natural selection. So what he's saying is that there is an optimal degree of
changeability and chaotic exploration of of any model space or any way of being that, to my mind,
provides a very nice perspective on this tendency for self-organized criticality, that we actually
move ourselves to the edge of chaos just to position ourselves so we can explore and make
sure there are no better ways of doing things. So I think that that aspect of the right mixture of
order versus disorder, order versus chaos, you know, comes out at the level of the structural
Using brain structure to infer about the world
learning itself and the sort of the repertoires of different alternative hypotheses about, you know,
modeling our world or making making decisions in that world. Okay, when we're modeling this world, most of the time, what we do is we look at nature,
and then we see principles. And then sometimes we can infer about the brain. So let's say we understand how atoms assemble, then we understand the molecules assemble, then we understand
cells, and so on. So obviously, it's not as simple as that. But then you in one of your interviews
posed another mechanism, that is that we can look at the brain structures, and we can infer about
the world. So for example, I believe you said that the fact that an axon is long and reaches out is
a reflection of spooky action at a distance or action at a distance. And then I was thinking,
well, what about the hierarchical structures of pyramidal neurons? Do they reflect that our world
is hierarchical? And first of all, why would that be the case? Why does it have to be mirrored?
Second of all, there's another structure that is the bi hemispheric structure of the brain. So one is, I know, there's a fair bit of myths about the brain, left brain versus right brain. But there's
also some truth to some parts of that. Now, Ian McGilchrist, I'm sure you're aware of his work,
or his name sounds familiar. He explored that as well. So my question is, what can you infer?
Well, why does it have to be the case that your internal structure of your brain would mirror reality in some manner? And second, what about the bi hemispheric structure? What does that say about
our world? Okay. That's a really good question, which could, you know, could take us in a number
of different directions. The notion that the, if you are in the game of predicting,
minimizing surprise, through the lens of minimizing prediction error, then you want
to generate a model that can faithfully but simply reproduce the kind of sensory data,
sensory impressions that the world is generating. So the formal structure of the process that
generates the sensory input has to be to a certain level recapitulated on the inside in order to
generate and afford those, the right kind of predictions. So that is a statement.
Really, I think, the good regulator theorem, which arose towards the end of the cybernetics
movement by people like Ross Ashby, sort of, you know, regarded by some as a father of
self-organization, this notion that every system that controls or regulates its environment must,
in essence, be a model of that environment. So there's an isomorphism between the controller
and the controlled. And that certainly is the case. Is it an sorry to interrupt? I'm so sorry. Is it an isomorphism? Like, is it exactly mirrored?
Because I recall when I was speaking to Bernardo Castro, he said, we can't model our reality exactly. Because if we did, we would dissolve into an entropic soup. And then I said,
what do you mean? And then he said, the argument was, it was too convoluted for him to state at
the time. And I think he was referring to you. So is it isomorphic? Or is it just
No, you're absolutely right. It's certainly not isomorphic. Because as you say, if you want, when the best model of the world is the world itself, I mean, that's, that's the truism,
whichever everyone celebrates. And so, no, it's a, it's a sufficiently good model or an
ultimately good model in the sense that it's the simplest caricature of the system or parts of the
system, the subspace you're trying to control. So, you know, I still think it's useful to consider
the good regulator theorem. But you're right, it's not, not isomorphic in any sense. It's
even less so when you when you consider that a lot of the time, we actually build our own sensations when we move. And certainly, in terms of sensing our own body, you know, we are in
charge of basically creating that sensorium. However, let's just stick to the original
question. You know, so no, it's not, it's not an isomorphic, but it certainly has the right
architecture to be able to produce a simplified summary or prediction of what's going on,
that is conserved every time around. So, you're only interested in predicting
things on average, so that you're revisiting particular states. So, you just need to get the
gist of what's going on. So, it's a much simpler one, but it's still fundamentally have the same
kind of causal architecture, the same conditional dependencies. And you've highlighted a really
important one, which is the, the, the symmetry between our two hemispheres. The, you've also
mentioned this, this, which I'd forgotten about, which is the, or the very existence of
neuronal processes, long, thin connections that our neurons are equipped with, which you won't
find anywhere else in any other organ. You know, the liver doesn't have them. The heart, to a
certain extent, does have fibers, but they're not, they're not nice and long. Which, which,
you know, just reading the structure of the generative model is telling you something about the kind of universe that's generating the data that this model is trying to predict,
tells you immediately you've got action at a distance, which is not necessarily a given,
but it tells you that this creature must contend with a world where there's some kind of action
at a distance. It can see things in the distance, for example. So, you know, the contention would be
if you had a, a worm that could not see things at a distance, then it probably wouldn't have
very long axons. And it would be quite comfortable having lots of short range axons that were quite
sufficient for modeling a world where it's just immediate contact and short range causality that's
generating its sensations. Okay. Quick question. So I'm speaking to a camera right now and its
sensor is fairly flat and yet it can pick up from far away, it can pick up a mountain. Now,
I understand that the camera isn't acting on the world. Are you saying that if it was to have some embodied enactment, then it wouldn't use the sensor in the way that it's formulated right now?
It would use axons in some way, would use long wires in some way? You'd, if you actually, well, okay, let's pursue that, that analogy then. So, so, you know,
let's assume you're going to be using some kind of VGI, computer graphics to generate
a visual scene that you could use in a movie. So what that would necessitate is basically a machine
with lots of wires because it's all action at a distance. So you couldn't do it on a computer
that didn't have big buses and the ability to move data around in a way that would recapitulate the
action at a distance that is necessary for VGI. So particularly sort of the ray tracing that's
required to basically render a scene. That's massively computer intensive, that requires a
lot of, if you like, hardware that you cannot do with just local computing. You actually have to do
lots of message passing. Yeah. And we're talking now about sort of the architectures that computer scientists would use. So it's just that there are certain computations you can do
without sort of the kinds of architectures you'd find in computer science that just involve local
interactions. But as soon as you have to actually generate virtual worlds or worlds that entail
action at a distance, you get a different kind of connectivity and a different kind of structure. So that's what I was really trying to intimate there. My favourite example is, before we turn
to the inter-hemispheric one, is a differentiation between a dorsal stream and a ventral stream,
primarily concerned with what things are and where they are. And this speaks to that modularity
that we were talking about earlier on, that somehow our brain has found a really simplifying device
to create a modular architecture by leveraging the conditional independences between what-ness
and where-ness in objects in the kind of universe we live in. So put that simply,
you're knowing that this is a cup doesn't tell me where it is. Knowing something is over there
doesn't tell me what it is. So that means that if I'm trying to generate predictions, I only need,
I can have one part of my brain doing the what-ness and the other part of my brain doing the where-ness, and then I can bring them together to actually explain the sensory input. And that,
keeping things apart, keeping these parallel streams apart, means I don't have to have
the complexity cost of all the connections between them. I don't have to represent every object in every position in the world. I can just represent what it is and where it is,
and then just bring them together as part of my generative models. So that tells you something
quite fundamental. If I find a brain that has this segregation into what and where, I know that they
live in a world of objects where in their universe, things are conserved when they move around.
Ah, aha, aha, interesting. So that brings us to the delicate issue of why we've got symmetrical brains. I think quite
simply because we've got symmetrical bodies. I think that, you know, but then you may be asking
why we've got symmetrical bodies, but so I'm not going to try and answer that. Well, I was actually referring to the asymmetry of the brains.
All right. That the left, as let's say, Ian McGilchrist would say that the left is more concerned with
manipulation and pinpointing, making definitive, and the right is more concerned with exploratory
motion. So even actually at nighttime, when you're looking for your watch or your clock, you actually explore with your left hand because it's controlled by the right brain. Naturally,
you move, you make more exploratory movements with your left. I'm not saying anything you probably don't know. And then with your right, most people are right handed. And they like to
well, whatever. So then I was wondering, is that a reflection of what the world is composed of or comprises in some manner? And then also, how does one know when one is taking
this too far? So for example, just because the brain has a morphological structure of folding this and gyruses and sulky and so on, doesn't mean the world is foldy.
Or my experiences is hilly. How does one know when to apply it and when not to?
So I was just thinking about all your challenging questions one by one. I like the one about the
the world isn't folding. That's very nice. And mystically, one can make an analogy and say, well, the world is complex and fractal like and
nothing is ever the same. And you can look at it from multiple vantage points. So it sounds to me
more like one is playing a linguistic game in that example that I just gave, rather than actually giving a property of the world that's reflected in the morphology of the brain.
Yes, yes. So I don't have just remembered that I saw a presentation by colleagues of mine
recently that actually, interestingly, made the foldedness a possible reality.
But that's a distraction and a unique and very exciting observation. But you're right. So when
I'm talking about structure, the only structure that matters is the same kind of structure that
underwrites a Markov packet, is conditional dependencies. So I'm talking about a connectivity architecture here. I'm not talking about the physical shape of the brain. I'm just talking
about what is connected and what is not connected. So all I need is the graph, if you like, if you're
a graph theoretician. I just need the adjacency matrix or the connectivity, usually the directed
connectivity matrix. That, to me, is what defines the structure. So at that level,
the kinds of structures that can be defined purely in terms of the adjacency or the edges on a graph
are things like the number of hierarchies or the number of parallel streams or the number of modular
modules or clusters, the degree of small world, if you like, or clustering indices. I can't remember
all the graph theoretic terms for them. But crucially, it's just that defined in terms of
connectivity. And I think you can, within that remit, without going into the world,
which I agree with you, is a brilliant sort of sanity check. I'm taking this too far.
But within the remit of instantiating and biophysically realizing causal contingencies
and associations in terms of connections between biological systems, in particular neuronal systems,
I think you can, I think you can, I think you can, I think you can, I think you can,
I think you can actually play this game and play it for quite a long time in terms of the hierarchical depth and in terms of this modularity and this factorization that we just talked about.
And in particular, the hierarchical depth, I think, is a very important one because, you know, you're asking me, well, why should the world be hierarchically structured?
But it is necessarily hierarchically structured if one just considers a separation of temporal
scales. So, you know, there just has to exist in terms of a coarse graining applied to any
dynamical system, a progression of slower stuff that is, you know, more coarse grained aspect to
it that you could add, you know, you could elaborate recursively, you know, in principle,
you know, for an infinite number of levels. So, there does exist causal structure out there
in any sparsely connected in the dynamical sense world that I think fully licenses an
interpretation of the corresponding architecture and in particular its hierarchical depth as
somehow mirroring or reflecting that hierarchical structure out there with the obvious example of
course is all of that machinery, that aspect of our brains that is devoted to providing an
apt generative model for interpersonal interactions. So, you know, if one realizes that
most of our lived world is, or at least the sensations generated by that world are generated
by that world are generated by other creatures like me, namely you, you know, whether we're
driving around in cars, walking in parks, talking on Zoom, reading books, 99.9% of our sensorium
is generated by another human being that is like me. So, that actually says there has to be a lot
of the brain has to be devoted to modeling me and people like me and making inferences about me.
On hierarchies and modelling different "things" (tools don't behave like apples)
And as soon as you start to get to this, think about what kinds of generative models would be
fit for purpose in that context, then the imperatives to resolve uncertainty are basically
the drives for me to understand you. So, this epistemic part of the free energy minimization
as a consequence of action translates into an imperative to understand the world, but the
lived world now is basically you in this instance. I need to understand you. How do I do that? We have
to have a shared narrative. What does that require? Language. It could be maths, it could be English,
but that narrative has many, many different scales to it that has itself a deep temporal structure.
So, there's the concept that I'm conveying, there's a temporal scale of the duration of this
exchange. There are recursively much finer temporal structures in terms of the structure
of the sentence, the phrases that I'm using, the words, the phonemes, all the way down to
the millisecond by millisecond activation of your sensory epithelia in your ears or my neuromuscular
junctions controlling my articulatory apparatus. So, we wouldn't be able to talk to each other
or comply with this imperative to resolve uncertainty, to explore the world that I have
to model without language and without a deep generative model with a deep hierarchical structure,
there can be no language. So, there's a natural, if you like, not pressure, but there's certainly
an easy way to understand why we have deep generative models in our brain. In fact, we do.
Nearly all the interesting architectural aspects of brain connectivity speak to a hierarchical
organization at some level. It's cortical, subcortical. The very word sub means below. Below is only an attribute of hierarchy. It can't be anything. The visual hierarchy being the poster
child for very well defined subsumption hierarchies. But beyond that, wherever you look in
the brain, there is some hierarchical organization where slow stuff is entraining fast stuff at the
low below and then all the way down to the sensory inputs and the actuators or the active outputs,
which are the fastest parts and the elemental parts. Okay. So, hierarchy is another way of
saying difference that can be compared. So, again, so hierarchy, a difference that can be
compared. So, these two are different, but there's no hierarchy between them if it's like someone may say apples and oranges. But if it's between apples and two apples, then there's a hierarchy there,
because there's a quantity that we can reduce down and put a comparison between them. I see. Yeah, no, absolutely. So, the height, the way I'm using hierarchy here is certainly
sort of, so when people talk about say deep learning, what they're talking about is inference
and classification under a hierarchical generative model that has a number of hidden layers. So,
the depth of the learning machine refers to how many layers you build. And so, what you do is you
set put the data in and then you try and explain it with one layer. And then those explanations
are that you then try to explain it with a layer on top of that. And then you keep on going until
ultimately you get to some very, very coarse grained, very abstract explanations that are
predicting, if you like, the layer below. And then they're unpacked to predict hierarchically,
right down to the level of say, pixel elements in a TV screen or sort of, you know, some image
that's been grabbed. So, the deep, the hierarchical depth is basically how many subordinate layers do
you have? I see. There's one higher level providing, getting information from the lower level,
but also providing constraints, saying, well, if this hierarchical, if this context is in play,
then I expect this kind of thing to happen over here in that modality, that kind of thing to happen over there in that modality. So, it brings a simplification and a better way of modeling,
provided that you've got this hierarchical structure. What you were talking about, I think, is more the modularity of the sort of, is this an apple or is this an orange? I think that within
the hierarchy, within the depth from sort of, you know, the lower level, which are usually at the
level of the sensors and the actuators, and the higher level is usually the top of a pyramid.
Of course, you know, there isn't a pyramid in the brain. You can imagine it more like a circle and the center being the deeper parts of it. So, but there's an other architectural structure,
which is not in the depth of the hierarchy from the bottom of the circle, say, to the center,
but actually the different streams you were talking about, the apples and oranges, and it's that factorization, that what and when, as I was, you know, hinting at before, which is a lovely example
of, you know, things I know about oranges are not relevant to things I know about apples.
I mean, that's probably a silly example, because there are things that I conserve, but things I know about fruit are not going to be terribly useful for things I know about tools.
So, I can actually have my generative model generating a cascade of abstract representations
becoming more and more detailed and committed, right down to a picture of, or a sound of, or me
moving this particular artifact. But, of course, this artifact can be either a tool or a face,
you know, or an apple, a fruit. And because you've got, you know, these conditional dependencies,
tools don't behave like fruit. And I don't, in particular, I don't actively engage with tools
in the same way that I engage with fruit. I eat fruit, but I use tools. So, it's likely that you
get this separation through this factorization or modular parallel architecture
in the setting of a hierarchical composition. So, these are really important sort of architectural
principles if you have to actually build or understand the brain. But also, if you wanted to build a conscious artifact or an intended artifact, you'd have to equip it with this,
you know, with both a deep generative model, but also have this sort of, these parallel streams
to them, which brings us back to the right brain versus left brain. I still don't, I don't have a neat answer for you, I'm afraid. You're right. I mean, you know, language lateralization is a
The importance of "shared narratives"
classic, a classic and conserved aspect of our brains. But I can't think of a first principle
account as to why that might be the case. You mentioned the word narrative, that we have to have a shared narrative. Now, were you saying that we have to have a shared narrative
in order to have peace between us or in order to interact or in order to understand one another?
And then also, does that narrative have to be encapsulated in language or can it be embodied?
Because I assume that animals can get along and they don't have language, at least not the way
we do. And presumably, we didn't have language prior to a million years ago. Yet we got along.
Yeah, well, I meant it in exactly the same, the sense that you, that you intimated there. So,
yeah, it is just there. If we have a shared narrative, that I'm now using narrative to
describe a generative model that entails sequences of things that happen over time. So it's a model
of sequences that usually has a deep temporal structure to it. So if I want to understand you,
and I want to communicate with you in order to understand you and to ask you questions,
to understand more about your intentional stance, your knowledge, then I'm going to need to infer
what you're thinking. And I can do that if I know what I'm thinking, but only in the,
under the assumption that you're using the same kind of model as me. So we're both using the same
code or singing from the same hymn sheet. So, you know, when you start to model this, you don't,
you, well, we have models of linguistic exchange, which are cast in terms of simple games of 20
questions. So, you know, one agent has to ask another agent through linguistic exchange,
but it does depend upon them both committing to the same generative model of this linguistic
exchange in the meaning. A simpler set of simulations arises when you think about sort
of just birds singing to each other so they can recognize conspecifics. So, you know, what,
that's quite, that's much easier to simulate when you just have two dynamical systems talking to
each other and they both now become entrained and show synchronization of chaos that we were talking
about before in a different context, but here in the service of mutual predictability. So another
way of thinking about what's the best way to minimize surprise, surprise or self-information
when exchanged with another is to make sure that I only exchange with other people exactly like me,
because I can predict exactly what you're going to do next, because I know exactly what I'm going to do next and I'm doing it. So, you know, we could be singing or talking together. Clearly
we take turns, but there are situations where we could be actually singing in the choir together,
but I can only sing with people that have a sufficiently similar generative model to me
that makes it, that licenses the use of my model of how this kind of creature interacts with the
world, licenses its use as a model of how you are interacting with the world and interacting
interacting with me. So that's what I meant by shared narrative, just a shared or a conserved
generative model between creatures that typically act together in terms of things like joint
attention or familial bonds or sort of specifics in an evolutionary context, you know,
that generalizes in terms of, you know, cultural takes on niche construction, you know, the existence
of things like signs and traffic lights and elephant and desire paths. These are all manifestations of
living, sharing a world with other creatures like myself, that after a while they become very
efficient, very simple ways of communicating that possibly, as you say, don't involve spoken
language and non-verbal communication is clearly an incredibly important part of that. But even
beyond that, just the fact that we have a shared commitment to stopping when a traffic signal or
light goes red, you know, that's a shared narrative we have that enables us to drive around and occupy
Religion as aiding "shared narratives"
the same streets when some of us are driving and some of us are walking or both of us are driving.
So that's what I meant by shared narrative is sort of, you know, a common, a common
generative model of how to live in this world with things like me.
Interesting, interesting. Okay, now it can't simply be just shared, there has to be some other criteria only because me and you can still share the same model that says that you're an
enemy, and I'm supposed to kill you and I'm and you're supposed to kill me. So then it's not just shared that allows us to be peaceful cohabitants. And I was wondering, then do you think religion
is an attempt to make a hypothesis or, or to generate possibilities as to generative models
that a large class of people could share and minimize the suffering of both the society and
individuals at the same time? Yeah, I haven't thought deeply about this. But that's a very plausible, very plausible explanation for why religious narratives have emerged, and they're
so successful in maintaining themselves. So, you know, just in terms of a simple analysis
of the minimizing complexity arguments that we were rehearsing before, you know, if you want to
find a really simple explanation that accommodates a lot of difficult to explain stuff very accurately,
then a deity that can cause all this stuff is a really simple explanation. And, you know,
if it accurately explains your sensorium and your world, then it's a beautiful example of a very
parsimonious hypothesis. Now, it may not be sufficiently accurate for a scientist who does
not accept, you know, a religious explanation for this or that. But if you are not, if you are not
sampling that kind of sensory information or that kind of scientific data, then that doesn't matter.
Because you only need to explain what you need to explain. So, just as a broad
comment upon religious beliefs, and I think you can generalize that to societal norms, you know,
just ways of behaving, the right way to behave. You know, these are just simple hypotheses that
explain a lot of my behavior, a lot of your behavior in a really parsimonious way. And therefore, they have big evidence or low free energy because they provide simple explanations.
So, but you're bringing something else to the table, which is an interesting one, which I haven't thought about, which of course, these kinds of hypotheses are easy to share as well,
in virtue of their simplicity. And there's always going to be benefit in having a shared or a
conserved or a common generative model, provided, as you say, that we're all cooperating, we're all
acting as conspecifics. And it's interesting to, and you know, so in answer to your question,
I am sure that if you simulated multiple agents, all free energy minimizing, all trying to predict
each other in the most efficient way possible, and then one of them had the simple hypothesis
of a religious or a ideological or theological sort that made sense of lots of things,
to which everybody could subscribe, you'd suddenly see the consolidation and the emergence of that
aspect of the generative model, absolutely. And that would render everybody mutually predictable, so everybody would be reducing their surprise. And that would mathematically be expressed as
a collective decrease in free energy or an increase in the adaptive fitness, in the sense of,
you know, increasing the marginal likelihood of finding that phenotype around if you simulate in multiple generations. But the... Well, in that case, that would be trivially correct
in saying that there's a deity because you're the simulator. Yes. Well, that's an interesting hypothesis, which, interestingly, if you do philosophy,
Politics needs 50 / 50 splits on issues
of course, then you got the brain in the VAT thought experiment, which indeed actually has that exactly as an alternative hypothesis to confound the philosophy of realism versus skepticism.
But coming to your interesting point that, you know, what happens if my generative model is that, you know, you're my enemy, you're going to cause me surprises. I think that's an interesting one.
You know, the level at which we simulate these things really only addresses cooperation and systems that have different components and trying to find their place
with a shared narrative. So, what one would predict is that if there were
other kinds of agents that were not like you, then you would certainly have to represent them,
but in virtue of the fact that they're not like you, you wouldn't be able to communicate with them. So, you know, my prediction would be that, you know, whether it's a theological or political
or other kind of commitment, if there's an in-group and an out-group for any one given
individual, it is highly unlikely that there will be a shared language or indeed a big transaction
of communication between these two groups. So, there will be a Markov blanket, if you like, between the in-group and the out-group, the blues and the reds, you know, wherever you go.
And an interesting observation, which is not mine, but I've heard a number of people make, is that the only stable non-equilibrium for that in-group, out-group is a 50-50 split.
So, you know, in the language of theoretical biology, the evolutionally stable strategies for
opponents is a 50-50 split, which is borne out, you know, time and time again in terms of‚Ä¶
What do you mean a 50-50 split of what, population? Of the number of people that would identify with one group versus another group.
So, look at voting. That's interesting. Yeah. So, Brexit versus non-Brexit in the UK, or Trump versus Biden in the most recent
American elections, you know, wherever you get something where there is contention,
where you can commit to one side or the other side, the only, if you like, contentions or
dialectics which seem to survive is when there's a roughly 50-50 split between you.
Okay. So, in other words, the fact that we stably defer somewhat down the line on many
important issues is adaptive? Yep. For the collective as a whole, it's just maintaining a non-equilibrium steady state, yeah.
I mean, adaptive in a deflationary sense that, you know, that is one way to maintain, you know,
an extended non-equilibrium, you know, where now we're talking about Markov blankets and
Markov blankets and sort of applying blankets to multiple agents.
The existence of free will and definition of it
There's one quote that I love, that I try to live by, and it's only the shallowest of minds
would think that in great controversy, one side is mere folly. I'm sure you've heard that before.
I haven't heard that particular one, but I've heard something similar, which is...
Okay. So, do you believe in free will? And if so, how do you define it? So, free will, yep. I mean, you asked do I believe in it? There's certainly space for free will
in the realization of a free energy principle in sentient artifacts at many levels.
When you actually come to write down and simulate or build little toy agents,
you very quickly realize that the most interesting, in fact, the only interesting behaviors
that you can simulate arise when you write down the generative models as containing
autonomous dynamics, usually of a chaotic sort. So, the reason I use the word autonomous dynamics
is that mathematically speaking, there's a sort of free will in the autonomy.
There's even in a deterministic setting, there is an unpredictability given the initial conditions
that cannot be determined. So, in that sense, there has to be a mathematical kind of free will
at play. The other sort of take, I guess, on free will is it comes back to what we were talking
about before about making our own sensations, creating our own sensorium. So, if you remember
that from the point of view of minimizing prediction error as surprise, there are two
ways I can do that. I can change my mind so that my predictions are more like what I'm sensing,
and that would be a minimization of prediction error through perception. But there's another way of doing that, minimizing the prediction error. I actually just change what
I'm sampling to make the sensations more like the predictions. So, that's action in the
service of minimizing surprise or prediction error. But what that means is that my actions are basically
enslaved to where they can fulfill my predictions. So, they are in the service of
fulfilling prophecies. So, collectively, action perception is a self-fulfilling prophecy. And in that sense, I think you can find free will. If we are creating our own worlds and
Self fulfilling prophecies
our own sensory inputs, we're constructing our sensorium. Who else is doing it? So, in that very
simple, I won't say deflationary, but simple account of free will,
I can't see how it can be any other way, really. There's something that I've been wanting to study
for quite some time and I've been making extensive notes on, which is self-fulfilling prophecies. I find that to be an extremely interesting area of research. The fact that you can have them,
it's like you have a model of the world, and most of the time what you want to do is make sure that your model comports with reality. But then it's as if there are these blank spots in reality,
where whatever you think, if you think there's a chair there, then a chair becomes. I know that
that's an extreme example, but what I mean is that if you imagine that your wife loves you,
then you're going to act in a manner that makes her love you more. And if you mistrust and so on, so on, so they're self-fulfilling. So, it's as if there's these lacunas in the world, that whatever
you think is there becomes there. I wanted to know what your free energy principle had to say about
self-fulfilling prophecies. I imagine quite a lot, but I'm not sure if we have enough time.
Do you have any quick notes on? Well, I mean, the way that you just articulated that is spot on from
the point of view of the free energy principle. So, we often use the phrase, action is there to
realize and fulfill the prophecies supplied by the brain. It is literally a way of creating your own
sensorium in virtue of self-realizing and self-fulfilling prophecies. The question is,
can you keep on doing that in the face of a particular environment that may allow you to do
that or may not? And in particular, if you're dealing with lots of other people who are also
trying to pursue and self-fulfill their prophecies. What are the limitations of it?
Yeah. Yeah. So, I think that's absolutely right. And it also speaks to,
you know, seeing stuff which is not there, starts to talk, brings into the world
of false inference and delusions and hallucinations and the kinds of self-fulfilling prophecies of a
perceptual sort that people with things like autism or schizophrenia might be subject to. So,
you can go too far. But on the other hand, there are many people who now consider perception
basically as sort of hallucinations that are entrained by sensory input. What we actually see
is a sort of product of the hypotheses about what best explain what's going on. And there are
Schizophrenia, Curt, and Karl
occasions when we can get those hypotheses wrong and that we have, we're then subject to illusions,
for example, in psychophysics or hallucinations and indeed delusions. You know, if we've taken
some psychedelic drugs or that we have conditions such as say schizophrenia.
So then is schizophrenia a pathology of free will? I don't think so. No, no. I think it's a pathology of,
that can be understood as a false inference, but I don't think that there's any aspect of,
that will enable you to sort of isolate free will as the locus of that false inference.
There's certainly a lot of work suggesting that people with schizophrenia
when they are acutely psychotic may have difficulties inferring who did that. So,
assignment of agency. So in the sense that, you know, who will that? Was it you or me?
There may be a slight confusion. So if I say something to myself, I may infer, actually,
you said it, you put that thought into my head. So, you know, that's just a false attribution of
agency. So in that sense, perhaps you could say that that is a form of disorganized free will.
But certainly the people with schizophrenia that I have treated or worked with in the past,
I think they would have a sense of self and a sense of free will, which would be indistinguishable
from yours and mine. You know, I know that we have to wrap up at some point soon, and I wanted to
bring this up. I didn't know how, but I'll just tell you quickly. A few months ago, maybe I'll
even take this out of the actual clip, but a few months ago, January, February, I woke up in the
middle of the night, and then I had a conversation with my wife, it was minor, neutral, wasn't positive or negative. And then as I was going back to sleep, she either said yes or okay,
or she could have not said it. But I was in this hypnagogic, almost sleep-like state. And I've
never had a panic attack in my life. But for some reason, I wasn't sure if she said okay, or yes, or whatever it was, or if it was in my own head. And then I thought, am I psychotic? Am I getting
schizophrenia? I don't know why. It's not like that was a background anxiety of mine before. Maybe it was, maybe it's latent. But then I started to have a panic attack, because I didn't
want to hear anything. And I felt like I may be able to will myself to hear something by telling
myself, don't hear. Then I'm like, well, what would it sound like if I were to hear? Then it's no, no, don't go down there, because you may hear a voice. And I don't want to go. I don't want to
be crazy. I don't want to be psychotic. A couple days later, I had another panic attack, almost based on the worry that I'm going to be psychotic rather than I am at all. And, and I'm, I've been
afraid to search about schizophrenia. Because I don't want to read that I have the symptoms of it.
And there's nothing else other than that I may have heard my wife say okay, or yes, in a state
where I was about to sleep, and that she actually may have, in fact, said it, or not. I talked to
my doctor about this on the phone because COVID. And she said, Oh, Curt, well, you can hear many things. You can hear music when you're about to sleep, you can your foot can feel like you're
about to fall off and you shouldn't. So don't worry about that. And I found that when I talk about it, I feel much more at ease. But ever since then, for three months, Carl for three months,
at nighttime, I've had such a difficult time falling asleep. Because I'm afraid of my own
mind. I can't let myself be alone with my own thoughts, because I'm afraid of what I might find.
And it's created such anxiety in me that I, well, I can't rely on any benzodiazepines to sleep,
because that can just put you in a, that'll create way worse problems. So I have to find some way of
sleeping without any medication besides maybe melatonin. That's difficult. And I'm just not
sure what to do with that issue. I brought this up on one of my podcasts, because I feel like there are plenty of people who may be experiencing what I'm experiencing. But but people don't talk
about it. And turns out when I did talk about it, many people in the comment section said, I can't believe you've been going through this. That's, I've been going through something similar.
When I study about consciousness, and so on for this, for these types of interviews, I feel like I don't know what reality is anymore, because there's so many different theories. And so that
is destabilizing me on top of what I've already been feeling, and I'm unsure what to do about it.
And I just want to know what what advice do you have? I know that that's extremely personal question. But what, what do you recommend that I do or not do? Well, if ironically, you've just
done it. So now I'm responding as in my role as a psychiatrist, not as the author of the free
energy principle, although much of the free energy principle was actually inspired by exactly
the questions that you're contending with, you know, how do I maintain a sense of self,
which is the most important part of my narratives, explain, explain me and what can go wrong when you
have psychosis, I think the first thing to say is that there have been an enormous number of people
around the world during lockdown and during the Coronavirus crisis with reduced social contacts
and changing points of reference. So your old narratives, your old models are just not fit
for purpose. And in a sense, you've got to be able to grieve for the things that you're the way that
things were. And it's quite frightening to actually relearn how to live even for a few months. You're
in a new COVID world, certainly if there's been, you know, changes in social distancing or the way
that you interact with people. And I should say also, when and if you have to unlock that will
also be very, you know, anxiety provoking as well, because of the uncertainty, you've got to relearn how to do it. So lots of my colleagues have had psychotic breaks. And you know, talking to you,
I think it's highly unlikely that you have any form of psychosis, or indeed, an acute psychotic
episode, just by your composure, your theory of mind, a lot of nonverbal cues. However, I do have
many colleagues who've actually had an acute psychotic episode. In response to this, I haven't,
but a lot of my close colleagues have. And it's perfectly natural. They usually last about sort of,
you know, sort of a few weeks to a month or two, may respond to medication if the person is becoming
sufficiently agitated, or they're worrying their close family. It needs containment
pharmacologically, that's certainly viable, if it gets that far. Usually it doesn't. But the
important thing to know is this is perfectly normal. Even if you haven't had a psychotic
episode, if you had had, lots of people are going through this. Which brings me to the answer to
your question. You can certainly talk to your GP, and talk to healthcare professionals and mental
healthcare professionals. And there will be the option of medication, either to help with sleep,
or to if you actually did have a psychotic break to take the edge off that and enable everybody to
cope with, you know, with the consequences. That's always an option, should you want to go for it, and you shouldn't feel ashamed of doing that or in any way hesitant. I have to say that the nature
of these episodes is such that it won't be the person who has the psychotic episode, who knows
that they need containment and looking after of a particular kind. It's usually the next of kin,
their children, their parents, or their wife or their husband, who has to take the initiative to
bring in support and help to get that done. And that help is there. The very fact you're worried about it means that you're almost by definition, can't be psychotic, because you've got insight.
So just by worrying about it, I'm afraid, takes you off that list. But it doesn't mean to say
the anxiety doesn't go away, right? It doesn't mean you're not actually psychotic. And the other
thing which really helps is just, which you've already said, it's basically sharing in the groups,
the angst that these things generate, whether it's a psychotic break or not, or worrying about it or
not, everybody's going through this. And being able to share that in a group can be enormously
therapeutic for everybody in the group. So if you can set up by sharing a safe environment within
to share these experiences and anxieties, and by safe, I mean, very clearly bounded. So it starts
at a particular time, and it finishes exactly one hour later. So you've got this boundary so that
anything that comes out in that context, can't spill over and affect and can be put back in the
box. But you know, there's going to be a box next week, or tomorrow, very, very carefully time,
you know, who's going to be there, or you know, what kind of people are going to be there. Boundaries are very, very important when it comes to group therapy. That, in my experience,
that's the most effective kind of talking therapy in this situation. How do you get a group together,
you have to say, well, this is a thing. How do you do that? You just have to declare,
you have to come out and say, I'm upset by this, I can't get to sleep because of this.
If I told myself these worries a year ago, I thought I was stupid, but these are real worries, they're stopping me thinking. I can't, you know, just saying that out loud means that other people
now are aware that this is a thing. And it's something that can be talked about. So when I said you've just done it by just going public in this kind of interview, is the first move.
The next move is then to find, you know, a network, or a structure that will support
either therapist-led or self-help groups, usually small enough that you actually have
the intimacy of a small group dynamic. So not more than 12 people, usually about eight people,
with or without a therapist. You don't need the therapist, but it's useful, you know, if somebody
just to get used to the importance of boundaries and group dynamics, but it's not necessary.
The important thing is you're getting together in a bounded way to share and
in a completely open and non-judgmental way, tell other people how what they are saying
makes you feel, and just use them to reflect literally like a mirror. So you come back to
the shared narrative again. You can get a long way with that. So that's what I would recommend.
Somebody in your position may well feel that perhaps you should start an initiative along
these lines, or actually start, you should take the initiative and actually set up a discussion
group or a self-help group. But if not, then certainly look around on the web, and I'm sure you'll find that somebody over the past few months will have started this. And be mindful
that you should tell your wife, if you do get a psychotic, she's got to get the doctors in to
get you medicated, because that'll go away in about three weeks once you, you know, if you just take the right kind of medication. It's not a big thing. I repeat, it's happened to several
colleagues and friends. And you're back in the saddle now. And it's been a useful experience.
Sometimes people get, they get more creative, they go slightly manic. I don't sense that in you.
But I do notice that when I was having my high anxiety periods right after the initial episode,
that I saw many more connections, almost like I imagine, when you're on LSD, or psychedelic,
that everything is imbued with meaning that every other sentence someone would say in a movie, I'm like, Oh, that's so deep, that it makes me want to cry almost. Now that's not there. I still
do see connections, but I tend to have always seen connections to some degree anyway.
Yeah, so I mean, the these episodes will either just reveal innate sort of, you know,
ways of thinking and seeing and making sense of the world, particularly pro social context.
But certainly, you know, what I was going to say is that there can be some, if you keep a record
of these, if you can, if you just see associations and links, and just keep a documentary record of
it, it may actually be something quite useful, either to go back to as a, you know, an essay in
the way that you saw the world in that particular state of that particular time. But sometimes you actually get some quite profound insights. Again, a number of my colleagues actually do suffer from
manic depressive psychosis. And of course, if you look at the history of your creative people,
in both the arts and the sciences, you're on this edge of chaos, this instability that is
associated with psychosis. So it's not an unproductive time. You know, if you are,
if you did get close to the edge, then make sure you keep a very, if you can keep a very clear
document, what happened to everything you can, this would be nice for you to go back to next year. Yeah, I definitely take notes on all my thoughts. I've done so for years. Anyway,
You are your own existence proof.
I'm always constantly saying, I can't say now because it'll turn on, but okay, and then the name of my device. And then I say make notes and so on. So yeah, okay. Well, thank you so much,
Doc. I want to say doctor. Thank you so much, Professor, you are a doctor, obviously, Professor. Thank you so much, Carl. There was a statement that you said before many times,
it's that you are your own existence proof. Can you explain what that is? What that means?
It is one of those deflationary summaries of the free energy principle that says,
the very fact you exist tells you a lot about the mechanics and the things that you must do,
or the properties that you must possess in order to exist. So you turn that on its head,
and the fact that you exist is proof of your own existence, again, in this tautological sense.
You can also read it as one way of encapsulating the notion of self-evidencing. So if you read
self-organization as a system trying to minimize its free energy or maximize
the evidence for its models of the world, then what you can say is that these kinds of systems
change in such a way to increase the evidence for their own existence. So it comes to very
close to the notion of this self-fulfilling prophecy that I expect to exist, and I'm going
to act on the world in a way that solicits or secures evidence for that existence. And if I
have a good model of that world, then I will be successful in soliciting that evidence. And in so
doing, I will persevere, and I will simply exist. And I look as if I'm self-evidencing. And of course,
evidence for what? Well, evidence to prove that I exist. So it's a rather sort of cheeky
way of celebrating the tautology of existence in the sense that just existing is really all you
Can you think yourself into non-existence?
need to know, and you can spin off everything else, all the attributes of artifacts, particles,
people, plants that exist just from their very existence. Curt Jaimungal
What happens if you start looking for evidence that you don't exist? Like, let's say you're on the eastern end of the philosophical spectrum, and you say that the eye is illusory, that maybe
this is all a dream, whatever that may be. What happens? Is there a system that can do that? Where
you look for evidence of your non-existence? Can you think yourself into non-existence? I know that likely not, but please run with that idea.
Dr. Richard Dawkins Well, it's a wonderful question. I mean, yes, I think you could certainly think yourself into
non-existence. I mean, just a trivial thought experiment would be somebody who's a very
committed meditator who forgets to drink or eat and dies through dehydration. So no,
it is certainly possible. It's a wonderful question because it speaks to something in
philosophy called the dark room problem. So it is certainly possible to simulate in silico,
in computers, agents that deliberately do not believe that they exist and will avoid
sampling data that would otherwise provide evidence for their existence. And what that
translates into is essentially an artifact or a creature that turns off the lights,
you know, deliberately avoids any information from the world and sequesters itself from the world.
But in so doing, of course, there are profound implications for its homeostasis. And, you know,
from a sensory point of view, it hides away in dark corners and is now subject to the dark room
problem. But at the same time, it will not be able to maintain its Markov blanket. And ultimately,
it will dissipate. So if it doesn't comply with the existential principles that maintain
its structure and form and its organization, technically, if it doesn't comply with the
principles that underwrite the maintenance of Markov blanket, then that Markov blanket will cease to exist. And so will you if you are that Markov blanket. So, you know, it's practically a
very interesting question, because it all rests upon having a good generative model of the world.
So, you know, there's a sort of dual dependency here that, you know, it looks as if creatures
that are systems more generally that exist, are seeking out evidence for their internal model
of how the world works and how the world generates its sensory samples. And that's only an apt
explanation for self-organization, if the generative model is a fair or a good enough
explanation for the way that those sensory samples are generated.
Technically, that's an idea which dates back to the inception of cybernetics in the early half of the 20th century, known as a good regulator theorem that in order to regulate,
to control, to survive in your environment, you have to be effectively a model of that environment.
Definition of generative model
So, you know, whether you're a thermostat, or, or a person, you know, your structure,
and the way that you exchange with the environment, under a model of that environment,
only works when you are a good model of that environment. When you say generative model, what's the difference between a generative model and just a
model? Well, generative model is just a technical term, you know, strictly speaking, it's just a
specification of the probabilistic relationship between causes and consequences. So you literally,
you write down a probability density or a probability distribution of the causes and
consequences. And that allows you then to evaluate the evidence in some data for that model.
So in this instance, the causes are unobservable, sometimes referred to as latent or hidden states,
say of a world, and the consequences are observable consequences, say, sensory samples
that we solicit with our sensory epithelia, our eyes, our ears, or indeed, our interception.
So the generative model, read like that is just a probabilistic specification of how hidden or
latent states hidden behind, say, a Markov blanket, generate observable consequences.
And if you've got that model, then you can assess how likely those sensory samples,
those sensations, those sensory impressions were under your model. And if they were very likely,
you're not going to be surprised, you have a low free energy, and you know that you've got a good model of the world. If you're constantly surprised, unable to predict, then you've got a bad model of
the world. And remember that surprise can also be read as prediction error. So if you constantly
subject yourself actively to lots of prediction errors, you're going to be constantly surprised
in a state of high free energy. But think about what that means. These are not just prediction errors, in fact, they are not prediction errors of a sort of personal sort, you know, a propositional
thing I could say, well, I didn't expect that. These are sort of fundamental deviations from
your expectations, like your bodily temperature, the amount of blood sugar that your circulation
is currently supplying. So when these get out of physiological bounds, you start to literally
disintegrate and die, and your Markov blanket dissolves. So it's important to keep these
Donald Hoffman's consciousness model
prediction errors within bounds, or in the language of the free energy principle,
do you to keep on top of your surprise, self information, or free energy, all words for
essentially the same thing. Okay, what do you make of Donald Hoffman's ideas on consciousness?
I know that's broad. Yeah, I had a mentor once called Jerry Edelman, there's a Nobel Laureate,
Quantum consciousness and Penrose's Orchestrated OR
famed for understanding the evolutionary basis of our immune systems. He used to call me an
intellectual thug, because I didn't know anything outside my own sphere. So if you tell me what
Donald Hoffman, yeah, so forget about that. Forget about that. Because in order for me to say that it would take too much time, and I'm, and I probably wouldn't do its service. Okay, how about orchestrated
objective reduction from Penrose, Roger Penrose, Stuart Hammeroff, if you've heard of them?
Yes, yes, yes, certainly. So, yeah, I certainly read Roger Penrose's Emperor's New Mind.
Yes, the Emperor's New Mind. So, so what, what, what, sorry, can you repeat? Well,
yeah, what do you think? What do you think about it? Does it comport with your theory? Does it contradict it? Do you think it's too unfalsifiable? Do you like it? Do you think it's
creative? Like, what are your broad thoughts about it? I think it's entertaining. So I'm
going to lump that in with quantum theories of consciousness, or, you know, which is entertaining.
I don't see it as a serious contender that offers any explanatory power in terms of sentient
behavior. I should say, of course, that the, you know, my work with the free energy principle and
things like active inference, these are not theories of consciousness. They can certainly
be deployed to set some parameters on questions that arise in consciousness research, but in and
of themselves, they're not theories or principles that would underwrite consciousness. Having said
that, you know, they do tell you where the mechanics of the Bayesian mechanics, the physics
of sentience lie in the physical world, and it is not at the quantum level. So, you know, from the
perspective of a theory of every space thing, there is a range that you can formalize
mathematically under things like the renormalization group of things. You can have very, very small
things that have very large amplitude random fluctuations, very, very fast things. You can
have very, very big things, very slow things, very cool things, where the randomness averages away.
So, you know, one can envisage this as a spectrum between quantum mechanics at the very fast,
small end, and classical mechanics at the very, very slow, large end of the sort that would
describe the orbits of heavenly bodies, which means that you ask, well, where do we fit? And
we being biotic systems that show a particular kind of self-organization that we would associate
with life. And it's in that intermediate zone where both the random fluctuations and
what underwrites classical mechanics, which is this solenoidal circular motion that doesn't
change at the surprise or the marginal likelihood, that's where we live. So, we know it's not at the
quantum level. So, we know that sentient behavior and by implication, sentience cannot be found at
the quantum level in the same sense that cannot be found in the motion of the heavenly bodies,
simply because they're too cool. They don't have the right kind of itinerancy, the right, if you like, adaptation, the challenges, the existential challenges that might
destroy their Markov blankets are simply not in play. And at the quantum level,
there's effectively no interesting itinerancy that defines non-equilibrium steady state.
So, if I was responding, I know I'm not, but if I was responding to a physicist asking that question,
what I would be saying would be that if we consider life to be self-organization to some
form of non-equilibrium, far from equilibrium, non-organization, then stipulatedly, I am saying
that we have to account for this non-dissipative, these non-dissipative dynamics that are
mathematically the solenoidal part. If they are dwarfed by random fluctuations that you find in
quantum physics, then we're not talking about any more non-equilibrium. We're talking about
equilibria. We're talking about solutions to the Schr√∂dinger wave equation. So, in conclusion,
quantum neurobiology is entertaining, it's interesting, but it's just not the right place to
What does FEP say about consciousness?
to create a mechanics of sentient behavior. And by that, I would guess that that precludes it from
being an apt description of conscious artifacts. Is one to understand the free energy principle
as giving any indication as to what consciousness is. So, for example, the self-evidencing,
is that consciousness or is it when it's minimizing the free energy? Or is it the fact that it has a Markov blanket? Because when I was looking at the nodes, any point you can define a Markov
blanket to so it doesn't seem like the fact that there exists a Markov blanket means it's conscious. So what are the conclusions one is to take from reading your free energy principle
that someone can draw for consciousness? Yeah. Right. Yeah. I mean, this is, again,
an excellent question, because it's one being posed around the world as we speak. Yeah. So
people like the John Templeton Foundation are sort of earnestly looking at ways to sort of
put up, for example, the free energy principle against integrated information theory as formalism that might speak to speak to consciousness research. So it's a great question.
The normal answer from people in my world would start off by saying that consciousness is probably
a vague notion. And I mean, vague in a philosophical sense that, you know, at what point does a collection of sand grains become a pile of sand? So it admits the possibility
that a thing may not be conscious. Yes, it certainly would, by definition, have to have
a Markov blanket in our formalism. But that does not mean it is conscious. It will be self-evidencing
in the sense of having gradient flows that try to minimize self-information. But that's as far
as it goes. So then you ask yourself, well, what kind of systems, first of all, look as if they
are living? And then as we move through this vague landscape or vague dimension towards very
sophisticated particles like yourself and myself, what would take us from living to
systems that had a minimal selfhood? And then even further, what would take us to systems
like philosophers that sort of puzzle over the fact that they have minimal selfhood? And I think
the answer lies really in the generative model. So if you remember, we were talking about a
generative model as being a probabilistic specification of causes and consequences that underwrites the free energy or specifically the free energy gradients that provide an
explanation for our dynamics. So it all boils down to the generative model. So first of all, what would it mean to be alive? And we have discussed this in terms of just moving to have
an itinerancy to actually act upon the world. So you need to see a particle moving around.
And it would look as if it was moving around in the service of sampling evidence for its own
existence and maintaining itself in these characteristic ranges. It's showing us a
generalized homeostasis of the sort you might expect a worm or a single-celled system,
kinds of behavior a single-cell system might show. Does that have any sense of self or any sense of
consciousness? Probably not. So you then take it up to say insects and small mammals. And at some
point in this vague continuum, you come across the next milestone or marker on the way, which is
the kind of generative model that would explain the consequences of action. So put it very,
very simply, though there are some creatures that, or systems at least, that will respond
reflexively, like say microbes and thermostats, that will respond in a way that seems to keep
themselves within a particular range. But crucially, they don't plan. So what would it mean
in terms of planning in a deliberate way, a deliberative way, basically selecting among a
number of ways forward, a number of causes of action that will lead you to reduce uncertainty,
minimize your free energy, or minimize your expected surprise as a consequence of that action?
Well, you would require a generative model of what would happen if I did that. Now, because
what would happen is in the future, that's a very sophisticated generative model. So now you're actually equipping this generative model with a temporal depth, it can reach into the future.
And if a creature or a system is endowed with a deep generative model that encompasses the
consequences of action, it's now in a position to choose those actions that it thinks will either
resolve uncertainty or supply the most evidence for its own existence, or put more simply,
evince the characteristic sensory states that define it and define what it is.
So then we're moving on now to creatures that plan. And if creatures that plan now have an
extra bit to their generative models, which recognize that they are planning, that have this
hypothesis that, hang on, it may be the simplest explanation for all these multimodal
sensations is that I am a thing. And that I, it is me that is prosecuting these reflexes or moving,
or it is me that is looking over there. And now you've got a very sophisticated generative model where you can certainly imagine that there is a minimal representation of self, like self-modeling.
So now we're moving closer to the notion of conscious artifacts. Would they be fully conscious?
Would they have qualitative experiences? Would they have qualia? And then the next argument is,
what would license a qualitative experience? What it would be like to see
red or any other attribute of the sensorium? That usually, the argument then is, well, that would
require the kind of generative model that was able to essentially infer on its own inference,
that would be able to enact a kind of mental or covert action in order to select in the model
itself, in the message passing in the brain, for example, be able to select certain sources of
information in the service of this hierarchical self-evidence. From the hierarchy, like layers
of an onion, and the deeper you get into the onion, the higher you are in this hierarchy.
You know, recurrent message passing between each of the layers. But if the deeper, the core of the
onion was now able to act upon the intermediate layers or levels of this hierarchical construct,
then you might now suppose that this is a kind of mental action that licenses you to say,
now this is an agent. It's an agent that plans because it's acting. Psychologically, this would
be effectively attention. So if you can plan what to attend to or generate attentional selection
of the way that you go and secure evidence from your world, then you might now start to develop
a theory of what it is like to actively perceive something. I could go on at length,
probably not very usefully, in terms of how you might cast that in terms of phenomenal transparency
and opacity. In brief, what we're saying is that there are certain generative models, there are certain creatures that can render their percepts experienced by rendering them opaque,
by acting upon them, by having this capacity of attentional selection. So now you've got to some
a very sophisticated generative model that not only has temporal depth that enables the
agent to plan, it's also truly an agent that may be self-aware, or at least aware of what it is
perceiving, because it can now act upon the perceptual inference that's implicit in this
self-evidencing. But we still haven't got to self-awareness yet. So these things might be
apt to describe, say, mice, but we don't know whether mice are self-aware.
Probably they can attend to this or that, and under this, if you like, spectrum of
vague levels of different kinds of consciousness, they could be said to be conscious in the
sense that they are sentient and have qualitative experiences, but are they self-aware? And if you
want to be self-aware, you've now got to, by definition, have part of your generative model,
literally part of your brain, that stands in and represents selfhood. So just, and then we come
back to this notion that your highest forms of life on earth would probably have realized and
The meta-Hard Problem of Consciousness
learned and infer that they are entities, they are agents, and that becomes me, and it's me that's
doing this overt action and this covert action, this attentional selection. And then the final
step would be to go from this highest form of life to become a philosopher, when you start to have
mental models of how it is that some people are self-aware, and so on, ad infinitum, in terms of
the number of... Is there an ad infinitum? What's the next step after philosophers? No, it's not. As soon as I said that, I realized that was stupid and you'd stop me. No, it's not.
Okay. I think we've probably got as far as we can in terms of levels of recursion. And I say that
because there's a lovely notion, which I'm sure you're aware of, this is a notion of the meta
hard problem. No, I never heard of that. I should. No, you'll love this. I think it's something that
was introduced just in a presentation or taught by Andy Clark in about 2001, and then seriously
taken up by David Chalmers about two to three years ago in 2018. So this is not the hard problem
of finding an explanation for sentience. What is it like to perceive red?
It's more, why do we find ourselves puzzling over it? Why do we think it's such a mystery?
Yeah. So this is not the hard problem, but what sits next to the hard problem, which is why is it that we find it so perplexing and difficult to explain? Why is the hard problem
a problem for us? And that's, to my mind, it's an extra level that you were talking about.
Now we're asking, we're trying to explain the emergence of philosophers. So we're now moved up to the next level. And it's a very interesting problem. And it tells you immediately a number
of very interesting things that, you know, if I am puzzled about the fact that I am seeing red,
or that I can see red, that tells you immediately that your generative model has to have a model of
a counterfactual where I can see red, but not experience it. Now that's quite remarkable,
you know, to actually have that kind of generative model where you can imagine yourself,
you know, structured in a very, very different way. So I use the word counterfactual there,
you know, deliberately, because, you know, it may be just because we are systems, artifacts,
sentient artifacts, that have these very, very deep generative models that entertain counterfactuals.
And Neil Seth calls this counterfactual depth. Now, allows it.
Well, I spoke to Neil Seth for this program. He's a great guy. Well, I hope he mentioned counterfactual depth. If he doesn't, you'll have to get him back.
Yeah, yeah, no, I don't think he did. Or maybe I slipped up and don't remember. Okay, so continue. Sorry.
Yeah. So the notion of counterfactual depth, I think is very important. I mean, it's absolutely
requisite for planning, in the sense that, you know, planning is choosing the right course of
action, which means you've got a series of options, all of which have these counterfactual outcomes. But of course, if you're given that model, you're given that kind of model,
you're now in a position to hypothesize counterfactuals that could never occur,
such as seeing red without seeing red, such as, you know, seeing but looking but not seeing,
for example, such as the other thought experiments that philosophers like, like, you know, philosophical zombies. The very fact that there is this meme of a philosophical zombie
tells you immediately that we are in discourse with creatures, namely philosophers,
that have the capacity to represent in their generative models, impossible scenarios and
counterfactuals of the kind that you would have to bring to the table to, you know, to conceive of a
philosophical zombie. So just perhaps even more simply, the fact that people can do these kinds
of thought experiments tells you a lot about the kinds of generative models they use to explain their world. And that is possibly a sufficient explanation for the meta hard problem,
just because we can. Uh huh. Okay, I'm gonna need to think about that. There's this lady named Anika Harris,
who's Sam Harris's wife, and she has a book on consciousness, I believe it's just called consciousness. And no offense to Anika Harris. But the book was the books, the best part of the book
to me was when she was talking about philosophical zombies. That is for the people who aren't
listening, how can there be robots that look like us that aren't conscious, and it produces an
produces an equivalent world. And she said, she said something so interesting, which is that
the fact that we're talking about consciousness implies that we're conscious is because in equivalent zombie like world. It's hard to imagine why they would come up with that question. So
Anna Lukomsky: Idealism vs Physicalism
that's what separates us from them. Yeah. That sounds exactly that that sounds exactly like how Andy Clark would phrase it, you know,
the big thing is why we so puzzled about consciousness and sentience. So that sounds
very, very close to the core question that underwrites the meta hard problem or the meta
problem. Yeah. Anna Lukomsky asks, she says, That's lovely to hear. When I told her that I was
speaking to she's fantastic news about Carl Friston. I'm curious to know if he's an idealist
or physicalist. Now I'm biased towards idealism. I'm speaking in terms of her. She's a psychiatrist,
by the way, or a psychologist. And she says, Well, first of all, are you an idealist or physicalist? I'm very happy to put for both sides, depending on who I'm talking to.
Okay, so you're uncommitted right now. And no, I mean, I'd be happy to commit to either. So
your I see this through the lens of the people I know in philosophy. So on the one hand, my friend
Andy Clark would be somebody who believes you certainly would not adopt a radical idealist,
whereas Jacob Hoey would celebrate the Markov blanket that separates you from the external
world. And therefore the external world can never be known. It's only ever accessed
vicariously via the Markov blanket and he might he might then take a more skeptical position.
I think the maths of the free energy principle really forces you to
to back for both sides. On the one hand, it is absolutely true that are making sense of the world
through the sensory veil supplied by the Markov blanket precludes any anything out there that will
be ever known. That is certainly true. So it's certainly consistent with brain and that like
thought experiments. There will be no way that you could verify or not what's actually going on
out there. Everything is this sort of delusion or hallucination that is entrained and grounded
by sensory evidence. But you never know the causes of that sensory evidence. That's
the whole premise of inference, active inference, encapsulating or the
encapsulating the take on self-organization as a process of inference. So that's that that would be
sort of the one side of the fence. The problem is that when you if you commit to that, it's very
difficult to actually simulate or engineer sentience, because in order to do that, you've
actually got to generate the sensations, the sensory states of the Markov blanket on that the
the agent can infer. And of course, when I talk about or refer to the good regulator theorem,
I'm implicitly assuming that there is a world out there to be regulated. I'm assuming that the quality of a generative model as measured by its free energy
is in relation to what is being modeled. So I have to commit to some realism in the sense that
I'm saying there is a model. So it's very difficult for me to answer that, because on the one hand,
if it's a model of something, then the something must be real. On the other hand, it's always the
process of inference under a particular model means I'll never know whether there's anything real or not. So you know, it sort of accommodates both points of view and resolves neither, I guess.
The psychological reason you're saying sorry, there's not a psychological reason that you're saying you're both a physicalist and a realist or neither. It's, it's not because you don't want to
offend anyone. It's actually because your, your model accounts for both. Well, one is like
ontological, the other is epistemic. So one is like, we can't have knowledge of it, but the other one, but at the same time, you're assuming that there exists a world that's independent.
Yes, that's a beautiful way of putting it. But but also, I also don't want to offend anybody as well. But yes, lovely chap, you want to keep your charming nature. Okay, so this person named
Matthew Nehemi says, does referring to you does Carl Friston know Alfred Korszybski? And what
does he think about his theories? That doesn't get vague about but you're going to have to
forget it because I actually don't know this person. And I have been told that I need to learn more about this person. Dr. JT Velikovsky of the University of Newcastle from Auster Australia,
who has published some work on holon parton theory structure of the meme, some memes like Richard Dawkins memes, he asks, do you expect, like David Bohm suggested,
that the scale, size of entities in the universe, e.g. matter energy, go infinitely smaller,
e.g. smaller beyond quarks, and also infinitely larger e.g. to multiple universes?
And yes, I mean, I think that would be that would be sort of mathematical take on the application,
if we wanted to do that of the apparatus of renormalization group when trying to understand
the separation of temporal scales between different levels of organization, which is an
important part of the free energy formalism when it comes to thinking about Markov blankets and
Markov blankets, say, your organs that comprise cells, where each cell comprises organelles,
that themselves comprise molecules that themselves comprise that, and so on and so forth. And then the other way, organs constituting phenotypes, phenotypes constituting populations, constipation,
constituting in groups and out groups, constituting species, and so on, right up to
sort of a cosmological scale. So, you know, I think, mathematically, that that's a very
comfortable position to adopt. So that the other, there is no lower or upper bound on the application
of the renormalization or the apparatus of the renormalization group when you move from one scale
to the next, which you can do very gracefully when it comes to certainly modeling, for example,
applying the free energy principle to single cells in a network of neurons, and then
coarse graining that to try to model, you know, parts of the brain as self-evidencing through
your physical motion, through to coarse graining that and then trying to model
populations talking to each other or interacting through the Markov blankets that defines
an organization or a family or a set of conspecifics, defines it in relation to, say,
the environment or the econish. So, these are just examples of lifting exactly the same dynamics,
the gradient flows that underwrite the free energy principle from one scale to the next, and in so
doing, working out what the states are, what the, you know, when you say the states of affairs or
the sensory states or the internal states, yeah, what are they? And when you sort of drill down on
that, what you can do is use the renormalization group formalism to, in moving from one scale to
the next, you basically take mixtures of blanket states, and then those mixtures of blanket states,
technically the eigenfunctions of the blanket states, now become the states of the next level. And then you look at the conditional dependencies of the states of the next level, then you find
the Markov blanket, then you take the eigenfunctions of those states, and then they become states in
the next level. At each level of coarse graining, you get bigger and slower. So, before we were
talking about sort of this, from quantum to classical, that inherits simply from this
successive coarse graining, but at each point, exactly the same free energy,
for like Lagrangian, you know, the way that you would write down the dynamics and, you know,
on one reading the energetics, the functional forms are exactly preserved. You're just
swapping out sort of, you know, microscopic states for mixtures of microscopic states,
in particular, repeat the eigenfunctions or mixtures of blanket states to get to the next level, noting that the blank, you're throwing away the internal states. Remember, the internal states
are independent of the external states, given the Markov blanket, and vice versa,
which means there's nothing in the internal states of any particular particle that is not,
if you like, encoded in the blanket states, if you wanted to move to the next level. So,
each level, you're throwing away the internal states that can have very fast dynamics,
and you're picking out the slower fluctuations on the Markov blanket, on the blanket states
themselves. So, the states at the next level up now fluctuate much, much more slowly, and they encompass,
they have a larger spatial scale as well. So, you know, once one has that sort of
recursive, you know, not proof by induction, but the same spirit as a proof by induction,
where you move from one level to the next level, once one has that apparatus in play,
there is no need to ask when does the process stop or where did it begin?
And in a sense, you dissolve those questions, because you're only interested in one particular scale and how it relates to the scale above and the scale below. I mean, you can go, if you're,
like, astronomy, or you're interested in the physics of the cosmos, then you'll be going,
let's say, six scales towards classical mechanics. If you're interested in string theory
and small particle accelerators, then you'd be going, say, six scales down to very, very small
things, you know, towards the quantum level. But we... Is six just a number for an example, or are you specifying something in particular?
Well, yeah, it is a number I pulled out of the hat, but it's probably about that when one looks at,
when one looks at the time constants empirically associated with any particular scale or any set
of Markov planks at different scales, and then one goes to the next scale using, you know, this
is not, this is not magic. It has been applied, for example, to brain imaging time series, where you
you look at every little cubic patch of the brain, a few millimeters in size, and then you say,
well, that's the scale I'm going to start with. And I'll take the eigenmodes or the eigenfunctions
literally as the activity of each of this little chunk of brain. And then I've got, say, thousands
of states. And then I look at the dependencies and I work out a Markov blanket, and it could be a Markov blanket around the little chunk of brain the size of your thumbnail. And then you can take
the eigenfunctions of the Markov blanket of that little chunk of brain. And then you put the chunks
together, you find the Markov blanket at that level, and then you talk about the eigenfunctions of the Markov blanket, and then you talk about lobes of the brain. And then you talk about the
entire brain. And then you think about well, lots of brains together at a scientific conference. There's so many, whatever, almost every four sentences that you speak, three ideas occurred to
me, and I just want to explore them all. So here's an example. We're not going to explore them. I'll just say them. When you mentioned that the internal states are independent of the external,
it's almost an arbitrariness as to which one you call internal, and which means that you can, at least I'm surmising, I'm going to, I'm pretty much asking, but either way, then that means that
Joanne Dong: Explain the meaning of life via the FEP
you can imagine the environment models you in a sense. And then I wondered, well, what's the
connection between that and the holographic principle in string theory, which says that as the boundary, it encodes the information. Anyway, okay, that's just what occurs to me.
And also multiple split dissociative personality disorder. Also want to know about that. But Joanna Dong has a question. She says, my question to Carl Fristin, how do you explain the meaning
of life using the free energy principle? That's an easy question. You can answer that in like 10 seconds. I've never been asked that before, the meaning of life. So I'm just going to use my
favorite words, tautology and deflation. The meaning is in the existence. The shape of that
existence defines the goals for the existential imperatives to keep yourself in those existential
domains. So it's just in the existence. It's just the shape of things that exist that define their
own meaning. And, you know, in a sense, you could look at self-evidencing as finding meaning for
your life or your finding or understanding the model for which you're trying to accrue evidence.
And what that basically means is if you're reading that as a psychiatrist or a philosopher,
you're basically trying to understand yourself and your own generative models. So if you understand
your own purpose, your purpose is just to aspire to this, these attracting sets that define you as
the kind of thing you are. And then the meaning would, I think, rest upon this, some kind of self
model where now you recognize you're this kind of person. So you can spin it off at a number of
different levels. So it wasn't a very, I'll think of a more succinct answer to that question. Sure. Psychologically, an attracting set would be what? Mathematically, that's fine. But for
someone who is just interested in how one lives their life, is this just a recapitulation of know
thyself? Yes. So the thing, the things that the things that you are attracted to literally,
the things that you see yourself being attracted to the things that you see yourself aspiring and working towards. And what you find interesting and admirable. Is that what you mean? Yeah,
that was a very high level. But remember, you know, this operates at all scales of a deep
generative model where remember, the core is dealing with sort of more abstract things,
such as, you know, being likable, being loved, being rich. But at the periphery,
there are still there's a model of basically body temperature, body pose,
and not being in pain. So these are also things that make me happy, in a sense, you know,
these are, these are attracting states, it's attractive to be at a particular temperature, attractive not to sense pain, it's attractive, you know, to be hydrated to a particular extent.
At some level, it is also attractive, you know, if you have very deep generative models,
that have this counterfactual depth, then there are certain counterfactual outcomes
that you would find very surprising would be unattractive. And there'll be other outcomes,
which you would have learned, this is the kind of outcome that I aspire to, this is the kind
of generative model I am, you know, at that point, that I think it would be quite fair
to start thinking about this in terms of, you know, I'm going to develop this reputation, you know, if I if I say this, or if I donate this, or I'm going to, I'm going to be this kind of
person, if I take these actions. So there are certainly entailed in the prior beliefs that
constitute the generative model, ways of behaving, ways of being outcomes that you a priori expect
to happen. And generally, these are going to be things that are consistent with your self image
with your self model, and interestingly, also require an optimism bias, a sort of, you know,
because of this self fulfilling prophecy of all our actions and decisions and choices and behavior,
if they're all in the service of realizing our fantasy about the kind of thing that we are,
then we're always behaving and selecting those information and ignoring other kinds of
information. In order to find evidence, and indeed, this is the kind of thing I am,
so I'm going to ignore any evidence that run runs counter to my self image, you know, that I'm not
liked or not believed, or that I'm very poor or very hungry, unless I can do something about it.
So, so, you know, that's a really, I think it's a really interesting question, because
it, it speaks to the, both the self fulfilling prophecy, but, and this sort of optimistic,
optimistic aspect of active inference, which is not a fallacy, it is, it is absolutely essential
in keeping us on track and keeping us within these attractive, attracting or attractive states.
So if you were doing, if you're a behavioral psychologist, this would just be some kind of
reward. If you're a control engineer, it would be some kind of negative loss function. So you just
score being in a given state, in terms of the probability that you would find me in that state.
And if it is unattractive, and the kind of thing I would avoid, that simply is a statement that has
a very low probability. That means that the negative logarithm is very, very high, it just means it's surprising. So it's just another way of saying that the attracting set of states or the
Monotheism vs Polytheism in terms of FEP and psychology
attractive states are those that I am not surprised to be in, that they are comfortable, they're
familiar, given I am who I am, this is exactly the kind of statement I think I should, I should
close and be occupied. Again, almost all that you say, there's so many thoughts that occur,
I'll say some of them now, not for you to explore, but maybe for people in the comment section to explore. I was thinking when you were talking about different goals that one has, and there's
different levels of abstraction. So one is to regulate your body temperature at an extremely low level than at a high level, one might be to be a lovable person or to love someone else.
Then I was wondering, well, though, you can go much, much lower to parts that you don't have control over. So it's, it's, you want to have transcriptase in your cells so that you can
have a replication of DNA, but you also want to have cell walls, it's not like you can control that. But that's at the extremely low level. And then at a high level, what I'm wondering is,
is there a relationship between the highest ideal and then God? And then is there a relationship to being fragmented there and having what's not monotheistic, so that is polytheistic. And then
if you have what's polytheistic, and there's a contradiction between them, is that one of the reasons why in monotheism, they say you cannot serve two gods? And is that related to people
who are well, all of us are in some degree, psychologically, not fully integrated, but is
there a relationship between monotheism and being fully integrated as a person where you have one goal that you're working toward, and they're not contradicted at some higher step. So you're
living in a in a more congruent fashion. You don't have to comment on that. You could probably say
that's all foolishness, but people do I can't resist because when you say I have lots of thoughts
as well. So that sort of can we act in order to make sure that our messenger RNA is working
properly? Yes, you can actually, but you'd have to use this sort of scale, different scales of
Markov blankets. But also there is actually a formalism that allows you to look at the way that
the central nervous system through neurochronology and through neuroimmunological mechanisms does
actually have an effect on gene expression. And this speaks to the transactions both between
Markov blankets, but also if a Markov blanket at one scale exists, that necessarily implies
existence at another scale. So a cell can only exist if the organ exists, but in the same spirit,
and in reverse, the organ only exists in virtue of the cells existing. And all of this has to
maintain a free energy minimizing dynamic in order to keep both scales in play at the same time. So
you know, it's a really, I think that's a really interesting example. The God versus, or
polytheistic versus monotheistic models of the world. I think that that's, you know,
a lovely description of sort of, you know, sources of cognitive dissonance, but possibly
the theological or existential, so that might underwrite or not ontological security, that,
you know, if I do have these counterfactuals about different things of the kind of person that I am,
or the data that I commit or subscribe to, then that's just another example of the opportunity
to resolve uncertainty. But in that sense, there's also uncertainty there, there's this puzzlement that underwrites the meta-hard problem, that is it this kind of God or that kind of God? Is it
the Holy Father or the Holy Son? And by introducing that uncertainty, you may well
expose yourself to cognitive dissonance and ambiguity and existential angst at that level,
which you will actively try to resolve. So that's this again, this imperative to self-evidencing
is acting in a way to minimize expected surprise or uncertainty in the future. So it may well be
that certain clerics... Certain sorry, what? Clerics. Clerics? Clerics, yes, or people,
Faraz Honarvar: Do our actions matter to the world?
people, you know, with an ecclesiastical... I see, I see, I see. ...leaning, they may spend a
lot of time trying to resolve that kind of uncertainty, that kind of cognitive dissonance.
Okay, two quick questions. That's it. Faraz says, in the context of embodied cognition, and by the way, Faraz is someone who graduated from U of T, right around here in neuroscience.
And I forgot the other one. So he's going to comment in the comment section about what I forgot. In the context of embodied cognition, what is the relationship between perception and
mathematics? And furthermore, if the external world perceives our actions, can we extrapolate
from that assertion, the idea that our actions matter to the world as well?
So that question you sort of hinted at before when you were... The duality between internal,
external? Exactly. Yeah, that sort of perfect symmetry, which I thought was, you know,
that was insightful. And I think that insight sort of speaks to the second half of this question
here. So, you know, it is certainly the case that when you simulate agents, conspecifics in a
particular environment or eco-niche, and you just integrate these simulation of physics engines,
and using the free energy principle, you get the kind of learning that you would normally expect
to see in the agents about the environment, but that is exactly mirrored by the environment
learning about the denizens that it plays host to. So I'm sure you know this, but my favorite example
from colleagues who really push these arguments as far as they can go at the present time,
my favorite, their favorite and my favorite example is a notion of a desire path or an elephant path,
which is the phenomenon that say, I'm going to get my coffee from the cafe on the other side of a
green or a park, and I can either walk around on the pavement, or I can take a shortcut across the
grass. And if I so do, I will eventually, me and all my conspecifics will eventually wear a
dusty trail of grassless signs and cues from my office directly to the cafe. So from the point of
view of the environment, this is basically the environment learning about the behavior of the kinds of agents that occupies that environment. So the environment is learning about the behavior
by being eroded, by being changed. So it's literally, it is remembering in its structure,
in its sub-personal structure, it is learning about the conspecifics that are good for occupying
that environment, the conspecifics that are occupying that environment. What are the conspecifics?
You and I are conspecifics because we're from the same species. So it's just a way of describing
an ensemble of or a collection of phenotypes, agents that have come from the same species,
and that the environment can learn, this is the kind of phenotype that operates well in my
environment, whilst at the same time, the phenotypes are trying to change to operate better in this environment. So there's a circular causality. While the phenotypes or the conspecifics
are trying to adapt to the environment, the environment is also adapting to those conspecifics. So it's a dance that in fact can get quite high order in the sense now that you and I will now
see the path and realize, oh, that must have, this path leads to somewhere that it must be nice
for things like me to go. So I can just infer seeing a desire path that it will lead to something
I desire because I know that everybody else who has used that are conspecifics. They like the same
kinds of things, they have the same attracting sets. So now the environment has learned about
the phenotypes and has memorized it in its structure. And now the phenotypes are now using
that to infer the kinds of things that I should do. So now you get to just using the environment
to cooperate and to signal and to change and to provide information for other things,
other creatures like me. And you can take that right through to the emergence of roads,
of traffic lights, of language. So you move these arguments. That's interesting. I didn't think about that.
Cultural domain. And now you've, so language, is that part of the environment or is it part
of Popper's third world or is it part of your brain? I don't think you can tie it down because
of this circular causality that you hinted at, in fact more than hinted at, when you recognize
that a Markov blanket, it's quite arbitrary what is internal and external. This depends upon which point of view you're taking. So I think it's a really interesting question, which you can take
in many, many different directions. I'm personally not taking it in those directions because I got
distracted by other things, but I have lots of young colleagues around the world who are really trying to understand this relationship to evolutionary psychology, evo-devo, the relationship
to niche construction, the relationship to what Andy Clark would have promoted, which is the
designed environment. So one of the sort of key parts of the triple, the four E's. So yes, it is
embodied, but there's also an extension. It's situated. So the environment, not just the
physical environment outside my body, but my body as environment as well, starts to become
an important part of this reciprocal loop and this sort of joint free energy minimizing mechanics
that rests upon a reciprocal exchange between one side of a Markov blanket and the other side of the
Markov blanket. I'll just close with the first part of the question, which is, does that mean
the environment perceives? I would say possibly not. It certainly would be the case mathematically
speaking that the environment is learning, but we generally reserve the notion of perception to
refer to perceptual inference or inference about states of the world, as opposed to the parameters
of a generative model, which are more attributes of contingencies, laws and the like. So that we
infer that the world is in this state or that state at this point in time, but we learn the
contingencies and the lawful mappings and likelihoods, the transition probabilities
that underwrite the changes and transitions in the state, the flux of states in the world.
So it's probably the case that the environment, the physical environment, not the body environment,
but things like roads and paths and buildings, trees, they learn, but they probably don't infer
and perceive in the sense of having qualitative experience of qualia, but they do learn.
They update their parameters in a way to model what's on the other side of their Markov blanket,
which is you and me. Thank you, sir. You've been far too generous with your time and I appreciate
it immensely. I think this conversation will be fruitful for quite a few people, especially more
on the philosophical end. There's not many, most of the interviews with you are more technical, so I'm glad that we got a bit philosophical, even though I love some of the technical questions.
Final words on Schizophrenia and existential anxiety from studying different metaphysics
I have maybe 30 more that I didn't get to, but we'll save that for the next time.
Well, as last time, it's been a real pleasure talking to you. Thank you.
Look forward to our next, next exchange. Thank you, man. Appreciate it. Honestly, I do. Thank you so much. And you've helped me
psychologically as well, because, well, just you telling me that other people are
going through what I'm going through, but sometimes even worse and sometimes better, but it's normal. That gave me at first some anxiety because I was thinking, well,
if your colleagues are going through psychotic breaks, I'm not at a psychotic break, but that means that it's possible. And if Cantor studying infinity could go through psychotic breaks,
I wonder how much of what I'm doing is self imposed from my own study of consciousness and investigating the universe. So it gives me gives me a bit of anxiety because it's like,
okay, well, this is a path that may lead to that. But at the same time, it gives me some calm, because you're saying it's okay. First of all, if it gets serious, it can be treated.
Don't worry about that. And, and it doesn't seem like I give off any signs of being schizophrenic,
even though I'm concerned about it. So. Ironically, the very fact you're concerned means you can't be psychotic. I did cross my mind when
you're talking about the monotheism versus polytheism and resolving that sort of cognitive
dissonance and existential angst you get when you, you know, you could be this way or that way. I mean, the very ability to entertain these counterfactuals is very, very close to psychosis.
So the, you know, the kind of the kind of angst you see manic depressive psychosis. So it's a
natural state for curious creatures. So the anxiety, you're going to go over the edge, it's just
the price you pay for being a curious creature. And as you say, you'll know when you're going too
far and you either get your wife to call him a doctor, or you'll just sort of commit to one way
of being on another way of being, you know, you, you, you will know that, but it's, you know,
what I'm saying is don't, you shouldn't be frightened of this. You should celebrate this,
you know, which is why I was encouraging you to make sure you write down everything you've Trust me, I write down.
Peers of extreme, extreme sort of loss of ontological security.
What I don't do is rewrite. And that's my problem as well. Because plenty of the writing is in the rewriting. And plenty of retaining it as in the rewriting as well. But anyway, I got to work on
that. Thank you, sir. You're I got it. I feel like I've gotten along with you more than almost
anyone that I've interviewed and interviewed almost 50 or 50 plus people. So I don't I don't
know what to attribute to that. But it's probably your, your demeanor and your there's a caringness
that comes across in your voice. And I appreciate that and a humbleness as well. Thank you.