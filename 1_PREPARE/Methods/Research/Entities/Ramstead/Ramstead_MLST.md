The Physics of AI

https://www.youtube.com/watch?v=8qb28P7ksyE
Machine Learning Street Talk



TOC:
00:00:00 - Intro to Maxwell
00:03:34 - FEP
00:14:42 - Markov Blankets
00:36:49 - Verses AI / Applications of FEP
00:51:29 - Potential issues with deploying FEP
00:56:24 - Shared knowledge graphs
01:00:03 - XRisk / Ethics
01:10:31 - Strength of Verses
01:14:04 - Misconceptions about FEP, Physics vs philosophy/criticism
01:30:15 - Emergence / consciousness â€‹


Well, it's a thrill and an honor to be here with you guys. Frankly, I'm just so pleased. This is really nice.
Maxwell, it's an absolute pleasure to have you here here today. And I want to thank you for coming on the show because you're one of the
uncommon type of combinations that I that I love talking to and find so enlightening, which is a philosopher who's also fluent in mathematics.
And I think that brings an interesting rigor to the philosophy. And there's actually like a really cool interplay between philosophy
and mathematics and science. So I think I think you gain a lot as a philosopher the more science and math, you know, and vice versa.
You gain a lot as a scientist and a mathematician, the more philosophy you know. Well,
thanks very much for your kind words. I'm inclined to agree that philosophy
and formal training go hand in hand. And you know, it is something of a strange historical circumstance that we don't think of philosophy as
a very formal discipline anymore. You know, if you went back a hundred years, some of the there was no there was no
separation, no hundred years ago. There was no distinction between science and philosophy. Right? Absolutely.
Think back to the Principia Mathematica, Right. You know, Russell and Whitehead, philosopher mathematicians,
you know, it was very common back in the day and less so now.
But you know, let's hope that the trend is reversing. I'm definitely optimistic about this. I think I increasingly find myself
surrounded by very technical colleagues who also have strong
philosophical backgrounds. So yeah, hopefully things are
changing for the better. Yeah. And you know, it's interesting. I'm going to take the time to ask you since you are, you know,
a philosopher like by by education and I mean no offense folks to philosophers whatsoever because I think science has lost out on losing.
Losing philosophy and philosophy has lost out on losing science And like the the rigor that, you know, confirming your thoughts
against reality can have. I mean, do you find that to be the case, which is that I find a lot of philosophers, you know,
without that grounding kind of in in science and mathematics, they spend a lot of time pontificating really about things that just
amount to the to the vagaries and ambiguity of like natural language
rather than than being able to map it to something symbolic, something concrete, you know. Mhm. Well um, so I think,
I think it depends what kind of philosophy we're talking about. I mean in, in general I think the, the ultimate problem is that
being a philosopher of science is difficult because you have to be a philosopher and a scientist and usually when you're training
you can only do one PhD. So I mean, I think to be like a proper philosopher of science, you know, you would have to be
familiar with the history of philosophy and contemporary philosophy of science and also to get some proper training in the
discipline upon upon which you are. Directing your reflections.
And so, you know, in my case, I had to do a lot of kind of
FEP
training on my own. So my, my uh, most of my coursework was in philosophy and cognitive science.
And so the, the the more formal stuff that I wield, I've had to
teach myself as a kind of side job. So like when I was doing my master's and my PhD in philosophy and Kokusai, I would also be teaching myself
math on the side. And I think that, you know, to, to to to, you know, exist effectively at these intersections,
you can't help but get some multidisciplinary training.
And you know, I think a good philosopher of science is necessarily a polymath in some sense like you need.
Well, thank you. Absolutely right. And I think that that is what makes it that is what makes it a kind of a rare breed. Right?
Like, you know, like one of my favorite philosophers of mathematics is Eric Curiel. And he and he has so much great,
you know, content on on general relativity and mathematics and philosophy in general. But like you say,
there are these rare, these rare combinations and or it takes a lot of self study, you know, to develop that. That's right. Yeah.
And I mean you know topics like the free energy principle and active inference are inherently multidisciplinary.
So it's it's beyond just like the philosophy and the math. You know if if you're in some sense if you're doing it well,
then insights from every discipline will wind up making contributions
to the way that you're thinking theoretically. So yeah.
Uh, but I um, this is one of the things that I love the most about our intellectual community around the and active
inference is the multidisciplinary, the multidisciplinary nature of it.
And that's sort of unavoidable, right? So, you know, the free energy principle which we'll be discussing
today is an explanatory principle that that its proponents at least
purport applies to every scale at which physical systems self-organize
and therefore, you know, insights from all of the different disciplines
working on all the different kinds of things become relevant. And the FCP then acts as a kind of like meta theoretical architecture
to fit these claims together in a way that's tractable from a physics
and from a mathematics perspective. Well, one of my earliest childhood memories is understanding how Cartesian
coordinates work when I was I guess. Yeah, 11 or 12 years old,
kind of really like understanding the mechanics of that and going like, wow, Like there are disciplines where there are exact answers to
the questions that we have. And so yeah, I was always very into the sciences and math, but I've also always been very
interested in the big questions and by the time I was done with high school I was I was either going into, uh, philosophy, physics or film.
And so I ended up deciding to go into philosophy and I, uh, I remained a
physics and math geek throughout. So I'm self-taught in a lot of ways.
Uh, and yeah, I ended up specializing in philosophy and cognitive science,
the philosophy of cognitive science and formal approaches in cognitive science in particular. You know, when I was doing my
undergrad, the embodied Enactive embedded extended traditions and
cognitive science were very hot. And so I learned some dynamical
systems theory and I was very into ecological psychology, which is a
branch of psychology that attempts to apply principles from physics to understand action perception loops. So I was very into all of this
cluster of ideas and around late 2014, early 2015, I was exposed to
the free energy principle and the ideas of Karl Friston in part by
reading this this really wonderful and by now seminal paper of Andy Clark's called Whatever Next, which was his famous paper where
he kind of reintroduced the the predictive processing framework
and active inference along with the free energy principle. So that essentially combined everything that I had.
Ever found interesting in some sense and had a real kind of conversion experience, if you want to call it that.
And so yeah, I had the pleasure and privilege of meeting Carl in the
flesh in May 2016 at a decision making conference in Montreal.
And you know, you've spoken to Carl a few times. He was very typical of Carl. He was extremely generous with his
time and friendly and insightful. And at the time I was working on
Sociocultural Dynamics and I was wondering whether it was apt to
apply the free energy principle to explain this kind of, you know, ensemble dynamics. And, you know,
Carl responded with an affirmative answer and encouraged me to,
you know, take this seriously and exchange with a few other people. And what began was a very extensive email correspondence
that turned into some papers. Carl then became my PhD supervisor and spent about, yeah, the better part of two years in
London with his group at UCL learning the ins and outs of the free energy principle. Yeah. And so so I guess that's that's sort
of my story and how I met Carl. That's interesting, you know, and the, the free energy principle so you learn about it
much earlier than than I did. I wish I'd had known about it earlier, but I didn't come across it until I guess a couple of
years ago when I were the first, you know, the first MLS episodes that that we did on it. But I had I had quite a bit of
Bayesian background up to that point. So when I first saw it I thought, Wow, this is really ingenious. You know, like I'm fascinated by
it and we wanted to learn more. And so we've had we've had Professor Friston on the show a couple of times and like you said,
tremendously insightful. You know, one of the most brilliant people I've ever spoken to. It's such a joy to talk to him.
And I think even though we've he's been on the show a few times and talked about we should probably frame up a little bit about what the free
energy principle is. Absolutely. It'll play a big role in our communication going forward here. So let me take a stab at it.
Absolutely. That's great. You're the expert. Like like you you're usually really good at summarizing.
Well, you know, what fascinates me about it, I think is and I want to get to the the crux of this this beautiful statement that was
made about it being the ultimate existential question. Right. Because usually we think what does what does a life form or a thing
even for that matter, what does it have to do to survive? Right. Like this is kind of the emphasis of, you know,
are you fit the Darwinian sense? You know, what kind of fitness does it take to survive? But this the free energy principle
completely inverts that and it says, okay, if things exist, if things survive, what must they do? Right and it turns it on the head
in this way, which is let's assume that there is a thing, you know, and it and it continues to survive. It continues to exist just by
knowing that what must it do? You know what what dynamics, what behavior must it have? Is that a fair framing and what
is what are those behaviors that things that exist must do?
So, you know, I think the way that you describe things is accurate and
an insightful way of putting things. The free energy principle is not just a basically a theory according to which things that
exist must be doing this or that. As in it's not it's not trying
to to tell you here's something that things do in order to exist.
What it's what it's telling you is we we observe that things exist in the sense that there are there are systems or particles or things
that can be reliably re-identified that are separated from but
coupled to their environment. And given that we observe these things that exist, what must be true of them.
So it's a kind of inversion of the explanation moving to like a kind of
first principles account of what what what must necessarily be the case if you exist And essentially what the free energy principle tells
you is that if you exist in the sense that you are separate from but
coupled to an embedding environment, then it will look as if you're tracking the statistical structure of your environment or more precisely,
it will look as if the states or paths that are internal to a
given to your boundary of a given thing track things that are external to that boundary. So in some sense it it explains why
or it provides a principle allowing us to explain why it it looks as
if everything that exists is yeah, tracking or representing depending
on how you want to think about it, features that are external to it. And this this tracking or representing relation is it is rather
weak in some sense, but we're not talking about like necessarily contentful representations, little images in my head what we're
talking about is something I think more fundamental or existential. So for example, I can see from your your camera
feed that you're wearing a. A button shirt that tells me
something about your environment so I can read off you from the
fact that you're wearing a button shirt that you're probably not in the Arctic somewhere. I mean, I can see your background
also. That's kind of cheating. The basically we we can read off
anything properties of its of its embedding environment by virtue
of the fact that it exists. Right. Right. So yeah, I think there's an interesting point in there,
which is that it isn't this exact 1 to 1 correspondence. I mean, really, how could it be? Right.
Markov Blankets
Like how could a how could say a subset of the system precisely represent the entire system, but instead in a sense it's
representing an abstraction of the system, you know, and I mean, I think there are even good energetic arguments why that would be the
case because, you know, since you can't maintain total information, you maintain an abstraction of it. You maintain enough in order that you
can predict and track, you know, behaviors because you exist. You must continue to exist, but you don't require complete information
only sufficient sufficient tracking. Absolutely. Yeah. Heuristically you can think of the the free energy principle and
this is metaphorical of course, but as a map of that part of the territory that behaves like a map. So it is a scientific principle
that we can use to construct models of systems that appear as if they are in turn modeling or tracking aspects of their environment.
And think thinking about modeling for a second is useful here. So if you had A11 scale map, is it Borges who who presents that
in a in a story at some point? Yeah, I think so. Yeah. So a 1 to 1 scale map would be completely useless, right?
I mean, just imagine the quantity of paper that you would need to have a map of, say to write a 1 to 1 scale map of LA.
It wouldn't be useful in the generation of, you know, your actions. So the map is necessarily
simpler than the territory, but that's okay in some sense, right? Because the implication of that is that using the map you're
going to encounter errors, you're going to generate errors. But in the active inference and the free energy principle approach,
those errors are the relevant signal basically. So all all you have to do is have a good enough map and act in such
a way that you are informed by what your map contains in terms of information and you in real time course correct based on the
errors that you're generating. So it's these errors in the kind of oversimplified character of the model or features rather than bugs.
You would need that in order to have a signal at all in some sense. Yeah. And there is this iterative nature to it that I think is sometimes
forgotten because you know, there are these two components and the free energy principle. One is fidelity. How accurately does it kind of
map to the environment? So so if you if you think of the the entity that's surviving the thing that surviving, you know,
it has to have a model of the environment has to be has some degree of fidelity because if it doesn't, it's not accurate enough to
maintain its survival. But at the same time, it also has to have adaptability, right, Because the information is never complete.
There's always new, you know, phenomenon occurring to it. The environment is changing or whatever.
So the model has to maintain a degree of flexibility. Right. And that's what this this kind of entropy term in there is.
It's saying precisely, you know, you need to maintain a certain amount of entropy because that is a form of flexibility. Is that correct?
I mean, that's absolutely correct. And you can think of the entropy in a few different ways and the entropy term in previous discussions
with Karl Friston, you have highlighted its technical importance.
I mean, basically what we are what we're trying to do when we minimize free energy is to increase the predictive accuracy of our model.
So that is to have a model that generates predictions that are as close as possible to the real data that I'm ingesting.
But the free energy principle allows us to, in a in a principled manner,
penalize the complexity of the model. Right? Because you don't just want an arbitrary explanation,
as you know, you can construct an arbitrary explanation for any
data set and you know, it can even be deleterious if it's
if you have incomplete information and you model it too accurately, accurately in a loose sense, then actually you're just you're
memorizing spurious information that doesn't generalize. Absolutely. Yeah, absolutely. And so the free energy principle,
when you're when you're applying it and you're saying that systems that exist minimize this this quantity, variational free energy,
the variational free energy can be decomposed roughly speaking, into predictive accuracy minus complexity. And so what you're doing is
you're penalizing your gains in predictive accuracy against the
the complexity cost of your model, basically penalizing every new degree of freedom that you need to introduce into your model to explain the data.
So in some sense, the free energy principle is sort of like you can think of it as kind of like a statistical predictive accuracy,
but also Occam's razor, Right, right, right. So yeah, the.
No, no, it it it makes sense. I mean, and that's it's an interesting balance. And the free energy principle
encodes that balance. And I guess the simplest, the simplest way possible this is a sense in which the free
free energy principle applies to itself because it's. That's right. It's almost the simplest formulation of that of that balance, right? Yeah.
I mean, there are all sorts of ways to control for complexity that have been introduced in machine learning, but those all
might seem ad hoc in some sense. What we try to do is to build in this complexity control right into the objective function that
we're using, right? So it's it's at the core of the architecture is that rather than just use reward,
which you could probably cast in terms of like predictive accuracy. So I think we have one more foundational concept that I'd like to
kind of get on the table and that is just the concept of a thing, you know, because because a thing the idea of a thing is is defined in
a very certain way in the context of the the free energy principle. And it's all about this this Markov blanket.
And and we've talked about Markov blankets a few times on the show they tend to be confusing. You know I, I tend to I almost
visualize them usually as cells like in the human body. So like, you know, you have a cell and it has stuff inside and
then it has the cell membrane and then there's the stuff outside, which is kind of the environment. And that membrane in a sense is
the Markov blanket. It's the set of stuff and states between, you know, what's inside and outside.
But can you talk a bit about, you know, why Markov Blankets are important, what they are, how they're defined
and maybe some of the edge cases like does an eternal flame have a Markov blanket? Why or why not? That's that's a great set of
questions. So you can think of the free energy principle as a the same kind of thing as the principle of
least action in the sense that it's it's a principle that allows you to write down mechanical theories or mechanics, right?
So classical mechanics has the principle of least action and
the principle of least action is basically a way of specifying the
the the conservation laws that we want to see our systems conform to, in particular the the balance of the potential and kinetic energies
are zero and the real trajectory of systems, physical systems are
those for which that balance holds. And they are maybe I'll just quickly interject here. It's not so much that we want
them to conform to that, it's just that they do. Yeah. And and that's actually key to the free energy principle too,
because it's not like it's not like we want things to obey the free energy principle. It's that they must obey the free
energy principle if if they, you know, exist. Right? Absolutely. I was speaking in the manner of a mathematician. Oh, yeah.
No, totally, totally get it. I just wanted to point this out to our readers. Is that because as we go along like you are almost these are principles that in the case of classical
mechanics just are they're just the way things behave. Right?
And in the case of the free energy principle, if you survive, if you exist, you're inexorably drawn to the set of dynamics,
to the set of mechanics. Otherwise you don't exist. Well, to get technical for a second, I think there are two issues that
that are both striking and that speak to what you just said. So things like the principle of least action and the free energy principle
and the principle of maximum entropy, they are in some sense true a
priori or mathematically they are mathematical truths. So you wouldn't try to falsify the principle of least action empirically
any more than you would say, try to falsify calculus or probability theory by coming up with an empirical counterexample.
So there's a sense in which, like the the truth of these statements is robust and mathematical. Having said that, it is a striking
empirical fact that the physical universe does in fact seem to conform to these mathematical regularities. So it's sort of A12 punch in
some sense. And. Right, right. It's the unreasonable effectiveness of math. Absolutely. Yeah. And it's getting even more
unreasonable now with the free energy principle coming into play. So the way I like to think about the free energy principle is,
like I was saying, as introducing a new family of mechanical theories or mechanics. So you have classical mechanics which
follows from the principle of least action and you have quantum mechanics and you have statistical mechanics. So basically the idea behind the
free energy principle is let's get the rest of physics working in the background So you get you get your. Classical statistical and quantum
mechanics working with all of those. Yeah. All of that mechanics is in play. And then you ask a simple
question What does it mean to be a thing in this context? I.e. what could it possibly mean to re-identify some state as the system
as being the same state over time? And so yeah, unpacking that question
leads to a Bayesian mechanics. So Bayesian mechanics is a physics,
but it's a it's a physics for the that kind of duly constrains
the system itself, the physical system and the beliefs that the system encodes about the things to which it's coupled.
And that I think is really the key for the kind of underwrites this whole construction. This is also what makes it
unique among other candidates in the cognitive sciences and the
biosciences. It's that it is connecting the thermodynamic entropy of the states that the system is made of.
To the information entropy of the beliefs of the probabilistic beliefs that those states encode. So the free energy principle is
all about this hinge between the two and the equations of motion that you write down Using the free energy principle are constrained
in both of these spaces. And that, I think is absolutely the key to understanding what's going on here.
Like the the system trajectories that you get when you're writing,
when you're writing down an theoretic model of the system
that you're considering. It is constrained both by the physics and thermodynamics of the system and by the physics of the
representations, if you will, that the system is entertaining about the rest of the universe in some sense. And I think it's it's not without
precedents in the sense that, for example, in statistical mechanics, you know, back back when we're deriving boltzmann's distribution
and there were questions about are these particles, do they behave as if they're identical or if they have the same attributes?
Are they are they are they the same particle and the same thing with Pauli Exclusion, You know, it applies to some particles and not others.
So there those are examples of where a statistical calculation,
a statistical property does map to the actual underlying physics
that's happening as well. This is almost a big step up from that. It's like, you know,
it's a generalization to a much richer set of I don't want to
say conservation laws, but a much richer set of these flow laws, you know? Absolutely. And that's yeah, that's exactly
the right way to think about it. In fact, what's transpired over the last few years is that you really you can think of the free
energy principle as a kind of generalization of the second law of thermodynamics to open systems. So, you know, the kind of
universality that the second law has with respect to closed systems,
the free energy principle has with respect to systems that are far from equilibrium. And as Carl has, you know,
pointed out, the Markov blanket is precisely the apparatus that allows you to move from the equilibrium to the Non-equilibrium regime in
the sense that you are now specifying the interface through which the system is coupling to its environment or the particle.
So the word system is a bit ambiguous usually, you know, because we could mean, you know, the whole agent environment system
or we could mean the specific kind of compartments that we're considering as agents. Yeah. So the you can think of the the
free energy principle as applying to systems that are not
at equilibrium and as giving you the dynamics of like particles within the overall system. If there exist particles in the
system, if there are these things that you can poke and re-identify over time, then the free energy principle will basically tell you
how they behave on average. Yeah. And it's it's interesting because
almost the Markov blanket really provides a concept of stability because when I think about equilibrium, right, when when you
know, the thermodynamic kind of equilibrium, what comes to mind, at least visually to me is things that are kind of unchanging and
just kind of quiescent and they're just sitting there like a goo. You know, that's kind of all thermally stabilized and never,
never moving around. But that's the point. The key point there is stability. Like it's a it's a stable sort
of unchanging system. And what the Markov blanket gives you is a way of defining a property that's stable about the system.
And yet the system as a whole may be far from stable. It may be in flux and moving around all the time and jiggling.
It's the eternal flame where the boundary is kind of changing all the time. But there's this property that
you can map from from time to time that that's still there. And so it's the stable, the stable blanket, even though
it may have a different form, it's still got a boundary between some stuff that's inside and outside that's identifiable,
you know, from frame to frame, if you will. Yeah. And I'd go even further and say that it's the self identical
pattern that you see at all scales of self-organization. So it's got this kind of fractal quality to it where, you know,
it's blankets of blankets, of blankets, of blankets. So I mean, you can think of the brain, for example.
So the brain has this nice Markov blanket structure at several different scales. So you can start with neurons
and neurons have their own Markov blankets that. Yeah. The cell membrane. Yeah, precisely. And it's probably the most obvious.
But you can go downwards and scales and upwards and scales and what you recover are, you know, similarly Markov blanket structures you know,
from the, the from the voltage gated channels on a cell membrane
to dendrites to the you know, arborescences that form up to the the
the neurons soma and then you know, you could go the other direction too,
right? From neurons to canonical microcircuits to more specialized brain regions to
brain networks and so on. All of these things are things that can be reliably re-identified with their own kind of, you know,
properties and features and connectivity to other things. And they all have this same pattern that repeats.
And so it really is. Yeah. So and I think anybody can see that pattern. I mean, look around we got we have
trees and they have boundaries and, you know, even higher in scale you have planets and galaxies and but at the same time, if you if
you dig down into it and you try to really precisely define it, then it it slips away. It's like if I zoom into the surface
of my skin, you know, fine enough. Well, it's no longer a surface. It's this ragged thing with cell membranes and then the cell membranes
are molecules with tons of space, you know, in between them. And heck, atoms are mostly empty, right?
Like there's this this weird, you know, vagueness and difficulty in defining, you know, boundaries. So they're not sharp.
Like, how's the concept of of a Markov blanket? How does it evolve to that kind of fuzziness or this this great
set of questions? Your questions are so on point. Keith Frankly, this is so I would say the the first thing to say
is that so this is sort of mind physics or brain physics, if you want to think about it like that. And one hallmark of explanation
in physics is simplification or, you know, you might say oversimplification. So I'm sure a biologist reading a
paper on the free energy principle might look at this and go, But you know, this is way too oversimplified, whereas the biological detail I
think physicists also do this to physical phenomena, right? Like that's that's sort of the joke. A physicist would respond, Yeah, but
we do that to physics as well, right? Like it's so yeah, there is a deliberate idealization going on If you define this Markov blanket
strictly as the the set of degrees of freedom that render some inside
independent of the outside. Right? So if conditioned on the blanket states you can speak of statistical independence between
the inside and the outside. Well that that is too strict to describe most physical systems. Right.
So I assume you myself and our listeners, we all had a bit of coffee this morning. We've all used the washroom.
So there's clearly a kind of permeability. Exactly. There's clearly a kind of permeability at play.
And so, yeah, we we know that there is material turnover in most of
the kinds of systems that we find interesting, especially those that self-organized far from equilibrium. So the Markov blanket is
necessarily an idealization. Um, having said that, there are good
reasons to think and we have some results coming out later this year.
A lot of them are due to our senior mathematician Dalton Shakti Vadivel, who is an absolute dynamo. So we I've seen I've seen some
of his papers. Yeah, it's very impressive stuff. He's been working on weak or fuzzy blankets in precisely this context.
So the the idea is can we get really rigorous about the
mathematics of approximate Markov blankets or fuzzy Markov blankets?
And the idea in a lot of his work is to construct this this quantity called the blanket index to gloss over some of the technical details
just for in the interest of our our audience basically there if you
consider a given dynamical system, there exists a Markov blanket in that system if a specific inner product is equal to zero.
So in particular this is the Hessian of the and the the solenoidal flow,
the product of those two things being zero. What it basically is a way of quantifying the the force or the
curvature that a system is subject to. And yeah, if the entries in this inner product are zero then there
is a strict Markov blanket. But there's a way of constructing an index or a measure such that you can accumulate the non-zero
entries and basically quantify how far from perfect blanketed
ness a system finds itself right. And so yeah, this blanket index has a
number of interesting properties, one of which is that it it, it tends
to zero as systems increase in size. So under what kind of assumption.
So it's very, very, very general. So locality assumption or Yeah
like you get the locality stuff from from the background right. So you get the rest of mechanics going. Right So Oh okay. Okay.
Verses AI / Applications of FEP
So then you already have like you know relativity in the background and you have statistical mechanics, classical mechanics and all that
stuff. So yeah, you do get this kind of nice locality. So that's interesting. So in, in a universe like ours that
has the, the basic physics that. That a universe like ours has as the scale of a system gets larger and larger.
You generate Markov blankets, you're bound to with a probability one. Yeah. Absolutely fascinating. And you know, most of the systems
that we consider in physics are large in the appropriate sense, right? So think about how many molecules are in in a drop of water. Right.
It's ten to the 26. Right. Some some something times Avogadro's number. Yeah, exactly. Itself is ten to the 23rd. Yeah.
So ten to the 23. Sorry. Yeah. So that's just for a single drop of water. Now if you consider the brain,
the brain has like something on the order of 100, 150 billion neurons, each of which make thousands of connections.
If each of those connections can encode a parameter, then you're talking about like a very large system, right?
We're way, way, way beyond like, you know, 20, 50, 1000 different
states that are coupled together. We're talking about like billions and trillions of different states. So there's reason to think that just
due to the physics of the situation, most relevant things that we
might want to consider will have Markov blankets and I mean it.
So Dalton is going to be releasing a few papers having to do with large fluctuation theorems. Okay. And so this let's pause for a
minute and appreciate this because this to me is a fascinating a fascinating result. So okay, so we start from the
point of a Markov blanket is kind of this intuitive concept, right? Like it's a boundary and and that sort of thing.
But there's no reason to believe that they're inevitable. And I'm finding it fascinating that there's that there's this work,
right, that says that as a scale. So we have a measure of blanket ness. It's kind of between 0 and 1 zero has a blanket, one doesn't.
Okay. That's right. And and yet as the scale of the system gets larger and larger, blanket ness approaches zero,
you get blankets no matter what. And in a sense there's a sense in which that's recapitulating what we see.
If we just look around like everybody out there listening, look around yourself and you're going to see blankets all over the place.
You're going to see things. And those things have have boundaries. Right. But it's it's remarkable, right,
that that there's a mathematical proof that that's inevitable in
this sense, isn't it? Well, I think it's remarkable in part because we have approached the question of
self-organization and emergence from a false starting point. So I've been going around saying recently Aristotle was wrong.
That's that's sort of my philosophical start. Well, the whole is much less than the sum of its parts, it turns out.
So yeah, there there are a bunch of things to unpack from that. Well, the first is that what makes you the kind of thing that you are
is the sparsity of your coupling to the rest of the world, right? If you think of a gas right where everything is coupled to everything
else, then it's just this fuzz and it's all one system and there's there's no you can't really identify particles within the system.
Particles are things are defined by their sparse connections to everything else. So I am in some sense what I am
not or I can be defined in terms of what I'm not connected to as opposed to what I am connected to. I mean, if you were to create like a
giant adjacency matrix for the entire universe, most of it would be empty,
right? No, I get what you're saying. That's critical. The whole the whole is less than the sum of the parts, which is there's more If you if you get rid of the parts you have,
you have less. Right. And but but there's more the so
think of an engine right. Like an engine functions as an organized whole because you're constraining its parts to behave
in very specific ways. So like, you know, if you think of an engine more specifically like a petrol engine, well the
mechanical effect of the engine you get by moving these pistons in a
specific direction up and down. And the best way to wreck your engine is to introduce new degrees of freedom into it. Right?
I would not want to introduce new degrees of freedom into the Pistons. That's a that's a great way to just tear your engine apart.
And I would submit to you that this is, you know, an inaccurate way of
thinking about all self-organization. We exist as wholes because our parts are constrained to behave in very specific ways.
So it's not merely that I am what I am because I am not what I am not.
It's just a nice tautology. It's that the what makes me what I am is the way that I remove degrees of freedom from my parts such that
they conspire to create, you know, to generate me as an overall pattern.
So I mean, it's it's counterintuitive from the perspective that we inherited. From, you know, a traditional
Aristotelian metaphysics. But I mean, yeah, it is.
It's so exciting. I mean, it really is. I don't know. I don't know why I get excited, but to me it's it's really excited.
And this I mean, so this is work that's coming out of verses, correct? That's right yeah that's right And so coming out of yeah I would say
a coming out of Karl Friston's group more generally and let's not forget you know Karl proposed the free energy principle in the
middle of the 2000 knots. Yeah And so yeah but definitely
this is the the powerhouse behind versus I technologies So yeah.
And let's talk about that for a minute because um, yeah, we generally don't talk about, you know, companies on the show,
but this to me this is an exception because it's fascinating what you guys are doing. Thank you. And so versus versus technology
is trying to operationalize these this understanding really and as
technology and I guess and I'm super excited by what we've been talking about conceptually but tell me, why should anybody care?
Like what does this what does this fascinating, you know, view of philosophy and mathematics and the relationship to really I
think it's really about understanding complex systems in a new way and new mechanics of complex systems. What does that mean for us?
What does it mean technologically? Well, thank you for your excellent question. Um, so I think one of the things
that we want to do at verses is to apply active inference to artificial intelligence. So active inference is basically
the kind of machine learning that follows from adopting the free energy principle as your kind of core method.
Our contention at verses is that active inference will be to the 2020s what reinforcement learning was to the 20 tens effectively.
So it's going to be, we think the way of doing machine learning,
the ethical, scalable, most efficient way of doing
machine learning and there are a lot of different aspects to that.
So one of the main differences between artificial intelligence
built on the principles of active inference and more traditional approaches is that we start from an explicit generative model, so-called.
So we talked about the Markov blanket. The generative model is another core piece of the free energy principle
puzzle or constellation, if you will. And the generative model is basically
a statistical description of the dependency relations within the system that you're considering. So when we're talking about Markov
Blankets, actually what we're saying is the generative model of the system contains a Markov blanket, right? So all of these dependency
relations that we're writing down, like once you do write them down, you get this nice sparseness structure where some parts of the system do not
affect other parts of the system. And so yeah, this this generative
model is really key to the doing of the free energy principle.
Um, and so yeah, what we do in active inference is write down generative models explicitly labeled generative models that then
allow us to perform inference. They allow us to do that because the
variational free energy that we were discussing earlier, basically the, the the gradients of the free energy that you're following,
they come from this generative model basically, right? So yeah, the model itself is this explicitly labeled structure and
this is where you get like a huge explainability advantage.
We actually have a paper that came out on designing artificial intelligence, explainable artificial intelligence using active inference
and yeah, what what you get just immediately from flipping to an
active inference framework is a way to write down Yeah, a generative model such that it is explicitly labeled and thereby auditable by
human users and stakeholders. So you don't have this unlabeled,
you know, 10 trillion parameter net as it were. Right. Right.
Which you have instead is yeah. A model that explicitly represents all of the different factors in the situation that you want to control.
So let me dig in to this. Let me dig into this a little bit. So. And I because I'm curious. There's a connection here to
some some work I used to do a long time ago. So writing down generative models, my experience has been at least is.
It's actually relatively easy to do that. So for example, a long time ago I was contracted to do some work on mad cow
disease so we could try and figure out what interventions to do to reduce the spread of mad cow disease. And it was pretty, pretty easy to
learn about the the food system, the supply chain, the food system to
model, you know, the processing of of cattle and that sort of thing and write down a large simulator. So this would be a generative model
can sit there and can generate trajectories through this space, right. Like we knew we could do that. We couldn't tell you anything
about the large scale kind of thermodynamics of the system or anything. Right? We could write down this generative
model though, and then using various sampling and techniques like that, we could then compute statistics from it, try out interventions,
see which of those had had kind of a beneficial effect. But that was all ad hoc architecture that we we designed
and produced by ourselves. If I'm understanding you correctly, what you're doing is producing a technology that one formalizes
that much more and applies the free energy principle I think to help guide like the sampling and the optimization and you know,
really just the effective use of these kind of generative, you know, simulations and models. Um, is that. Close to what you're talking about.
That's right. So I mean, you can why use active inference? It is demonstrably the most efficient
machine learning technique. So it's sort of like, you know, a Carnot cycle analysis but for for an engine but for AI in particular,
what the free energy principle allows us to formalize is the thermodynamics of information writing onto the boundary.
So in in some of the newer work on the quantum information theoretic
formulation of the free energy principle, which we don't necessarily have to get into in detail, but there are these kind of new
scale free extensions to the free energy principle that have been developed that appeal to the tools that have been developed
on in quantum mechanics, right? So the theory of very small, fast things but quantum information theory.
So the kind of information theory that gets augmented to handle things like probability amplitudes, which are the the roots of
probability densities. And so you can get your wave equations moving. Place and all that. So the that formulation of the
free energy principle allows us to formulate the computations carried out by a system in terms of like a per bit read and write cost.
So there's a there's a there's a sense in which like you're bringing it down to the like to the the bare kind of, you know, machine
elements of the of your computations and you're writing things down in a way that is demonstrably the most efficient way of doing it.
So if you if you set up, you know, some simulation system using active inference, you are and this kind of brings the conversation full
circle in some sense you are generating a model that is as predictively accurate as possible, but also that expends as little
energy as possible due to this, you know, controlling for the complexity of the model. So yeah, we have this this preprint
up that we'll be revising soon. Um, called the map territory fallacy
fallacy which is precisely about the kind of canonical nature of
theoretic modeling. Yeah. The, you know, the one of the reasons
why the is optimal is that it's it's another way of writing down
jaynes's maximum entropy principle. So for our audience, the maximum
Potential issues with deploying FEP
entropy principle you can think about it from from the point of view of statistics and also from the point of view of statistical mechanics,
from the point of view of statistical mechanics, the maximum entropy principle is the principle according to which things dissipate.
Um, so from from the point of view of statistics, it's the principle according to which give me a data set and a set of models from which I
might have sampled that data set. The it says the model with the highest entropy is most likely to be the the real model from
which you sampled. So that's a way of kind of saying like what is a maximum entropy probability density?
It's a flat density, right? And so basically a maximum entropy
probability density encodes no information because all of the outcomes are equally probable. And in some sense what Occam's
Razor would tell you is that like you would want your model to be as flat as possible, right? You want to build in spread out
as possible. Exactly. You want to build in as few assumptions as possible into your model.
This brings it back to the whole keeping your options open thing that you were saying you were discussing earlier.
You know, if you're thinking of a probability density over different courses of action, unless you're really sure that you want to do this,
you probably want to keep things as non-committal as possible and keep your options open. So. The just to back up then The
free energy principle is a is a way of writing down the principle of maximum entropy. They are effectively the same thing.
You can move from the one to the other And we know that the principle of maximum entropy is is is the principle of parsimonious
explanation in some sense, right? So if the and maximum entropy
are the same principle, then all of the epistemic virtues that accrue to maximum entropy also carry over to the and therefore yeah,
a a a free energy principle theoretic model of the belief updating of a
particle can be shown to be the optimal dynamic systems model for the
whole system that you're considering. Like there is a kind of canonicity what we're calling Jaynes optimality that yeah the basically the it allows
you to write down the best model that you could for your the system that you're considering given your current state of knowledge in that system.
It's just the optimal way of writing that down full stop. Uh, so that's why we, you know, care about active inference. Yeah.
It might be useful to, to give some examples of um, of, you know, maximum entropy distributions to understand.
So for example, if you have a data set and let's just suppose it's continuous data and it's and it's positive only.
So I know that it's continuous data, it's positive only and I know that it has a particular mean, you know then the,
the distribution that has the maximum entropy under those examples is an exponential distribution, right? Like it's sort of spread out as
much as possible and yet it has a particular particular mean and
and for example if we go to the case of it can be a real number anywhere between minus infinity and infinity and it has a mean but
it also has a finite variance. Then you wind up with the Gaussian distribution as being, you know, the maximum.
So it's really it's it's a distribution that captures what you know about the system i.e. the constraints, right?
And yet is as spread out as it's possible to be while satisfying those constraints. Right? Absolutely. And you know, I hope our audience
is able to kind of see the pattern that's starting to form here. You know, like all of these connections are non accidental.
Right? So the the is all about balancing your predictive accuracy and your complexity. So all these things are kind of connected at a deep level.
Uh, and yeah, I mean maybe the audience also can see why we're so excited about this. Like this is highly non-trivial.
Well, and I don't know if this is crazy or not, but it actually even seems to have implications for fairness of of
models because So for example, suppose I'm trying to train a model that does anything of human interest, you know, diagnose or prescribe
medical treatments or, you know, give out give out loans or that sort of thing. And we need to train it on some
type of data, whether it's a generative model that we calculate or data that we actually observe. Well, we want we want the system, we
want the machine to learn only what's relevant for that particular task.
Shared knowledge graphs
And like nothing else, you know, we don't want it to to learn kind of extraneous things. So for example, if it's deciding
to hand out medical diagnoses, we want it to be based solely upon the medical attributes that are in in the, you know, the data set and
not some spurious correlation to like a the geography or, you know,
where where you came from or or the letters in your name of your file or anything like that. And so in a sense what maximum
entropy helps you to do is force out that stuff because that stuff, if it's not useful for the actual prediction, it'll get, you know,
ironed out because it's smoothed out by the demand of maximum entropy. That's right. And that brings us back to
sparseness, right? How so? Tell me. Well, in the sense that, you know,
this this even has to do with like situation or task definition. Like situations are sparse. They're not all not everything
is connected to everything. Not everything is relevant to everything else. So there's even like a kind of it's
really a kind of a meta methodology because you can even define
specific situations in terms of their sparseness And then. Yeah. So, um, so it sounds it sounds great, but I'm always the eternal skeptic
because I know a lot of this type of computation, you know, the generative starting with a generative model, doing inference on it just
computationally is so difficult. Like what what is the magic that
verses is found and how are you so sure that how are you so confident that it's going to work? Great question.
So I mean, in particular, one of the big questions that plagues generative
model based methods is where do your priors come from? Right? So what is the structure of your model?
What are the parameters that you're using, What's the relevant state space? All of that is often I mean,
often you have to hand design this stuff and it's very labor intensive.
So at verses we are a a contextual computing company,
so we draw inspiration from the architecture of the brain and
basically we're proposing a kind of general standards based solution to
the problem of where do your models, where do your priors come from? So just to, you know, do a crash course in neuroscience,
Um, so we love neuroscience here, so please do, I'm sure. Well, so source of inspiration. I'm sure everyone is familiar with
the idea that the brain has a layered or hierarchical structure.
So it's not the case that the brain is just a soup of connections where everything connects to everything else.
To the contrary, there there are very regular structured patterns of
connectivity in the brain. Okay. Again, this takes us back to the theme of sparseness, right? Like the to say that the brain
has a hierarchical organization is to say that it evinces a specific very special kind of sparseness where connections are
directed in specific ways, where you're connected to layers immediately above and below you, but nothing beyond that.
Um, so we've spoken in the past to Jeff Hawkins. Like is this related at all to the concepts of cortical columns and like
the way in which they're connected? Like it almost has these, you know, components that are reused and put Absolutely In
XRisk / Ethics
terms of different layers. Yeah. And not all the layers speak to
each other from a an active inference perspective. This layered or level level involving structure has a specific purpose.
So what each level is doing is providing priors or expectations
to the level below and receiving context from the level above.
And what each layer is doing in turn is shuffling prediction errors to the to the level above and receiving prediction errors
from the the level below. So what you have is basically a
set of layers that contextualize each other and the way that each layer contextualizes the next one is essentially coarse graining. Right.
So there's some fast, fast, small scale activity that lower levels are
tracking closer to the sensory end and with each successive layer is doing is finding basically the the set of hidden states or latent states
that explain variance in the data that it's receiving and so on in
this kind of hierarchical fashion. So the the brain is not one monolithic system. Rather each layer of the brain is
specialized in encoding specific features of the situation pitched at a specific scale and it functions by kind of providing context.
So we like to say that the brain is an organ of context effectively where really what it embodies is successive layers of context that
are each coarse graining each other in this kind of fashion. So so I know, I know our neural network fans out there in the
audience are going to they're going to be hearing that that's just what a neural network is like. It has kind of layers.
You know, they're connected. What's what's different about just any other kind of neural network architecture, if you will?
So what we're proposing is an infrastructure project in some sense.
We have we're working with the IEEE in the US.
So when I say we versus has a sister organization, a nonprofit
called the Spatial Web Foundation, which was to whom we gifted the the
first massive chunk of research that came out of our group. And what we are developing with the Spatial Web Foundation is a
is a set of public standards that people can use to build out
basically shared knowledge graphs. So we're building an ecosystem
where folks can basically think of this as sort of like Wikidata or Wikipedia, but for kind of shared contextual compute context.
So, you know, obviously we are building this out. So we're going to be the first to put things onto this network.
But what we're trying to build is basically a spatial web or a hyper spatial web that kind of in some sense reflects the structure,
the kind of graph structure of the various kinds of situations
that humans deal with it. So it's so it's really an application of, of interesting. So it's it's an application of the
free energy principle at multiple scales. Absolutely not. Okay. Okay.
So my mind was going in the wrong direction here, which is I was going to like the scale of of, you know, the individual thing and how it does
its its modeling. It's compute. But this is this is more than that. This is Well it is that you're absolutely correct that but it's more
than that it's that it's and it's actually like a multi scale I guess
arbitrarily nested really framework for communication across absolutely
not Not even a it's more than a mesh. It's what's the right word for it. It's a hypergraph I guess it's a hyperspace.
So we call this the you know, the name of the protocol that we've developed for modeling is called the Hyperspatial modeling language.
It's meant as an homage and a nod to HTML.
And what we hope it doesn't use the same syntax. Please.
No, no, it won't. Well, what we've also built is a transaction protocol and a querying language that live
within the hyperspace. So so-called hyperspace transaction protocol Http and the hyperspace hyperspace querying language SQL
And so yeah, what we are basically in the business of doing is on the one hand building out these graphical models of knowledge,
basically of the knowledge that is involved in specific tasks, domains and situations. And then we've developed methods
to take these knowledge graphs and to flip them into graphical models of inference. So that's really that's that's
kind of where the secret sauce and the magic happens is that this is a two step process. And the overall versus technology
stack combines active inference based AI with explicit generative models on
the one hand and this kind of nested hyper spatial representation of the problems to be solved on the other. And the technologies kind of are
married through their kind of reliance on on graphical
techniques basically. So it's knowledge graphs meets graphical inference in a nutshell. Yeah.
And we we really are committed to developing these in terms of,
you know, open publicly available standards. You know, there's a lot of as I'm sure you're acutely aware, there's
a lot of hype and doomerism going on right now with regards to AI.
There's a lot of I think maybe over inflammatory, uh, you know, doomerism
and over utopian hype going on. And in terms of, you know,
the different options that we have to develop these technologies in a responsible way. There seems to be one call for
government oversight. Which is interesting but comes with its lot of limitations. For example, governments are limited
to their jurisdictions And so, you know, you can't you can't coordinate an international community of research and development and R&D
merely through national regulation. So that's limited.
On on the other hand, you have, you know, markets and companies
that want to, you know, solve these issues in-house. They are maybe faster and more flexible.
But there is this necessity of, you know, how do you how do you constrain
the activities of corporations in such a way that we develop these technologies responsibly, ethically, transparently, in a manner that's
audible and that's, you know, acutely aware of and sensitive to the potential harms that might be caused by these technologies.
So what we are proposing is a kind of third path. A middle way not to say that we shouldn't pursue a private
development of these technologies and regulation. I think this is all, you know, a great idea.
There's some interesting legislation coming out of the EU. The AI Act that everyone is talking about that I think are
interesting paths forward. But to really consolidate the international community around these technologies, we have proposed a
standards based approach and the IEEE Group, where the standards
will be housed is an open group. Uh, folks from anywhere can join.
We have some pretty high profile corporate partners, but the idea is to build these technologies in a manner where we avoid silos
basically, and where we can kind of coordinate the entire world's
technological and intellectual prowess towards solving these issues.
So I think the and and yeah, there has been definitely, um, uh,
the threats of AI, the risk of AI have been quite, quite heavily, quite heavily discussed as I think with good reason listeners. Yeah.
Well and you know, I mean recently we had a show about this and I was pilloried, you know, quite a bit in the comments because
my, my role is devil's advocate. But I mean, I mean for me personally, I see the damage of of AI happening right now.
I mean, you know, when you have when you have kind of, um, let's say social media algorithms that have been highly engineered and optimized
and no use the transparency. In addition, it means the transparency of the models that we're using, right?
So, you know, one approach, one approach to training up AI systems might be, you know, give AI access to extremely curated
data sets so that it learns only the right things, you know, in
extremely like controlled settings. There's reason to think that that won't generalize easily. Another thing that you can do is
to equip your system with the capacity to form inferences about
its its own inferences and to evaluate itself with respect to,
you know, things that we value. So you could, for instance, design an AI that had an explicit notion of like discriminatory bias and then
train it to identify discriminatory bias in data sets, for example.
And you know, you can use active inference technologies to allow the system to access and report on its own inferences.
And it's even more general than than that, I think if I'm understanding correctly, because, for example, you have these nodes
right in this in this hyperspace. You have the you know, you have you have all these nodes in there and you can learn, for example,
Strength of Verses
that say a particular node is racist. You know, like it'll it'll give
you great answers to a particular question so long as it doesn't think you have certain, you know, demographic
characteristics or whatever. And then it gives you like, you know, bad answers, well then you can the network can
learn how to mitigate against that. It can learn how to compensate for the biases like inherent in nodes. So not just data in particular the
actual algorithms. Yeah, exactly. And you know, the algorithms that we're using are based on explicitly labeled generative models.
So these are systems that can be audited by third parties. Right, right, right. Because everything is labeled
explicitly, right? So like you can really calculate the incidence of this or that node on this or that part of the inference
and it gives you a kind of tractable, interpretable, you know, auditable
method of constructing systems such that you understand what went
into the decision making process. I said earlier that my suspicion, our
wager is that active inference will be to the 2020s what reinforcement learning was to the 20 tens. My my gut tells me that if
legislation the legislation that they are, you know writing up in the US and in the EU goes through it may be that active inference will be the
only set of technologies that we're allowed to use in the sense that,
you know, neural nets as they're used right now are black boxes.
Though not explicitly labeled and they are built to be black boxes like they are not built. They're not designed to be
interpretable. The the kind of, you know, these kind of privacy security issues, issues around confabulation,
issues around, you know, the the interpretability of these models. These are not like bugs in some sense.
They are features of the approach that we're using to design the systems. You're not using an explicitly
labeled model. There is no way to render this tractable post-hoc. Whereas if you start from an approach
that you know it's explainable, it does what it says on the tin. Then you get around these these these issues through your choice
of architecture in effect. So, you know, I think there's a, you know, tremendous ethical import to the manner in which
Misconceptions about FEP, Physics vs philosophy/criticism
we're designing these systems. We care a lot about ethics and versus as we discussed, my PhD, even though most of my publications
are in computational neuroscience and kind of theoretical biophysics, you might say like my PhD is in philosophy.
We have a lot of properly trained ethicists really at the core of this team and we take these things really seriously at verses.
So there's no accident here and I really think that active inference plus the standards based approach is how you're going to
get something like responsible, scalable ethical AI. Okay.
So and so far I'm on board with everything, everything I've heard. But I have a question for you, though, which is if it's all open
and and ethical and you're trying to do the right thing, how exactly is that profitable? Like what? You know, what's going to keep
the the lights on it versus. Well, so we have our own in-house implementation of ML So you know, we we are providing the
standards so that anyone can build a version of ML. We're providing the kind of core infrastructure for, you know, domain
registry and this kind of stuff. But we also have, you know,
a very advanced, highly engineered and developed versions of these things that can actually do things. So yeah, Okay. Yeah.
I mean you can think of, you know, Red Hat and the Linux Foundation as a kind of similar aspirational model, right?
So, you know, Red Hat do generate a profit from a commercial point of
view that Linux is still open source. The Linux Foundation is the open source custodian of the Linux operating system and yet they
are able to operate. Our contention is that our stack is organized in a similar manner where the spatial web Foundation
is the custodian of these open standards that we are, you know,
distributing, hoping everyone will widely adopt them and we
are the more kind of hard nosed, um, kind of architects who know
how to build things using these tools who for having built them, know how they they work. And you know, we are probably at this
point I mean almost certainly the world's premier active inference research and development group. So there's a whole powerhouse of
you know, well there's a lot of great academic papers that that
that come out of there. I mean, you know, I know Tim and I have enjoyed looking at, you know, quite a few of them.
Well, thank you. Yeah. Yeah. You mentioned Dalton, you know, earlier, I mean, you know, there's an example of some some
very refined and quite deep philosophically and mathematically, you know, papers. Right. Well, we have basically hoovered
up the kind of core luminaries of the active inference tradition
as it stands currently. I mean, Karl Friston himself is our chief scientist and is joining us in an increasing capacity
over the next few years. Yeah. So when you combine that with,
you know, I'm fairly well known in the field,
we have really scooped up like, you know, the Lance DaCosta, Connor Hynes, Brennan Klein, Mao Albarracin there's a the it's
it's it's pretty sometimes it's a little bit I guess the lunchables
must be must be interesting though right? Yeah absolutely. Yeah. And I mean this was this was my dream, you know, back back in
academia to have a central. Centralized research group with with all of this talent able to work together.
And yeah, we're definitely doing some interesting stuff and you know at verses we are committed to continuously also contributing
to the public domain and open scientific publication as you said,
you know we're we're a fairly productive research group.
We published a few dozen papers last year, for example, You know, so we I think there's a way of striking the balance between
contributing to an open community of developers and having an open core and this kind of thing on the one hand, and also being able
to continue existing as a profit generating entity on the other. But really the I think the key strategy is this open core, right?
So like have the standards open. Yeah. Make sure that everyone can contribute to it. Like, you know, there is a kind of selfish dimension to it as
well because then we are able to harness the entire power of the, the intellectual international community, uh, you know, to,
to build this stuff out. I think yeah, there there are, there are certainly some advantages. We also, for instance, maintain and
contribute to the Pi MVP package, which is a Python package for
partially observable Markov decision processes that power a lot of the active inference technology. So we use that as our core. Yeah.
And it's it's on an open license so anyone can just, you know,
download these packages, go to the GitHub and use it. So we're trying to build these technologies such that, you know,
everyone can start to use them. But we definitely have, you know,
some key differentiators and I think a pretty a pretty
unshakable oil market advantage. So so speaking of market advantage,
let me ask you about this question, which is as as you know,
we've had we've had Professor Friston on the show a couple of times. We've talked about the free energy principle a few times and there
seems to be a lot of what's the right way to say this, you know, misunderstanding or even negative press, if you will, not, you know,
around the free energy principle, right? Like like just kind of push back against it is either something of
of of trivial trivial interest or, you know, a tautology that's that's of no value. And we've talked about some of
this too in our in our intro. So like what, if any what do you think the biggest misconceptions are about the free energy
principle and or active inference that that really acts, you know, potentially just intellectual barriers to the adoption of the
technology And this is your paper, I believe is, you know, the map fallacy fallacy, right? Which is this this enduring kind of,
um, difficulty in understanding that a system can can follow these dynamics. Okay? It can it can it can behave as
if it can behave as if it has beliefs right about the world
and a model about the world. And it can behave in those ways. And it's okay to point that out like it's okay to say yes, this thing
is behaving as if it has beliefs. I'm not literally saying that it's like a conscious mind, you know, that has has beliefs.
What we're saying is that if it continues to exist, it must have have these behaviors so that it doesn't dissipate into equilibrium. Right.
You put your finger on the crux. Yeah. I think that's really maybe the most important confusion that people
have is they think of the free energy principle as some part of like philosophy or metaphysics, but it's not metaphysics,
it's just physics. It's physics, physics, it's mathematical physics in some sense. So, you know, this isn't really a
statement about the way that how things really are in some kind of
deep kind of philosophical sense. It's about how we can come to know
them given the kind of the kinds of modeling tools that we can deploy,
You know, so it there is a kind of deflationary aspect to the free
energy principle. Uh. Like it. It is a way of writing down canonical
models for the dynamics of systems that we find interesting given our state of knowledge about it. It's it's not it's not necessarily
going to tell you about the ultimate nature of mind or something like that unless you take a super deflationary approach and you think that physics
at the end of the day will be able to tell us everything we need to know about the mind. So yeah. What makes this do you think
that I'm. Yeah. The physicist in me wants to say yes.
The philosopher in me wants to say there are still a few issues that we need to sort out. Like, you know,
where does consciousness come from? But we're working on it again using the free energy principle. I think one of the things that makes
this difficult is that the free energy principle is ontological.
So it's about things, but it's not metaphysical in the
sense that it's not about like these fundamental philosophical principles that tell you about thingness. It is a it is a theory of everything
without being a theory of everything. Do you see what I mean? Right. Well, I think you hit upon this earlier,
which is I don't know if it's the only example, but as far as I know, it's the only one I know of an example that directly ties physics
to to inference or to, you know, belief updating like this.
This the first example of that that I know of. So like you just said, you know, it is it is a physics principle and
it just so happens to correspond to. Bayesian updating. That's right.
Absolutely. Yeah. Or approximate Bayesian variational stuff which is to say basically the same thing.
I'm being a bit cautious here because I don't for those of you
who are in our audience, follow me on Twitter, you'll know that I have to put it diplomatically. Some reservations about some of
the recent literature that's been published on the Free Energy Principle. I think a lot of the issues with the literature is sociological. It's you know,
and it's difficult to talk about this without seeming like, you know,
a bit like deprecating or negative. But like a lot of this work was
written, especially the critical work was written by early career researchers who did not necessarily have the formal familiarity with
the free energy principle that might have been required. So I mean, look, for example, I, I heard a lot, you know,
circa 2017, 2018, 2019, you know, people say, well, you know,
the free energy principle can't be true because some systems maximize their entropy, right? They move towards more entropic
states. Now from the from the perspective of our conversation, that might seem nonsensical because we've
just spent like, you know, about an hour and a half talking about how the free energy principle is a way to write down maximum entropy.
But yeah, the free energy principle says something very specific, right? It says that if I maximize the entropy of my beliefs,
then I can keep the thermodynamic entropy of my physical states at bay. But these kind of sophisticated kind of hinge statements are not
necessarily fully appreciated. So it can lead some people to just say false things about the free energy principle.
Well, you just you just made another statement that I don't I don't know that it's hinge but it requires paying careful attention.
You said something to the effect of, you know, the free energy principle is a theory of all things, but it's not a theory of everything.
That's right. And and I think and the way I interpreted you there was to say that like the free energy
principle applies to all things, but it doesn't necessarily tell you everything about all things. That's right. Right.
Is that is that what you meant? Yeah. And you know, like I think that there
are some states of affairs that are just not that are not directly free
energy principle adjacent. Sure. So I still don't know why, you know, the so-called hard problem of consciousness. Right.
Why does Red feel like red? Why does a middle C sound like a
middle C? But it also seems to act as a kind of lightning rod that attracts, you know, multidisciplinary criticism.
Let's let's say it that that way. And in fact, you know, so we we over the course of kind of studying up on the free energy principle,
you know we've we've read critiques right of the of it you know so for example those by Biel and others and and I'm wondering like what you think
about the criticisms of it you know, do you do you find validity in them? Do you find do you find the quality of the criticisms to be good has
has just moved on from it? Like what's what's kind of the state of the art, if you will, of of criticism of the of the FEP?
Well, the first thing to say is that we appreciate the critical engagement that the free energy principle has received.
And you know, like any good scientific framework, it stands to benefit from serious adversarial engagement.
I think the quality of criticisms varies quite widely in the literature. So to take the example of,
you know, Beal and colleagues, the I think the paper you're referring to is a technical critique of some parts of the free
energy principle. Yeah, yeah. It was a very, I think important paper when it came out. It pointed out some of the
inconsistencies in the way that the Free Energy Principle had been formalized circa 2012, 2013 or so. And I mean since then the mathematics
has been corrected and I think we've moved beyond the criticism.
I have this directly from Martin Beal himself. He says, You know, my paper the lesson to draw from
this paper is that you should incite Friston's 2013 paper life as we know
it to make claims about the free energy principle which is fair. On the flip side, I would say that we have moved
beyond the formulation as it was as it stood in 2013. One thing.
To keep in mind is that so the is sort of like brain physics or mind physics depending on how you want to think about it.
And physics and mathematics have a strange relationship that I think is important to think about. So the history of, you know,
developments in physics often goes as follows A physicist,
you know, borrows some tools from mathematicians more or less,
you know, rigorously applies the tool to explain a bunch of interesting phenomena, but then that leaves mathematicians wanting.
So for example, you know, the Dirac Delta function was introduced in the context of quantum mechanics and the delta function
is this weird probability function that concentrates all of the probability mass under one outcome. So you got like basically a
Emergence / consciousness
probability of one for one outcome and then zero everywhere else. When Dirac introduced this measure into the literature,
statisticians were not pleased. It just didn't seem to them to be a well behaved object. And it took a couple of decades of
work in mathematics and statistics to make sense of and kind of tame,
you know, the Dirac measure. And yeah, you often get this you
can think of a lot of the history of recent theoretical physics as this kind of back and forth between like sloppy mathematical physics
that gets then tightened by some rigorous mathematical work. And I think, you know, we're in a kind of similar back and
forth here where, you know, the was effectively developed as a kind
of brain physics or math physics. And what we are witnessing now is an attempt to rederive all of the core theorems in terms of more
well-established mathematics and effectively recapturing all of the
core intuitions, but within a kind of mathematical receptacle that,
you know, passes the mathematical smell test as it were.
But you know what's interesting too, about the the Dirac Delta function and correct me if I'm wrong here, but I think I don't know if it was
the first, but it definitely helped to push along what later became known as generalized functions. Right? So so to at least spurred some
significant, you know, work and research in mathematics, right? Oh, absolutely. And the is similar in that, you know,
we're now working out, you know, some some cool stuff having to do with, you know, generalized coordinates and things like maximum
caliber which are which is like maximum entropy but over paths. And all of this investigation is in effect opened up by the free energy
principle and by the can of worms. So I've never heard I've never
heard of maximum caliber. But let me see if I can guess what that is. So if you have paths going through, you know, some state space, I guess it's like the the, you know,
the the cross section, the cross sectional area of the paths that they traverse or what it's more like, um, well, it's similar to that.
But what you're basically doing is you're considering the entropy
not of individual states but of entire paths throughout the system.
So it's it's actually the entropy of the whole path. Okay.
And so yeah, it's an extension of, you know, jaynes's principle of
maximum entropy, but in such a way that we can talk
about like the counterfactual histories of the system that is like all of the different paths that it can take through its state
space in terms of their entropy. And then the principle of maximum caliber is that the real path is the one that maximizes entropy.
So it's not just about finding yourself in a in a low entropy configuration. It's about finding yourself along a
path that has the lowest entropy. Yeah. And this turns out to be important because the the free energy
principle evinces all of these interesting dualities to the
space that Jaynes is describing. So in the literature there are
roughly speaking, two main families of application of the free energy principle, the so-called density dynamics formulation and the path
based or path integral formulation. In the density Dynamics formulation,
what you're considering is states and how surprising those states are per se. So when you're trying to talk
about that, what you do is you appeal to this construct called a generative model. And the generative model is basically
a joint probability density. And what it describes is the relations of dependance between the variables in the flow or
dynamics of a system. And so in the density dynamics formulation, what what the surprise is about, like I was saying,
is how implausible is some configuration of states of a system.
So this is different from the from the path based formulation.
In the path based formulation, you're considering the trajectories of system over time and given the kind of thing that you are, for example,
then you're going to have an inertial path through your system just given the kind of thing that you are. You know,
I'm the kind of thing that wakes up at 6 a.m. and has some coffee and then gets progressively more tired and then goes to bed at like
9 or 10 and then you know me so well. So if you're that kind of thing,
then there is a characteristic or inertial path that you'll take. And in the path integral formulation, the surprisal scores the
deviation from the inertial path. So yeah, these are slightly different
objects and you can think about dualizing these to an entropy context
where you know in the density dynamics formulation you would be talking about the entropy of states or configuration of states
or indeed of the beliefs encoded by those states or the entropy of
entire paths. So this caliber notion. But yeah, all of these are kind of
joined up and as I'm sure we'll discuss a bit later. Yeah. Yeah.
The yeah, the free energy principle turns out to be a way of writing down the principle of of maximum entropy. Yeah.
So all these things are really like, deeply connected, I would say. Now, you know, previously I kind of prodded you about whether or not the
physics could explain consciousness. And you said the physicist in you was really, really, you know, leaning towards hoping it hoping it could.
So I want to take this chance while we have you to ask you about one of our favorite perennial topics on the show here,
which is emergence, you know, weak emergence, strong emergence. Now, you know, there's there's different ways of looking at it,
different definitions of it. I think what I want to ask you, though, is that there are clearly certain behaviors, right,
that are best modeled and talked about and described mathematically at
these higher levels of of abstraction like thermodynamics. Okay. I mean, you know, there are these bizarre kind of properties of,
you know, entropy and temperature and free energy not somewhat related to the free energy we've been talking about that you can that you can
develop these equations on right? The first law, second law, third law of thermodynamics. And they apply to these kind of
bulk systems Now like in principle. In principle. And that's really the the key word there, which is in principle,
if you could write down all the, you know, details, excruciating details of every particle and solve, you know,
wave equations and kind of massive, massive dimensions, you may be able to formulate those laws. Right. And predict the emergence of
those laws. But the fact is nobody ever has like they they they don't do that. We can't do that.
And and there's even the possibility that in mathematics, like mathematically these effective theories, right,
where you try to do that, you try to write down all the particles, calculate integrals and averages. They can sometimes end up with
these singularities where you can't cross that divide. So I guess my question to you is, is this which is that and if you
couldn't cross the divide, that would be a strongly emergent phenomenon versus a weakly emergent one where you could mathematically cross write.
So I'm just curious if you think, first of all, if you think there's such a thing as strongly emergent phenomenon or if we're
always be able to cross that mathematical divide, if you will. And then secondly, even if we could, is there really any point or is it
better just to develop, you know, descriptions at different levels and and just be happy with that at the end of the day?
That's a really great insightful question. I would be inclined to say that the free energy principle gives
you a kind of heuristic or map to tame weak emergence.
So maybe we could start there for a second. So the free energy principle applies in a kind of multi-scale manner to
things composed of things composed of things, and the kind of key insight
that you get from the study of ensemble dynamics in the Free Energy
Principle is that things can engage in emergent behavior provided that
they have a shared generative model. So if if you and I kind of encode
the same dependency structures, then we are going to react in
characteristically coherent ways to whatever we're experiencing
and therefore we will end up coordinated even if we're not directly communicating. So there is a story that you can
tell and I know you've had Mike Levin on the call here on the show
here a few times. Yeah, Yeah. He's he's absolutely amazing. So the this kind of like. Yeah. Ensemble behavior that Mike is
interested in explaining has to do with the emergence of a shared generative model. So this again it's the same core
story. You know, you have things interacting over time and the says that if there are boundaries in the system
between things, then they will track each other across the boundaries. Right? So this means. That over time things end up
sharing a generative model and can then begin to display. Coordinated shared patterns of behavior.
So I think that's really key. The you know, and we discussed
Aristotle a bit earlier. This is again removing degrees of freedom from the parts, right? If you and I are aligned on what
this or that means, it means that we're aligned on what this or that doesn't mean. So we are, you know,
coordinating by becoming models of each other, becoming good predictors of each other, kind of sparsifying the set of things
that we expect each other to do. And over time we can arrive at some form of like, you know, coordinated behavior.
And I think the the contention. Is that this explains
biophysical emergence at every scale where we observe it.
So there's an argument to be made that really this is. Really a theory, like a formal theory of well, I mean, the itself
is not a theory, as we discussed. It's a principle, but it's a formal approach to that begins to give you a grip on how to model nested systems
of systems, of systems of systems. The cool thing is that the whole stack operates on the same quantity basically.
So you have one objective function. It's the same pattern at every scale. It's the Markov blanket that repeats and it's this free
energy minimization behavior. Um, you know, and so that's,
I think, powerful. You know, the Segway is one of the applications of the free energy principle at verses is to design
systems that are able to perform inference at different scales using the same objective function. So the variational free energy.
And if you introduce this time scale separation into the mix, then you
know at the bottom of the stack you have state inference, right? So I have hypotheses about what might be causing my data.
I am generating data through my actions and I end up selecting the hypothesis that accords the best with the data that I'm generating.
But you can do your parameter learning using exactly the same architecture just on a slower time scale, right?
So you accumulate counts of state estimation and then over time you're able to, you know, estimate what the best configuration and value of
your parameters are for your model. And then similarly, you could do the exact same exercise at the level of the entire model structure.
And then, you know, that's where you get into the natural selection story that the free energy principle brings to the table.
I embody a model in my existence. I am kind of generating evidence
for that model. Good models persist and leave copies of themselves. Bad models are destroyed and
dissipate. So you can really tell a kind of, I think, powerful multi-scale story. Um, so yeah, I would say like there's
not much that remains in the weak emergence stuff that you can't, you know, address in a tractable manner using this kind of approach.
Your other question about strong emergence is a bit more vexed. Um, you know, thinking about this, I think the only thing that might
really be strongly emergent is our conscious experience. And there are reasons to think that that actually isn't
strongly emergent but just weakly emergent in particular. Are you familiar with Andy Clark's notion of Bayesian qualia?
Uh, not. Not quite. What is it? It's very cool. He he calls this the meta hard problem. Oh, okay. Yeah.
And what Andy is basically saying is that, well, what we experience
as qualitative sensations are just further inferences, namely inferences that I am feeling this. Right, right. Well, that's that's very similar.
You know, I really liked Professor Friston's take on this and I'm blanking on on the on the article where he described this.
But but he said that, you know, when you when you're doing this free energy principle and you're doing this this inference once you're
once your inference has reached a sufficient temporal depth and counterfactual depth, if you will, then that's when consciousness can
emerge because it can start to model itself on its own internal states and you know, this sort of thing. I think it makes a lot of sense.
Absolutely. Yeah. Yeah. Well, you know, you're you're preaching to the choir here. Obviously, I find that kind of explanation extremely compelling. Yeah.
And so, you know, we also have some interesting, in my view, work on consciousness that we have, you know, in a free energy
principle adjacent kind of area I've been putting out for, you know, nearly two decades. But more recently we've been
looking at the question whether you can derive a theory of consciousness directly from the free energy principle.
And so we believe that we can. And the idea there is that consciousness corresponds to something like an inner Markov
blanket, so an inner screen. So to back up just a little bit.
Uh oh. Uh oh. You said inner screen. Now people are going to think of the homunculus. Well, so that's why I want to
qualify this carefully. You can think of any Markov blanket as a screen of sorts. So it is a screen.
And you mean a screen in like a mathematical sense? Yeah, exactly. Like in the sense of the holographic principle in physics, Right?
So the holographic principle is a principle that originated in black hole thermodynamics and it relates to our ability to encode
information within a system. And what it basically says is that you can, from the perspective of an outside observer,
a given system can only contain as much observable information as you can fit onto its boundary. The reason being that if that if
that bulk collapsed into a black hole and there were more information than that, then you classical information would be destroyed
in the process. Yeah, exactly. And you would violate basically the principle of unitarity in quantum mechanics. So.
Uh, I you know, I mentioned this quantum information theoretic formulation of the free energy principle that I said I wouldn't
get into, but it's probably worth getting into for like two minutes. So according to this formulation, you can think of the Markov blanket
as a kind of holographic screen that separates the inside of the
system from its environment. And it's a slightly more kind of computational take on what we've been talking about.
So, uh, you know, the active and sensory states of the Markov blanket would correspond to reading and writing onto the screen
or a measurement and preparation operations in a kind of quantum mechanics perspective. Okay. So the interesting thing about
the Markov blanket in this formulation is that by definition,
because it is constructed or contains all of the degrees of
freedom that a couple, you know, systems across the boundary all
of the classical information that you need to describe the coupling lives on the boundary in some. So Chris Fields about three years
ago, along with Mike Levin and Jim Glazebrook, proposed that well,
maybe the core architectural feature of systems that have consciousness
is an internal Markov blanket. The idea being that the classical information that I use and bring to bear in parsing my perceptual
streams and deciding how to act has to live somewhere. And so the idea is probably lives in this kind of internal
screen or Markov blanket. Interestingly, there's a way of just taking this stuff that we were saying about levels in the brain and just
directly translating that into the Markov blanket talk between any two levels of brain architecture. There is a Markov blanket by
definition whereby these messages are being passed. So you can basically according to the model that we're proposing.
So you have an external Markov blanket, right? That separates the the internal the inside of the organism from
its outside. And then if you look at these internal states, they have this structure of a nested hologram in
some sense, right, where like you have a series of screens that are successively coarse graining each other and that are therefore kind
of resonating with each other. And so there's a whole story that you can tell about. Yeah, the the emergence of something
like Yeah, consciousness just directly by appealing to the free
energy principle, the kind of key to this architecture is that at the very top of this nested hierarchy there is a right only layer that
doesn't get further contextualized from by anything else, right? And so there's a sense in which that layer is constrained to write down
and can only kind of infer itself into existence vicariously by acting
on the other layers of the network. And so the idea then is that this is where the kind of well, this is how you resolve the homunculus paradox,
first of all is that there is a layer that is not observing itself. It just exists to observe right? Layers below. Yeah.
And so yeah, we have a new paper that was just published in a series of 2 or 3 papers that were articulating. So I say this because like I think
if if anything is a candidate for strong emergence, the only really serious one is consciousness. And the absolutely utopian,
overconfident. Part of me thinks that by combining
some of the philosophical work that, say, Andy Clarke has done around Bayesian Qualia with these computational architectures for
conscious systems that were developing based on the free energy principle somewhere in the vicinity of this, if you if you you know,
if you look at it for long enough, there'll be something that'll emerge to resolve this issue. So well, I guess David Chalmers
will at least be happy that you've identified consciousness as the only if there is something strongly emergent, it's only consciousness.
So I can't think of anything else, frankly. And I mean.
The consciousness may ultimately be inexplicable, but it also may not.
And so, you know, I'm an optimist until I'm proven wrong.
And we're going to keep working on this. I think, you know, what we're proposing is just the very kind of basics of a sketch of what a mechanism for the generation
of consciousness might look like. We're very, very, very, very far from a comprehensive question. But yeah, so we can think about.
Oh yeah, go ahead. Well let's say we weak emergence. Definitely a cool idea. I think the gives you some tools
to handle that strong emergence. I'm not sure like if anything is
it's definitely consciousness, but maybe not. Okay, Well, fair enough.
And you know, I was going to say, what's funny about the free energy principle is it's this onion that just keeps on giving.
You can just keep pulling back more and more layers. And I think we probably have, I don't know, maybe centuries of
mathematics, you know, inspired by it, most likely.
Well, I mean, I think I think it is one of the singular most important discoveries like of the last maybe 200 years.
Like I think, you know, the you've had long discussions with Carl, so. Yeah, yeah, yeah. I mean, I think this is like, you
know, the this is physics of mind. You know, we are we are I think
this is the same, you know, to bring it back to mechanics. Um, so Galileo basically destroyed. Uh, you know,
it's the Galilean moment, right? But like, Galileo destroys thousands of years of philosophy inherited from the Greeks. Right?
The Greeks thought that there were basically two kinds of stuff. There was the sublunar stuff and the super lunar stuff.
And then the Sublunar stuff was governed according to these four elements where, you know, like a things that that were earth
fell down and things that were fire rose and stuff like that, right. And the super lunar was all about like eternal, perfect circular,
cyclical circular motions of like planets and so on. Right? And you know, you can if you were around at 400
BC and you looked up into the sky, it really would look as if there were two different kinds of things two utterly distinct, you know,
the the stuff around me, you know, rocks fall to the ground and smoke
rises and water is cold and so on. And the stuff out there that just
moves in perfect eternal spirals and so on. What what Newton and Galileo.
But I mean maybe in particular Newton end up doing is to say, well no, actually it's all one kind of stuff like it's all, you know,
subject to the same fundamental laws. It's classical mechanics and the
Newtonian kind of Galilean Newtonian moment is sort of like the split where like, you know, the old way of thinking. Yeah.
Started to show signs of being incomplete and a new alternative arose. So it kind of unifies all of
reality under the auspices of classical mechanics. And I think the same kind of thing is at play here where, you know,
we used to think that there was physics and then there was biology or maybe, you know, there's information theory. Yeah, exactly.
Or maybe there's like physics and biology and then there's the mind.
What the is ultimately telling us and you've heard this, you know, from from Mike and Carl before, I'm sure is that there really
isn't a distinction to make here. Like it's all just, you know,
physics in some sense. And biology is just slow physics and psychology is just even slower. Physics and culture is just even
slower physics. And so yeah, I think we have the same kind of like radical quantum leap in the way that we, you know,
are able to think about the world that opens up with the free energy principle, especially when you combine this to like the philosophy
of sparseness and emptiness that I was referring to a bit earlier. Like I think what emerges out of this is like a real powerful
constellation to to think about the way that intelligence is expressed in physical systems. And that's also why versus has
adopted the approach like here is finally we have the physics of intelligence. So let's let's build our AI
systems on these bases. I mean, it hits exactly the phrase that you said that so impactful and meaningful,
which is the whole is not greater than the sum of the parts. Exactly. It's radically less than the sum of the parts. It's beautiful.
Well, listen, Maxwell, it has been absolutely a pleasure to have you on. So thank you so much for taking the time to join us and and talk.
And you know, I hope you come back on again. It seems like there's so much to discuss. I'd love to.
And you know, I am a long standing fan of your podcast, so this was Oh, thank you so much. No, it really genuinely this was
a pleasure and also an honor. So thank you very much for having me.
This discussion was extremely exciting and fun and yeah, let's do this again sometime. I'd love to come back. Absolutely.
And best of luck at versus I'm supportive of what you're doing there. Very glad to hear it.