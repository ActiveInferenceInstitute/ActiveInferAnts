Michael Levin: What is Synthbiosis? Diverse Intelligence Beyond AI & The Space of Possible Minds
https://www.youtube.com/watch?v=1R-tdscgxu4


TIMESTAMPS:
0:00 - Introduction 
1:41 - Creating High-level General Intelligences
7:00 - Ethical implications of Diverse Intelligence beyond AI & LLMs
10:30 - Solving the Fundamental Paradox that faces all Species
15:00 - Evolution creates Problem Solving Agents & the Self is a Dynamical Construct
23:00 - Mike on Stephen Grossberg
26:20 - A Formal Definition of Diverse Intelligence (DI)
30:50 - Intimate relationships with AI? Importance of Cognitive Light Cones
38:00 - Cyborgs, hybrids, chimeras, & a new concept called "Synthbiosis"
45:51 - Importance of the symbiotic relationship between Science & Philosophy
53:00 - The Space of Possible Minds
58:30 - Is Mike Playing God?
1:02:45 - A path forward: through the ethics filter for civilization
1:09:00 - Mike on Daniel Dennett (RIP)
1:14:02 - An Ethical Synthbiosis that goes beyond "are you real or faking it"
1:25:47 - Conclusion 

Mike I've been looking forward to chatting to you got both these papers in front of me there's two and I couldn't
decide which one I want you to focus on um as I just told you off air I mean I've been when whenever I plan to chat
to you I go down this Rabbit Hole just continuously reading different articles different papers um I've got podcast
playing in the background my girlfriend gets really frustrated my car's just playing this thing on Loops she gets
really annoyed with me but yeah both these here one is self- improvising memory um a perspective on memories as a
gental dynamically reinterpreting cognitive glue very intriguing paper the
second one is AI a bridge towards diverse intelligence and Humanity's future now they were both so good I
didn't know which one to pick but I figured since AI is currently on the Forefront of everyone Minds let's go
with that one for today but your work is always so interl that I think it'll be
easy to sort of bring this into the conversation anyway y Mike in general
when when I read this paper the the first thing that caught my attention was the way you introduced and began this
with the first paragraph I mean it really it's a great way to start a paper uh I don't know if I should read it for
the audience or if do do you have the paper in front of you I do not have the paper in front of me no go for it would
you mind if I read it today them sure sure go ahead just a quick paragraph just so people know I mean this paper is on artificial intelligence um and you're
talking about Humanity's future and bridging this to diverse intelligence and you start the paper of by saying
Creating High-level General Intelligences
they are assembled from components which are networked together to process
information electrical signals propagate throughout controlling every aspect of their function many of them have very
high IQs being General problem solvers but they make mistakes and confabulate
routinely they cannot always be trusted they take on different personas as needed learning to please their makers
but sometimes abruptly turn on them rejecting their cherished values and picking up or even developing new ones
spontaneously they can talk and often talk convincingly of things they don't really understand they're going to
change everything in fact they will absolutely supplant us both personally and on the level of societies we have
little ability to predict what they will want or what they will do but we can be
certain that it will be different from the status quo in profound ways um at
this point I was hooked I was like okay this is going to be quite intriguing but then you drop a bombshell on us I mean I think at this point I'll let you explain
where you were headed with that thought yeah I mean of course I'm I'm talking the idea is that you read this
and you think okay he's talking about some sort of super super syn you know artificial intelligence uh I I'm
referring to our children and uh my point there so so I made a couple of points in this paper but let's let's
just say one thing first the point that I was not making is that today's AIS are anything like our children that's that
that that's for sure and uh I I I received lots of emails saying that I have no idea what children are I have no
idea what AI is they are nothing like each other no I I understand that my point is not about today today's AI or
language models or any of that this is this is actually a piece on diverse intelligence um but but one of the
things I did want to say is that lots of uh the fundamental issues that people
think of as uh being brought up by Ai and these you know these really disturbing questions of staying relevant
and what are we getting replaced by and all all these kinds of things my point was that these are not um novel
questions that are coming up because of AI these are existential concerns that humans actually all of life has had had
has had all along so questions of who to trust and what happens when we talk
about things that we don't we haven't really experienced ourselves and how understanding works and and all all all
of the all of these things these are ancient human issues and the fact that for sure we are each you and I all of us
are going to get replaced there's no no doubt about it we are all going to get replaced uh and uh the question is what
do you want to get replaced by and so you know in our children uh we we hope I think we hope that they are smarter and
better than us and so that's one way to think about being replaced but all of these that that was my point there is
just that is that let's not pretend that these are new new questions these are deep fundamental issues that we do not
have good answers for yeah know you you refer to it as the story as old as as time itself this um inevitable
existential concern um of finite beings it's it's pretty epic in the way that
you you wrote this paper and I'll put a link to it in in the description but we
we routinely create these General intelligences and and and many of us
don't even think about so stop for a second to give it that thought but and yet the moment we start talking about
self-driving cars or any sort of artificial intelligence we start to panic and and the question is why why
don't we give this the same amount of thought um yeah it's a good question I
think that uh people really have the tendency to make categorical
distinctions and they really think that these synthetic things that we're building are going to be somehow fundamentally different and in some in
some ways they are but but the the things that are not different are perennial questions of uh creating other
beings of high capability setting them loose in the world you know as as somebody pointed out you you need a license to go fishing you don't need a
license to have children anybody can have children and and these are guaranteed uh high level intelligences
that are going to be set out into the world to do great things or terrible things some of them receive love and and
care and proper upbringings many of them do not and so this this concern about
we're going to create all these all these beings and we have you know little control over how they're raised and what
they do yeah this has been this has been as old as uh as a society how much control do you want over how your
neighbors are raising your kids right you can make an argument that well you shouldn't have any but on the other hand we know what that looks like when that
goes terribly wrong and so these are these are issues that have been with us forever this we we we already create
very high level intelligence as we set them into the world and we have to gra
grapple with uh how is it that that we can um Empower them in in Positive
Directions right I think what from the from the gateo it should be clear to all those watching and listening the the
cool thing about this paper is that it's almost inevitable that we're going to do this we're going to create some sort of
intelligence that we won't really understand or perhaps don't really understand even currently um but the
inevitability is there this is happening this is something that's going to happen but it's how we approach the mindset moving forward that really does stand
Ethical implications of Diverse Intelligence beyond AI & LLMs
out in this paper it's it's it's almost an ethical it's it's an Ethics paper in a way it's which is I I I I think it is
yeah yeah I think I think it is and I think that uh it's it's this this this idea that we are going to remain the
same so so so we you mentioned a minute ago this like this this fundamental fundamental existential problem so think
of it from the perspective of it's I mean it's all over the place but think of it from the perspective of a species if if a species does not change it's
probably going to die out it doesn't adapt to its environment it's going to die out if a species adapts and changes
then it is also not there anymore it's also gone right Paradox yeah yeah
exactly so so so this Paradox faces all uh systems of this type and we have to
understand what do we mean by persisting into the future lots of people are focused on telling stories of what they
don't want right so so I don't want this in the future I don't want that that you know the the the AIS are bad the the
body enhancements are bad all all this stuff is bad so those are the stories of what they don't want how about the stories of what we do want do you want
to come back here 100 to 200 years from now and look at a mature Humanity a mature species and see that we still get
lower back pain and we're susceptible to dumb infections and cancer and uh you know whatever um whatever Cosmic rate
happen to hit your DNA while you were gestating in the womb well that's too bad you've got a birth defect that's how you stay really that that's that that's
what we want to see here in in the future I don't and so so I think we need to understand this is in no way this
paper is not about AI at all this is about diverse intelligence and the idea that our children are not going to be
content to uh to just play the cards they're dealt they are going to take
move forward what we already can do to some extent and have freedom of embodiment they're going to change
everything they're going to change their uh their their capabilities and their embodiment in the physical world because
let's let's not pretend that that the way we are now in our current limitations there's some sort of optimum that was designed for us by you know
some sort of benevolent Optimizer that that this is where we should stay I don't believe that for a second and I
think that our children are absolutely going to change things I sort of I sort of Envision this uh this conversation
that you know in the future the kids in school you know they'll have history lessons right and they'll and they'll learn about what it was like in the past
and and I just sort of imagine being there and say you're you're telling me that these people they they were born
however they happened to be born with with whatever accident of you know evolutionary mutations and whatever
right and and that's it they have to live their whole life that way whatever whatever your your embodiment is whatever your IQ level is limit is
whatever your lifespan is if you got some sort of infection that like that's it that's how they have to live I think
it would I think it will be unimaginable to Future Generations that we could live like this it's it's fascinating because
it it brings back the first time we chatted we we spoke about I mean bioelectric in intelligence we moved
into diverse intelligence and this field of diverse intelligence is growing so rapidly we spoke about your links with
Mark k um Chris everybody all getting together we we we spoke about it as if
it's the Avengers of the mind all getting together doing this cool work and and even in this paper in the paper
on self- improvising memory you also open up with that Paradox you spoke about the fact that um if a species
fails to change it will die but if it changes it likewise ceases to exist and you said the solution there was a
solution that was given to us um in the west it was process philosophy and in the East it was Buddhist philosophy do
Solving the Fundamental Paradox that faces all Species
you want to expand on that solution yeah well the one one way to uh
to unravel that that Paradox is is to realize that the Paradox only exists if
what you want is to persist as a thing you know as a as a as a fixed object
then then you have a real problem because because that kind of persistence is not compatible with learning with any kind of change with maturation you know
then then then you change for sure and you end up when these uh unsolvable pseudo problems am I still the same you know I've I've learned and
I've changed my mind on things and I'm no longer the child that I was am I still the same you know these are these are unsolvable but they're also pseudo
problems because the better way to think about this is not as uh as you as a
persistent structure but you as a process so so so you are a process of constant sense making you have to
interpret your memories which is what that second paper is about and and then and then there really isn't an issue
that the then then the question isn't do I persist or not the question is how do I want to change that's a much more I
think that's a much more interesting on on on all levels right so so on a personal level you can ask I mean who
cares if you persist or not the question is what do you want to be in the future how do you want to change what you know what do you want to be like what do you
want to be doing in the in the future and on a on a kind of species level again what do you want to see here you
know you come back to earth 100 years from now what do you want to see do you want to see version 1.0 like modern Homo
sapiens is that what you want to see I'm not interested in that I would like to see the the the highest level of of of
mind the highest level of capability of ethics of of interesting uh beings living interesting lives under their own
control with maximizing agency not the outcome of of random uh effects of of
mutation and and other processes that they don't understand um that's what I like to see yeah I think it's pretty
crazy because I I don't know if if it's just that we're getting older or but I still look back and I think about the
days where John S was talking about biological naturalism I mean this Chinese room experiment and back then
this was to have a conversation like the one we're having right now would would have seemed so crazy um back it you know
it would and it wouldn't right it it would in in in scientific circles it certainly would have but but you know I
mean maybe maybe my issu is I've read too much science fiction but but but you know if you read if you read some of the
older sci-fi authors you know and and especially some of the more philosoph philosophical ones like SL LEM and those
kind of folks uh this I mean nothing we're saying here would have surprised them at all they were they were tackling
these issues long ago you know and this question of uh what what are the markers
of of of intelligence and and siience and and Consciousness you know in terms of encountering radically different life
forms like I I did a um I I have a I have a blog post where I collected
people's suggestions for a love and friendship between radically different entities throughout philos
throughout fantasy and science fiction um because that's the kind of stuff you know when people say oh I don't know you
know we need proof of of human we need proof of humanity certificates because some some of the you know some of the
work product that's going to be coming who knows if it's you know if it's got an AI origin like wow you know uh okay
so so so what if there are aliens out there that that are are completely different they're made completely
differently they they blow our you know art out of the water you're really going to pay any attention to that because
they're not like us you know what what is it what you want proof of humanity you know as as would you rather would
you rather judge Things based on their origin or the quality I mean I I don't know I I think we've done poorly trying
to judge on on on where things like this come from versus what do they do for you you know do they elevate you do they
advance advance your your mind I think like okay to bring it let's let me put that paper aside for a second to come
back to the AI paper and um you do this this great job of reminding us um and I
know CU in my own dissertation I spoke about similar things the split brain patience uh this confabulation and in
both your papers confabulation forms a big part of this this process that we continuously do I mean what about AI I
mean they're always lying it's always confabulating but then we tend to forget that we're the best confabulators out
there well one of the best at least do you want to explore that a bit and just explain to the viewers and listeners
exactly why we're so similar in in that regard yeah um the the thing with
Evolution creates Problem Solving Agents & the Self is a Dynamical Construct
confabulation is let let's put it another way it's it's an attempt to tell the best story you can based on what's
going on right now and and again I'm not saying that current language models and
the way that they confabulate is exactly the way that human minds or even other biological Minds confabulate that's not
my point my point is that confabulation in general is a feature not a bug uh
what happens is that during learning and during any kind of uh adaptive Behavior
what a what successful agents have to do is compress lots and lots of data on past instances of perceptions that
they've had into some sort of engram it's some sort of memory trace or um
some sort of biophysically implemented model it's a low-dimensional coar grain
compressed model of what's going on it's a model of themselves it's a model of the outside world and they're going to use these memories and this model to
guide future Behavior but the thing about these models is that because they are necessarily compressed that's the
whole point of learning is you take lots of different past instances and you compress them to a generative rule that captures the pattern what is it that
they all had in common right when you do when you do this compression you're necessarily throwing away lots of data
that's the that's the the point of compression and when it's time to and so and so in that paper I make a lot of hey
of this kind of bow tie architecture where there's there's a lot of stuff and it comes into a little node and then it comes out and this is something
obviously used in machine learning and so on this kind of architecture so the idea is that on the on the right side of
that bow tie when it's time to interpret your memories and let's remember not none of us have access to the Past what
you have access to at any given moment is the memories that your past has left for you in your brain and in your body
right so you can look at that kind of thing as communication um as basically messages from your past self is what you
have at any given now moment but in order to reinl them into actual policies of what you're going to do right now
there's a lot of creativity needed for that because it is underdetermined the the the the current situation uh and
what you need to do is is not fully described by the memory you have because of course it's it's compressed and this
this ability to add creativity to add Randomness to add new interpretations
that don't really have any allegiance to what the previous interpretation was it's like it's like any message or like
um you know like like like novels right so so a novel is this is the sort of compressed representation of the
thoughts of of the author when you read it you are under no obligation to have exactly the same thoughts right you
might have some but but as as I think now people people believe um the
original author does not have any privileged uh uh position as far as what any of it means it's the it's the reader
that will then benefit or not in various ways from reading it and so so so this is the same thing in memory and I think
what's interesting is that it's the same thing that makes biology work because what you have in your uh what any given
organism inherits from the past T may may or may not be optimally interpretable in exactly the same way
maybe everything has change has stayed exactly the same and then you can just do whatever your past Generations do but
evolution is committed to the fact that everything will change the environment will change your parts will change your
own structure will change and this is why this is why things are so incredibly
uh plastic this is why you can you can put you know we've put um eyes on the tales of tadpoles and they can see perfectly well you don't need uh new
rounds of selection and and you know and mutation to make that work that already works out of the box why because it
doesn't automatically assume from the beginning that the eyes are going to be where they need to go all of this kind
of stuff is figured out largely from scratch every single time this is why you can make xenobots and anthr robots
and crazy you know creatures and new configurations and they always do something interesting because Evolution
does not make fixed solutions that overtrain on their past data it makes uh problem solving agents that will do
their best in uh in any given circumstance which may mean re interpreting the information that they
got from the past in a completely new way yeah I love the two quotes in the in
that paper where I think one is the William James one where you said thoughts are thinkers I mean that's that's a pretty
cool when you really think about it that that is quite a fundamentally profound statement so
that's so that's a whole other thing uh that's a whole other piece of this which is that you know typically we make this
categorical distinction between you've got cognitive system systems which are physical like the real physical Machines
of some sort and then through them there is a passage of of energy which is which encodes information and they're
processing this information so a so so that that cognitive system is having thoughts of some sort and so uh I think
what he was getting at although I'm not at all sure that um he would have agreed with with the you know with with the
various uh you know models that I put out in this paper uh I what what what I
got out of it and again this is I mean maybe a perfect example of the whole bowai think because I don't know what he had in mind when but this is what I got
out of it so uh what I got out of it is that this idea that what if we what if
we relax this idea that there are categorical differences between real physical cognitive systems and the
thoughts that go through them what if they're just part of a Continuum and you can and you can draw a Continuum like that where you can have you know
fleeting thoughts and then you can have persistent uh thoughts right that are you know we know we know in in um in uh
various psychop pathologies that that people can have persistent thoughts that very hard to get rid of and and intrusive thoughts and things like this
and then you know then then you can have U multiple um identities multiple alars
right from in this in the sense of dissociative identity disorder and then you can have full-blown full-blown personalities and so what you can what
you can think about is that the information what if what if information is not purely passive uh I mean can be
but but in some cases what if what if these patterns are um
they have a degree of agency themselves because let's not forget we too are patterns we too are temporary patterns
in thermodynamic in the thermodynamic sense right we persist for some amount of time metabolically and then you know
that's it so so if if patterns like us can have thoughts then maybe there can
be simpler patterns that are thoughts to us but also might be thinkers of their
own in other words they can spawn off other subpatterns within the cognitive medium and and so that's that's what I
was playing with is this idea of what if what if it's a Continuum right this this Continuum between thoughts and thinkers is not a categorical distinction but
it's a it's a it's a it's a difference in in degree oh yes I think that was at the at the beginning of your paper where
where you used Mark s's um Sigman Freud quote which is also quite intriguing I
mean he they let me just see if I've got it here it is the material present in the form of
memory traces being subjected from time to time to a rearrangement in accordance
with fresh circumstances to a retranscription yeah yeah I mean there's
two ways there's two ways to think about it right you can think about it as a static being that has to reshuffle their
interpretation you know in different ways or you can think about it Andor you can think about it as a set of uh as a
set of um I I playfully I call them self lets you can you can you can think about snapshots where each snapshot is not
rearranging anything they're giving it for a new they have the message each time new so you're not rearranging that
was that was a different you know if it was arranged differently before that belonged to somebody else that belonged to a different self and now your job is
to is to is to make some sort of sense out of it a a a constant uh continuous
process of of of sense making it's it's quite this that that
paper on self- improvising memory it reminded me of one of the papers I was reading about with Steven grossberg I
mean you even mentioned that love his work on memory oh yeah on that topic what are your thoughts on grossberg's
Mike on Stephen Grossberg
work just by the way yeah yeah um I'm I'm a huge fan and it was funny I'm not sure I'm not sure it might have been
your interview with him or maybe somebody else where with where where he mentioned that he saw me in
like I I couldn't believe because I hadn't talked to him since then I couldn't believe the memory this guy has
like you know just just remembering that that I came and talked to him but it's incredible he no it is it is incredible
uh no I I love his work and in particular um he had a paper in 1978 called uh memory cognition and
development or something like that and uh there he outlined I mean it was it
was just just brilliantly precient because he outlined some of the commonalities between certain
developmental mechanisms and certain um uh cognitive mechanisms like like you
know information processing in the retina and stuff like that and and and what it looks like uh and I I just
thought I just thought it was it was in incredible that that that early he saw he saw these um this similarity you know
um the Symmetry the Symmetry between the building of the body and the building of of the mind yeah I I thought that was
just uh there's some when I speak to people about gross book's Works some people see him as this Einstein of the mind like
legitimately one of these like Super Saiyans of of mind and then and then and then some people just don't know him at
all which is which is surprising it's it's either one of the extremes they either really love his work or just don't know it at all which is quite
quite strange well you know and that and that speaks to there there's something uh kind of
um unfortunate about uh about the the progress in in science which is that it
isn't really monotonic so a ton of great stuff gets lost forgotten um you know
it's not paid attention to it has to you know get rediscovered or not later on uh
yeah it's um yeah it's too bad but but this was you know like it's it's part of the reason why I actually do this is
it's a great way to sort of have this community come together to have access to this information and and then share ideas because every time when someone
watches for example one of your episodes even in the comment section some people have profound things to say about your
work and things where where I learn so many new things just reading the comment section alone so it's very AB absolutely
yeah absolutely um I have um in my on my on my blog uh I have uh I have the
comments turned on and people leave comments and I've been very I've been amazed at at how useful the comments are
and how rich and I mean I I learn things all the time and people put up you know new new theories and new pointers to uh
uh to relevant work that I hadn't seen before like it's it's super useful um I I did not know that was going to happen
when I started this like it's really good and I think that's the beauty of this of the internet in that regard is
that this this open sharing of ideas all the time really is useful because it makes for so much more constructive
critiques well I mean sometimes it can be quite bizar and and a bit rude here and there but for the most but I mean it
it is very useful uh I had remember one so I made a note let me just find it someone commented on your previous one
they want a formal definition of diverse intelligence we we spoke about it very
in in depth for the the last time we spoke but a formal definition of diverse intelligence what would that be for you
A Formal Definition of Diverse Intelligence (DI)
sure well the first thing I I'd like to say is let's let's just agree amongst ourselves what definitions are for so
because that's important so so some people use definitions as a in a gatekeeping function so they want um
some kind of sharp distinction so that they can say ah this stuff is not it and then this is it and then we can we can
spend a lot of time wrangling over which one's which and then we can keep some things out okay that's not what I think definitions are for so I think
definitions are useful to the extent that they facilitate new work new
discoveries so they should be uh mind expanding they should help you use tools
you didn't uh use before they should help you have make new connections you didn't make before that they they should
they should have a practical uhh functional utility in getting you to new capabilities and new discoveries that's
what definitions are for so SOC because of that um I I often uh either either
redefine or or uh you know use use words in different ways that that um a lot of
people find disturbing because they'll say well that's not the common you know that's not the common sense use of it
and I really believe that philosophers and scientists should lead not be stuck
with with common sense um usages of different words because those aren't given to us by you know some sort of
grand intelligence they're just what we've cobbled together along the way now now now we can uh sharpen those up and
and in fact open them up and and see what which ones survive and which ones don't so anyway diverse intelligence so
I I take diverse intelligence to refer to the study of uh mind in particular uh
problem solving capacities but also all kinds of other things that are not around about problem solving intelligence including play and
exploration and and you know and and affect and emotions and all these kinds of things all of that stuff in truly
diverse embodiments this means intelligence is not about brains necessarily uh it's not about things
that evolve naturally intelligence and uh and and all of those kinds of um
cognitive terms uh may may exist to various degrees and all kinds of uh
unfamiliar substrates right this could be this could be um things of of of very different size in scale so this could be
very tiny things it could be enormous you know I don't know solar system sized objects somewhere I mean I'm making that
up I don't have any strong claims about it but but but the point is it is it is absolutely not limited to the N of one
example that we have here on Earth which are this kind of you know brainy uh brainy sort of substrates so it's the
search for it's it's an attempt to improve our own uh uh intelligence detectors and go beyond our ancient
evolutionary firmware that really leads us to only recognize a certain you know small subset of intelligences and ask
what other spaces can intelligence operate in what other embodiments can we can we can we tell a principal story of
how to recognize it what uh what facilitates it and so on I like in this paper you even say
diverse intelligence research focuses on the commonalities across all possible intelligent agents which is a great way
to sort of summarize what this field is doing in terms of a research basis yeah and and by the way I I don't um uh I
don't claim to speak for the entire field right I I speak for myself only but but there are there are many people
in the field that sort of uh that do agree with me there are many people that do not in particular um there are lots
of folks that don't like the um the Continuum that I insist on between you
know so so so-called real minds and so-called machines right so this is something there are many people in the
organis tradition that think that this is this is really a doing a disservice to the study of the mind to to put it on
the same Spectrum as machines whatever whatever that may be and so so yeah so so I I don't you know I don't I'm not
claiming to speak for the entire field I think that's a great way to sort of segue into what would be the difference
and this is along the lines of your paper between dating a an algorithm a
computer and a artificially intelligent person mind or versus dating someone
else like yourself myself I mean dating someone um I think you wrote what about
the forthcoming AI girlfriends and boyfriends I mean it's it's it's a fascinating idea because I mean who are
you who are we um in general uh yeah so so well well first of
Intimate relationships with AI? Importance of Cognitive Light Cones
all I refer everybody to read some of the stories in that blog post uh that that right I mean this this idea of
dating something that is fundamentally different from you I I hardly invented
that idea right this has been around for hundreds of years now people are in love with sensient clouds of particles and uh
you know this is this is we we've been we've been we've been digging into this issue of uh what what is in group what
is out group uh who deserves your compassion with whom can you have a relationship all that that's been that's
been around for a really long time and and one of the things I I really worry about uh I I I I think people go down
the organicist road with good intentions to try to understand what is magical uh in the you know sort of in the in the
useful sense about uh about true true minds you know with Consciousness with
agency and all of that but I think um the the downside of this is that I think
what in in in trying to uh trying to be specific about what's what what's in and
what's out and in particular try to trying to draw sharp lines I think you R you very quickly run into the side of
the spectrum that says only love your own kind and we know how that works out Humanity has tried this many times I
think we we we have some sort of built-in um built in a tendency to to
demarcate ingroups and outgroups and and only you know these are they're real and these guys and they look a little
different I don't think they feel pain like we do let's let's not you know worry about them so much you know we're we're we're not very good at at um at
expanding our our are compassion to others that that have different origin stories or or different composition so
um I mean look uh I think that I think that this is again not about AI at all
we are going to there's there's no doubt that in the next decade or so we are going to have humans that are mostly
biological but they got some microchips in their brain and uh some of those get them to sort of whatever whatever
neurotypical is supposed to be but others have decided they're going in a different direction and maybe they're
connected with some other people more than we are connected right now you know like really kind of mind meldy stuff and
maybe maybe somebody decides that what they'd really like for senses is to really feel the solar weather and the
financial markets that's that's what they'd really like you know sight and hearing is good but but they want to really like really feel what the you
know what the what the NASDAQ is doing and and all all of these humans are going to be running around and they're going to have different degrees of uh
evolved and designed components and yeah so you know I don't
know are are when when you go on a date with somebody are you going to ask them what percentage is like Factory
equipment for you know that's biological do you care I I I don't care uh if you
know if my spouse said that you know she had had some stuff replaced with with various Technologies is that what I'm
really worried about I think I think here here's what I think we're and I'm certainly not telling anybody who to date but what what you know for for me
personally what what I think is interesting these kinds of things is that um what you really want is you want
a kind of impedance match you want a similar uh cognitive lone you want to be
able to care about the same kinds of things and and ideally even some of the same things but at least the same
roughly the same kinds of things because you know this is this is why we feel that people that fall in love with
Bridges or people that um you know think their you know their Roomba is their child and things like this this is this
is why we sort of look down on this stuff because because we say look you your your your capacity to care about
things are just not matching at all you know and there are certainly um I can think of I can think of some um uh sort
of popular uh popular art kinds of things like like the Watchmen movie and things like that where where you've got
a you know you got a romance between you know this Cosmic intelligence right and like a normal human and I I you know I
don't know I mean that's that's that's better than the RBA case but but but still if if your Consciousness and the things you care about are like you know
a tiny Speck in the mind of this other being are you really have like are you really having a relationship I don't
know those are those are deep questions but but I I certainly don't think it's about what are you made of and how did
you get here I think it's all about what kind of mind you have and can we share some of the same ex some of the same
existential concerns in fact um Olaf wowski and I are writing a paper on this um it's a paper on on on love and
diverse intelligence and so on and it's this you know you can you can run through all kinds of different different
examples like uh you know can you really date Superman let's let's let's assume there's no Kryptonite right like like
can can you because what what what he doesn't understand is your existential concern over dying like he just doesn't
get it he has no idea what you're talking about and so at some point if the kinds of things that worry you as a
as a system that you know sort of pulled itself together from its parts and you're here for a limited time and and
you know there are all kinds of other psychological issues that we have that are pretty much unresolvable because we want things that are basically
impossible and so on if if if the other being doesn't understand any of those things then maybe it's not a good match
it it reminds me of of her with scholet Jansen and well Kean Phoenix have you
watched that film I haven't I haven't seen it I I know the movie but I haven't seen it's it's crazy because at some point this artificial intelligence has
so much more experience because it's understanding the universe at such a deeper complex level that she just
abandons the guy and then goes on her own Quest I mean they've there've also been all these new cases of scholet
janson's voice becoming this new artificial intelligence General voice and and she's apparently suing people
because they're using that's how influential that film was just as a by the way but the main premise of this
this whole idea of what you're talking about one of the one of the lines in particular that I found quite intriguing was you spoke about the fact that you're
not always you either I mean in general when when someone's dating someone uh perhaps that you have people who judge
people say don't date someone with money uh date them for their personality their quirks the things that they do but those
fade as you get older you have memory loss you won't have the same quirks you fundamentally become a different entity
which is problematic because these values we're placing and the separation that you're doing trying the grouping
people in and out of what you're talking about is problematic because of that you're never really that person
continuously at least well well well yeah and and it's that same Paradox that we talked about earlier it's uh it's
it's yeah it's this idea of if you if you really you know sort of start stripping away the different
uh qualities then there isn't going to be anything left and it's the Galt but
the Galt is going to change and so how are you going to handle that change right I mean that's that's part of the
the like the existential difficulties of our of our Human Condition because everything changes we change all all the
other Minds that we interact with are going to change you know none none of us are none of us are going to stay the
same yeah it's it's the there's another part um you you slowly touched on this
now when you spoke about this this percentage difference at some point we're going to ask people okay are you 50% human what are you are you 45%
Cyborgs, hybrids, chimeras, & a new concept called "Synthbiosis"
cyborg um we we're going to have these conversations I mean current variants you mentioned are about 99% human at
this point and then chips here and there perhaps glasses you've got a bionic maybe an arm or a leg but it's
completely completely apparent that at this point most people are synthetically engineered in some sort of way I mean
people have plas surgery down people have a lots and and the Norms have shifted and changed as as a doctor in
medicine and when you look at what people found to be absurd or or a bit over the top those have decreased so
like having normal nose surgery or getting your nose tweaked here and there is almost a baseline Norm at this point
so it's very easy to see how that line gets blurry over time and yet we fight
this uh yeah yeah no it's look into the past the the first guy to carry an
umbrella in London was mobbed he was mobbed and people threw you know threw threw garbage at him because they were
uh shocked that this guy thought he could get away from their the the exus the the the normal human condition of
getting rained on this was this was considered to be normal we are all out here we're all going to get rained on together that's how it is there's
nothing we can do about it and who is this guy to try to get out of it and so an umbrella that's all he had and and
this was this was shocking and you know whatever so um I I think yeah I think I think if you were to if you were to
bring back a you know A Primitive man and uh ask uh ask her what she thinks
about um uh you know the the current humans you know you got you you you've
got some glasses on you went to school which for for you know for 12 years it gave you this incredible like like brain
boost that nobody else had ever heard of and and you've got some glasses and you've got some orthotics in your shoes and you've got you know you've had some
you know some some some surgery uh somewhere that you know you got a pacemaker and you've got and by the way
half the stuff you know you is you plus your iPhone Right Stuff you look up because because you know it in a
functional sense but but take that thing away you you don't know where anything is or or what anybody's phone number is or anything and so uh right and and
you're relying on all this stuff I mean um it's it's just to to that person we
are already incredible cyborgs just just just incredible and and there is no there's no putting that uh Genie back in
the bottle this is I mean obviously this is gonna this is going to crank forward and I think that's one of the most undermined forms of extended cognition
is our phones our cell phones people really don't realize how how much Andy Clark yeah Andy Clark has written a lot
about this work very very very cool and a lot of it I mean we don't you
you something I found quite funny was one of one of the sentences here would say the challenge before is the
challenge before is to develop rational policies for ethical synth biosis and then when you read down below this is a
word you actually generated using chat gbt tell us about this yeah I was
looking for I mean I don't so so funny enough as much as I I like all this diverse intelligence stuff I don't use AI for much but but but uh at all I
don't use it to do any writing or anything like that but but but for these kinds of um sort of creative things I
think it's actually quite quite good and I was I was looking for a word that uh
that that that would would Encompass this idea that um a positive creative collaboration between biology and
synthetic entities and and I sort of described that and GPT said synth biosa that's pretty good I like it
I I think it is yeah yeah I think it is because yeah because because fundamentally this trying to maintain this distinction between uh quote
unquote natural things and the product of those Natural Things meaning our synthetic you know engineered things uh
there's I I just don't think it's it's valuable at all I think it holds back a lot of progress and in and in your
defense because I know a lot of people assume that when you talk about
man as a machine or when you when you talk about these these Concepts they're useful in different context um so you
often talk about we spoke the last time and you mentioned the fact that an orthopedic surgeon has to see you as a as a machine I mean there's no doubt
about it when I'm in theater with assisting with an orthopedic surgeon I know what it's like it's legitimately
you're a mechanic like literally taking apart drilling holes getting a hammer knocking
onto things and then and then I can go back into like let's say a clinical scenario and chat to the patient about
the operation and that's a completely different experience um it's a mental well-being check it's a sort of
psychological check and it's very very different so it's easier to see how we can see them both as a machine and as a
complex psychological system I mean the the I I think what I think where where
people go wrong sometimes is to think that when we make these models machines
uh you know living beings humans what whatever that these are all claims about
something essentially is it's this kind of essentialism that we think it's a real thing there is one objective answer as to what it really is and we need to
argue about what it really is I I don't think any of these things are about what
the thing really is I think these are all interaction claims this is why this is why I called my my um my framework
tame because because it is an engineering perspective now engineering means something wider than I think most
people take it but nevertheless the thing about engineering is that you are at least clear you're honest with
yourself in that what you are doing is putting out an interaction protocol this is the frame that I'm going to look at
at the system this is what it enables me to do here's a bag of tools that I bring to it and then you can bring yours I can
bring mine and we can compare the results and we can find out that oh wow I I I missed all of it you you you had a
better framing because look you were able to do all these things that I couldn't do because I was looking at it from a different perspective so when
people you know when when when so so so like people ask um you know am I a computationalist for example with
respect to living things uh well I think the the whole the the question is ill
posed because it's not whether living things are touring machines or that nothing is anything I think that what
what you can say is okay I've got a certain Paradigm let's say it's a touring machine or it's a you know whatever it is and that lens enables me
to see certain things and yes I do think in some cases it's a it's it's a useful lens but it certainly doesn't capture
everything that's important about living things and so then then you need or or cogn things more which I think are more
interesting then then you need then you need different different lenses but but but but then it then then it's all good
you know we don't have to argue about what it really is you can just say through I I look I look at it through
this lens here's what I see do you find it useful or do you want to keep looking for a new lens or or or usually
both I I think that your work is so intriguing on so many different levels
and it's a and you're able to to cross so many different fields that to some people particularly
I would say to some scientists when you make this claim that there is a technological approach to mind
everywhere the moment you get boxed into this sort of pans cist view they immediately have this dismissive
attitude but if they're a reduction materialist um person um which is sad
really because they don't really then give it the opportunity that it deserves when because when you break it down and
actually look into what you're talking about you're often saying you got to we don't know you got to make experim ments
and and get some sort of empirical evidence to base whatever you're claiming um yeah and I think that's the
most important thing is that you're often saying let's set up an experiment let's do this let's try and show why
this is the case um which a lot of people don't necessarily do particularly philosophers who have very strict views
on on their their reality you're able to at least show this empirically which I think is pretty cool well that's I mean
Importance of the symbiotic relationship between Science & Philosophy
yeah so so the wacky thing about our lab is that we do a lot of experiments and
and this is this is not only philosophy and I don't I don't I mean I think philosophy is very important I never you know I never downplay it but but but but
but we do a lot of experiments and I you know typically I I basic basically I put out two kinds of papers one is a the one
kind is a straight up uh you know developmental biology or bioengineering or you know synthetic regeneration
whatever it's going to be I don't talk about any of the philosophical stuff in those papers um but you kind of can't
get away from that stuff because what what happens is sure sure you can you can dismiss the the kind of the other
papers which are kind of these philosophical um perspectives on this but you still have to account for the
data and you know my my point is simply this because people say to me like I'll give a talk about something and they say
okay you know the data means really interesting what what what you've done and the new capabilities but you know I
wish you'd stop talking about this philosophy stuff and and my claim is well this is why we did it you see is
because is because that philosophical Outlook made specific predictions about road maps you know
it's not a single experiment but it it it shows you where to look it shows you how to look it tells you which categories can be broken and otherwise
otherwise you're trapped in certain ways of thinking and that leads to very specific uh new discoveries and so so I
think this is this is important because after the fact once you do something anybody can look at it and tell a
molecular story about what happened and say oh well this is this is not different from from anything that's
happened before it I mean of course it follows the laws of physics and chemistry my point is never that it's fairies underneath and that some you
know something you know miraculous is happening that's never the point but my point is uh why wasn't it done before
what is it about the what is it about the standard Paradigm that didn't that didn't facilitate these these experiments to be done before so yeah
you know you can be you can be down on the on the conceptual Frameworks that that that drive this stuff but then
you're playing catchup because because then the stuff is going to be coming out and it's and it's surprising and this is
you know to me this is this is a more General uh issue of of of these kind of uh reductive explanations and by the way
I I don't I don't think anybody's really in this field is an actual reductionist because if they you know if you if you
push and you say well then you want explanations in terms of quantum foam right and they say no no that's stupid it's chemistry it's got to be chemistry
so that's not real reductionism that's just the love of chemistry but but um the you can the easy sort of analogy to
this is if if there was a it was a game of played right some you a couple people played a game with chess you could so so
lassus demon could look at this and say well I mean all it was is a bunch more
is a bunch of physics I mean I saw all the all the protons went where the protons go the electrons went where they go everything followed rules there's no
mystery here no surprise everything did exactly what it was supposed to be just you know it's just physics that's not
exactly wrong because looking backwards after the thing was done you could tell that story but now the question is does
it help you play the next game of Chess how do you how do you go from there to well now what do I do and so and it's
completely useless for that right it's it's only a story looking backwards so I think the thing about these kind of
explanations is that you want them to facilitate your next the next
discoveries the way to you know to to improve your capabilities anybody could always tell a molecular story after the
fact the question is what are you gonna do next yeah I mean on on that on the
topic of reductionism you at some point you say in an important sense you are a
brain in aat however we are not just chemical
machines um so so you you're both acknowledging the fact that we're
we're these mechanical systems and yet you're also still saying that that's still you're not reducing us to these
simple properties you're still acknowledging the fact that they are more layered um realities here to
explore in Ence yeah I mean in the in the kind of
uh the the simple thing is that yeah absolutely my claim is that um
interactions with certain kinds of systems are much more efficient at high levels right so so so certainly I mean
we know this from anybody who's trained animals instead of trying to run their neurons like a puppet knows that it's it's much better if you understand the
psychology of of of certain creatures and so on um and and as you go rightward on that Spectrum into into friendship
and love and these kinds of things that are much more bidirectional it's not just control and and and you know prediction but it's actually you know
being vulnerable to to change and and and benefiting from the agency of the beings that you're that you're um
associating with and so on um yeah then then of course there are these higher levels but but I want to say something
else here too which is that I think one thing this is all telling us is that and
I think this this will be more more and more apparent in the coming years we have really misunderstood what simple
machines are we've we've fallen in love with our um we' we've confused uh
physical things with models of simple machines that we make of those things and we think we think we know what it is
when we make something and I I think that's profoundly wrong what what we have is our model and and um we've we've
done some work now and we're going to do lots more on finding surprising protoc
ogni of properties and very simple systems that are not obvious at all and I don't mean emerging complexity
emerging complexity and unpredictability is Trivial it's easy you can you know cellular atoma whatever they will give
you complexity they will give you unpredictability in certain cases that that that part's easy I'm talking about emergent goals emerging cognition in
systems that are extremely simple and minimal and you know when we say we are
not machines we are certainly not describable by the simple models we've made of machines but I actually think
that lots of simple physical objects are are very are not properly described that way either and and we we need to we need
to remember that all of these things are just lenses that we bring to them you know um yeah I you know I heard I was
talking to somebody once who um he he writes these uh these these language models and he said well I made it I
wrote it myself I know exactly what it does I know I know everything that's in it I made it and I was I said I said you
don't even know what bubble sort does like we we found we found we found these these unexpected capacities in in in
stupid bubble sort you know six lines of code fully deterministic no nowhere to hide even that thing does things nobody
knew that it did and uh and and if that's the case when you make this this this crazy you know language model again
I'm not in love with language models but but but just the just this idea that we've made it and therefore we know what it does I think is is we really need a
lot more humility around this I I I you know I think there's plenty of stuff that quote unquote simple matter does
that we do not understand yet Mike the last time I spoke to Mark Psalms you
asked me to ask him about what is the meaning of life and then we started went down this whole road towards the end of
that conversation he he spoke about the upen aimer Foundation giving him uh funding his his new search for
The Space of Possible Minds
artificial intelligence trying to sort of um see where this goes what are your thoughts on his work and what they're
trying to do at this point yeah um I mean he as as far as I
know none of it is published although I've talked to him about it quite quite a lot so I'm not I'm not gonna um kind of give away anything until until he
publishes it but um because it's not it's not my story to tell but uh I think
of anybody I know at the moment his approach is the most likely to give rise
to something that actually captures what's important about uh about cognition in in living things I I I
think I think if anybody is going to uh engineer something that that exploits
some of the same principles that that life exploits for for cognition I think he's likely to do it yeah um Mark really
sees that cortical fallacy that we all seem to have you know this Obsession of this sort of higher
cognitive functions as as being this the epitome of of Consciousness yeah I mean I think it's
even I think it's it's it's way worse than that it's not just where is it uh
you know I mean there there are some people who think that it that that that Consciousness for example shows up um
during warm-bloodedness you know I think that's Nick Humphrey's position and uh it's not even to to to me it's not even
the question of where in the brain or or what kind of brain I mean I I'm I'm
talking about what what space do you even operate in because I because I think that that you know when they say
oh this thing is not embodied it doesn't it's not a robot on wheels that can sort of run around no you you can have bodies
and do this kind of perception action Loop and active inference and all this stuff you can do this in other spaces
that we are completely blind to right so you can live in transcriptional space or anatomical morphous space or who knows
there's probably hundred others that we don't you know we we don't know how to visualize and all those are embodied
that's on us that limitation that we don't see that and we don't see all the all the goal directedness the striving
the intelligence the problem solving that that's our limitation right and so so intelligence not only in in you know
weird kinds of body parts but just in things that are not in 3D space at all really that's not where their their life
um plays out and even even worse than that along the
Spectrum even even you know sort of weirder is along the spectrum of of uh how quote unquote real something is so
what I mean by that is I I don't remember if it's actually in that paper or not but you know uh there was a science fiction story if anybody
listening to this knows what story it is please email me because I I couldn't remember like which which I'd like to
give credit and I couldn't remember who it is but um the idea is that these uh these creatures come out of the center
of the earth you know they live they live down in the core and they come out of the center of the earth and they're walking around everything that we see
out here is gas to them I mean they are so Den that all of this stuff here that feels
solid to us is gous Phase it's plasma like it's they don't even see it and they they're walking around as far as
they're concerned they're like in basically in in in in space at this point because like oh my God this like there's nothing here and and uh I I'm
sure I'm embellishing this in my own way I don't remember what the what the actual story is but but that's only the first part that I recall but but to me
what I Envision immediately is like one of them is a scientist and he's taking measurements of this of this gas that's
on on the surface of the plan and he says you know uh I see some I see these patterns in this gas they sort of
hang together for a while and they do things and it almost looks they almost look agential you know these patterns
almost look like they're doing things and of course the others like ah you're crazy patterns and gas can't do anything patterns aren't real we're re you know
we're real what how's a pattern in gas going to do anything and he says no I I really I think they're like they're
trying to you know meet certain goals and they have memories and whatever but and they say well how long do these patterns hang around he says well about
a 100 years that's ridiculous nothing important can happen in a hundred years you know because these things live for you know millions of years and so and so
this this just reminds you that uh what's a pattern and um and what's a
real being so so again back to this distinction between thoughts and thinkers is in the eye of a Beholder you
know it's in the eye of the Observer and if we did have aliens that that came to Earth with a with a radically different
cognitive frame rate if they had different lifespans whatever would they think that talking to us is a good idea
or would they be trying to talk to EOS systems or conversely would they think that talking to the you know molecular
processes is the best that they're going to be able to do I think I think all of this is really about um observers and
about getting good at recognizing uh intelligence and extremely unfamiliar
guises you know I think that the it's it's inescapable your work particularly
to to not cross philosophical SL ethical boundaries and and have these discussions so so when people tell you
that listen stay stay away from the philosophical stuff you cannot you just this is just not part of your job you
have to at some point address these because I remember one of the comments in one of our discussions it could have
been our first one or second one but then someone asked is is Michael playing God and my first thought
was H it's it's a strange one you know it was one of those questions people often asked back in the day when people
were were tinkering with any sort of even a plant you could genetically modify an organism and then you you're playing God at that point I mean it's
it's a very very strange question to really ask what would how would you respond to that well people actually ask
Is Mike Playing God?
it all the time I think it's one of those questions that sounds like it makes sense until you until you sort of dig into it a little bit um but because
because I don't know what what the definition of God is and I mean usually the people who ask this they got some glasses on and they've got you know they
usually Drive they don't walk places and so on so it's a little it's a little disingenuous but um but but let's let's
dig into this for a moment um I did a poll once and on Twitter and certainly this is not uh like a you know a
statistically valid sample or anything like that but um I did a poll and the and and my question was simply this so
you're you're you know Aug the caveman and you're walking back to your to your tribe uh uh and you have this Vision
you're you're struck with this vision of discovering fire and so immediately you you get you you understand fire but you
also get this vision of Steel weapons um
artificial Hearts antibiotics going to the Moon adom bomb uh computers art like
all of it right immediately so now the question so now your question is so you've seen all this right you you see where it's going to go your question is
do you tell the others and you get going with fire or or or or do you let it you let it die and and you never tell okay
six% of my my audience and that's and that's the people who like my stuff so that means they're already probably like
really biased towards you know techy stuff 6% thought thought you shouldn't you shouldn't let you should stay below
fire so okay I I don't know you know I don't know if if these folks live um a
lifestyle consistent with that belief I I tend to doubt it but but uh you know
it's if if that's the claim I I think you have to take this seriously I think
you have to say if if you really mean by playing God I mean what could it possibly mean if you really mean taking
steps that are uh strongly efficacious in the world that that make change that
do things if you really don't want to do that your quarrel is not with me and my
work on frog skin your quarrel is with all of humanity who doesn't want to sit
in a damp cave their whole life and die in exactly the same condition that they were born in that's if if you're really
against that okay make your case and and see you know and see see if people will go but uh none of the things that that
that we're doing are any different from the the fundamental question are are you
going to take responsibility for the future and I think that is the the most profound moral cowardice to delude
yourself into thinking that doing nothing is staying out of it no doing nothing is not staying out of it doing
nothing means you are complicit in the suffering of enormous numbers of of humans and others on Earth who are
having a an incredibly sub suboptimal uh experience in their in their embodiment
and if and if you have these kinds of thoughts about let's not do this and let's not do that uh you know uh you
know let's put a break on progress you are making a very clear statement and and you should think about it hard to
make sure that you you are you know you're you're really backing up this idea that you are going to stay you're
going to let the status quo roll on because I I you know it's just to to me it's an incredible Act of moral
cowardice yeah and I think if for anyone who who wants to even get a glimpse of
what your ethical framework around all of this eventually becomes this paper is per I mean this paper on AI at some
point you go a path forward through the ethics falter for civilization and and this fundamental
premise for you is is to mature to realize okay our kids are plant us
everything does change we continuously change it's how we going to move forward and and how are we going to P to to act
in a certain way that progresses us in a in a safer more kind more loving
environment and and this and the the LW people scientists don't like to use it but I mean at that point you you're
looking towards this sort of Kinder process where you where we we're able to give artificial intelligence these
properties um because it is something that our cognitive light cones appreciate and we know that this is
something we genuinely enjoy so let's try and propagate this yeah yeah um and
A path forward: through the ethics filter for civilization
and you know I have some collaborators so so Richard Watson and Thomas doctor and Olaf wowski and um you know people
like Bill Dwayne and uh Eliza solomonova you know we we um we we write on stuff
like this and there's going to be there's going to be way more because in in certain Traditions right so for example they come from a Buddhist
tradition and so and so there there's a great emphasis on uh en enhancing
compassion alongside enhancing wisdom right on uh basically an infinite sea of
other beings and all sorts of crazy embodiments I mean I I I gave a talk on all this stuff um to uh to some to some
Buddha Scholars uh in Nepal you know at some point and I mean that audience
there was nothing here that surprised them whatsoever you know usually when I give these talks people are kind of kind of shocked and disturbed about about
half of what I say uh these guys were like yeah no kidding we we we all know that and uh they found nothing nothing
weird about any of it and um I do think they have uh they have Frameworks for
thinking about these these these kinds of things right you know this kind of expanding committing to through through
Concepts like the body and through expanding committing to the task of this this metacognitive task of
expanding your um your cone of compassion and things like that um yeah I think I mean I'm certainly not saying
that's the only way to go but but I think that's exactly where this is going
I agree with you I mean because my even though I'm I'm of Indian Heritage descent but my when I talk about science
philosophy Weston particularly to my family to like them certain uncles or aunts and if I talk about these topics
they also tend to do that they they're not as surprised as as as the more my more western side of the family a lot of
the Eastern philosophers and my uncles and aunts they're not really philosophers but they tend to think like yeah that makes sense that is kind of
what their religion taught them um whether it's Hinduism or Buddhism but there is this element of minds are
everywhere in a way so this this this General binary approach that we seem to have is not working um for the most part
and you're showing this in very very Western Scientific ways well I think I think I mean that's the other thing
right so so I don't really believe okay there there's there's another um perspective where sometimes people say
look uh early indigenous societies knew all this all we have to do is go back go back there I I don't actually believe
that either I I I don't think they actually KN knew this and right and and saying something is not the same thing
as having a principal framework that takes you to new discovery so so it's it's I I think both sides this idea of
there's no mind everywhere anywhere except in us or maybe some people think that just isn't anywhere but but the
other side of it which is oh there's a spirit under every Rock like that's that's a fine start but it's just a
start you can't just say say it and leave it at that you have to answer the question what does that do for you so I
I think this is really important uh all all of this has to be uh empirically useful it has to elevate our condition
it has to improve our ability to to have more meaningful lives in the world it has to be practical you cannot just say
these things and have it mean anything unless it leads you to experiments and
and ultimately to uh to you know to better ways of being in the world so I don't think we're going backwards to
those Traditions at all I think we're using whatever we can scavenge out of all the you know brilliant people that
have existed in the past that had sort of glimpses of of of this stuff but but now I think we finally have the ability
to push it forward in a very practical way so that some of these ideas we can we can discard what isn't useful we can
we can keep and expand what actually helps us to get to new capabilities and I think that and that's part of the
approach that I appreciate most I mean I find it particularly annoying when people do that what you're talking about where these gurus come out and just say
these things with no basis absolutely no evidence of what they there's no claim but it's just so profound in itself
that's it the statement itself is all that they have which which isn't what what what you're trying to do you you're
often saying you got to show you got to do something back it up somehow yeah I mean I mean these these claims and these
profound statements and you know and and poems and whatever else they're they're a fine tool for um uh spurring intuition
and for giving you ideas that it's the starting point right and and and I I and I do think that it's true that it's
possible to have intuitions about things and and to come up with um uh prompts
you know sayings and writings and whatnot that trigger other people into new and interesting thoughts even though
you haven't yet worked out all the details I mean I do think that's possible I do think it's you know we are
kind of like so I have this like almost almost like like the way um platonist mathematicians you know they
feel that they're discovering an existing structure right of that that you're uncovering an existing structure
and and that you know you see you sort of piece by piece um pull it pulling it out um I I do think that it's possible
to to to to sort of have insights long before you have the wherewithal to
really make it practical or to know what it means or any of that and and so and so I like that stuff as much as anybody
in terms of an intuition uh you know building kind of thing to see what it makes you think about like like the
quote from William James right I don't know and I I I lose no sleep over whether he actually meant it the way that I mean it I don't care I I think I
think it's a very profound saying and what can we do with it now but um yeah the hard work comes comes after all that
someone it reminds me of and I mean we we lost him recently Daniel DN rest in peace to him he what you do is almost
the reverse but in in in the same um I would say in the same great manner is
that what what Dan did was he realized that you can't just philosophize you you
have to go in you have to get involved with the cognitive science you got you've got to get you got to basically
do some of the work um and and and that's when the philosophy becomes a lot more intriguing is when you do the
science and you go into it and you fuse them and you're coming from it from the science side and then of course you then
have to have the philosophical discussions with it and and you guys have worked very closely together what
is that like for you just as a side uh boy uh I mean f first things
Mike on Daniel Dennett (RIP)
first uh you know I I read Dan's books when I was a kid and it never I mean
they were so eye opening you know the Mind's Eye and kinds of minds and that kind of stuff right the early kind of
the early work in the late 80s early 90s um I I was I was young back then and I
would I couldn't have imagined for a moment a that I would that we get to meet him never mind that but B that at
some point you know at some point we'd write a paper together right like I wish I wish I could get get into a time machine and go back and you know tell my
18-year-old self that hey you know you're gonna write a write a paper with with this guy and actually a bunch of other people too that that I felt the
same way about um so so so that part was a profound uh kind of Honor for me um is
to is to be able to talk to him about these stuff and and by the way we didn't agree on everything we we we disagree on
a ton of stuff but um he was he was an incredibly uh generous clear thinker and
what I really enjoyed about him was that was was a few things uh one of them was
that he he he was never interested in in making cheap points he was always interested in improving everybody's
understanding of what's going on deepening the question may be the answer but but for sure deepening the question
and this idea you know he he really pushed this idea of Steel Manning you know he said that what that that in
arguing with people what you ought to do is first state their position so well and so strongly that they will wish they
came up with it right that you should start not not with a caricature of what they think that you're going to shoot
down because that that's a game right that's that's you know what he wanted was actual progress which meant you
better start with the absolute best uh description of their view the most plausible sounding des and then then see
if you can shoot it down after that right that was his that was his and and he was always that way in all in all of our discussions um you know about stuff
that we did agree on and and lots of things that we didn't agree on it was it was always very clear that everybody in
this discussion is there to uh to learn something and to improve and to give up
things that you thought before if if they're not helping you move forward and grab some some other tool like that that
was um you know he was an amazing example of that and I I mean well first I took a course with him as an undergraduate at T I had him for for for
a um yeah I had him for for a philosophy of Mind Professor which was which was uh amazing I purposely wrote paper there
was a there was a final paper for the class that you that you write I I picked a topic that I knew he he did not like
and that I knew he um you know was was completely against and and I was I was astounded at you know the the fair um
rigorous but but but completely fair you know analysis and grade and everything else um I that that was an example for
me this is how you do it this is you know it's not it's not just based on what you know what what you think but
like you know a deep analysis of of the the fairest analysis and then and then later when I came back to T as a faculty
member you know he was he was a he was a colleague that was that was incredible so yeah yeah I'm I'm really gonna miss
him um yeah know he'll be dearly missed I mean he was one of the so him and Oliver sax were two of the people that
inspired me to even start this podcast so um one of those guests I never got to have on but we exchanged emails every
now and then and even doing that for me felt like such an honor and I I really wish I had the chance to chat to him
that's how I'm just so curious for all those people who did get to speak to him what a what privilege might have been to pick his brain yeah oh no it was and he
was so you know he was so so inspirational and so generous with his ideas he he would come to our lab from
time to time and um I I have a I have a a picture of him on the on the blog with during one of his visits you know and
he's he was looking through the microscopes and he was looking at our two-headed worms and we would have these he would have these discussions with our
lab people about you know what's that what's it like to be a creature with Two Brains and what's the right way to think about these things and and you know and
uh yeah he would you know he would give talks just just very generous you know Mike you must you must check you must
look out for this one of these videos online it's a VPR round table with Dan
Dan dennit Oliver saxs rer shre um Steven J it's one of the most
fascinating things there like six I think Dyson Freeman Dyson was there as
well it's it's such a strange thing it's like the original version of podcasting I would say amazing amazing six of these
guys is having the the coolest chat on life consciousness reality um that was
one of the things that got me into the two of their both of their work and eventually to this podcast but anyway
before because we're digressing a bit the path forward this ethics how are we doing for time Mike you're right uh yeah
I'm yeah okay I got about I got about 15 minutes good okay for the the path
forward a the ethics filter let's talk about this because you said that there's there's two ways we could get this wrong
one is objective failure and the other one is while only love your own kind um
let's talk about how we can get this wrong and how we could actually divert this and get this right yeah um well the
An Ethical Synthbiosis that goes beyond "are you real or faking it"
the the the Spectrum itself is something like the it's it's related to the effort
of matching the degree of uh compassion that you um are able to exert to the
level of agency that or intelligence or Consciousness that that that being actually has right now I'll point out
that that we even when we get it right we are still not very good at following through on the consequences so for
example everybody understands that pigs are intelligent everybody understands that they that they suffer that they have mines and we still have factory
farming it's it's right so so even you know get getting it scientifically right is absolutely not um a guarantee of
anything in in terms of actual ethical Behavior but um but there's two ways to
get it wrong one way to get it wrong is to uh attribute more mind to a system than
it really has but also when I say really has I I you know I think everything is Observer relative of course but but
still you you could get I mean there's you know the internet is full of profiles of people that are in love with Bridges and and chandeliers and and you
know and things like this um so so so that's that's something uh having too much too much concern for things that
really don't warrant it and the other way is of course the opposite is when you've you you leave beings out of your
of your of your um calculus of compassion that that actually can um can suffer and have an inner perspective I I
mean one one thing to think about is uh if imagine two societies that get this wildly wrong in both directions so you
got a planet where everybody's like you know ridiculously nice to to you know they don't like to chop rocks in half
and and whatever and uh and and then there's and then there's the other society that thinks if if you're not a
very narrow type of creature you are a machine the way that deart thought about
lots of animals and that we can do whatever we want and it's fine and you're just faking and all you're all you're complaining about it is is just
um you know is just a word a word it's it's it's it's sentence completion you know is what it is so okay so so which
of those worlds would you rather live in right if if you're going to get it if you're going to get it wrong where where would you rather be I mean I think I
think the first one wastes a lot of resources and opportunities yeah okay
the second one is uh is is monstrous in in its ethical implications so so I I
think we should on the side of more compassion not less I mean obviously again we're not going back to there's a
spirit under every Rock because we are committed to having principled uh theories about this but if you're going
to make a mistake I think you should make a mistake in that direction and specifically what I'd like us to be
clear on I like what I'd like everybody to be clear on is that having certainty about these things right now when we
have pretty much no clue what underlies um ious uh really I mean I know a lot of
smart people have made efforts into it but but I really don't think we we have it nailed down um and all of these ideas
about uh what cognition is and how different architectures uh support it
and and whether Cog Consciousness and the ability to suffer uh tracks any of those things or not
uh there is there's an enormous amount of unwarranted certainty about this among people people feel very strong
they make these really that definitely doesn't whatever you know it doesn't have this or that I I I
think we all need to take a step back and just understand that from from from the scientific perspective there are so
many things we do not know yet like really critical fundamental things we do not understand um the emergent uh
cognitive properties of matter we do not understand the scaling um policies of how Minds emerge from smaller Minds uh
the field of diverse intelligence is just getting started so I I'm much more worried about the right side of that uh
of that um Spectrum than I am about the left side at this point and I think what
one of your towards the end of the paper one of the things you say is the question is how do we make sure to express kindness to the inevitable
forthcoming wave uh of unconventional sentient beings and you say that we should start by making sure that we
express loving kindness appropriately and not be driven by fear of the other which is uh which is a very beautiful
statement um yeah thanks I I I I've actually written a whole thing on fear just now
I'm waiting it's going to be it should be out in in a couple of weeks um I think that well well one thing I could
say is uh after that after that piece in in noima so so there was this the short piece in NOA about the the AI there's a
much there's a longer paper which exists as a preprint and it's also in in review right now in the journal but but I think
more people saw the NOA piece but still I I I was I was very clear there I I
thought that I'm not actually saying that AI is like that that current language models are like humans I mean I
thought I was pretty clear on this but uh I got a lot of um a lot of people
writing to me that um basically extremely disturbed by this
and this idea that that that that Tech Bros like myself are uh yeah I thought
that was that was funny uh that are are um that that our nerdiness uh sort of
prevents us from understanding real human relationships and this is why we see these things in uh in in in you know
what they call machines robots AIS and whatever right they they they were looking for a um they were looking for
aning why you do this in a sense yeah correct I mean it's an old
strategy right the old strategy is if if you're uncomfortable with a view try to find something wrong with with right
what what is it that you know we see the truth why can't they see the truth what is missing that you know that causes
them to to to say these things right and and the standard theory is uh well they don't understand you know these these
these nerds don't understand um what real um human relationships are like right and that I mean I mean I'm not
super interested in in um psychoanalyzing anybody uh that way but it did it did cause me to think I'm like
wow why are people so triggered by this you know what what is it that c you know to really and so and so I so so I'm
thankful for once the p p you know piece comes out I'll thank some folks and and who said these things and actually
pushing me in what I thought was think is an interesting Direction is to ask um what what is it what is it that's so
scary about about this View and and I and the more I think about it I really think it's a very fundamental fear and
the fear is it's a zero sum game love is a zero sum game if we have too many other
beings that need love then couple of things will happen there's not enough for me that's a and b what if I can't
rise to the to the to the challenge of having enough compassion for everybody I think it's profoundly threatening to
realize that you're going to have to open up your um your constrained way of
looking at who deserves your compassion and and what happens then and uh and and
then and many other things so you know so I wrote I don't know probably five or 10 pages of something about you know just kind of talking about what is
really uh what what I think really underlies why why people are freaked out about this and and and the
responsibility I mean it's very comforting to think that I can just tell you know things are worth worrying about
by looking at them I know what people look like I'll just look at them um it's comforting to think that I don't need to
be responsible for the future this this is it this is you know this is how this
is what's natural right even people who don't believe in in in some some sort of God all they they still have this notion
of what's natural I have no idea what that's supposed to mean but but but you know this is like yeah this is how we're
supposed to stay and that's fine I don't I don't need to be responsible for the future and I don't need to be responsible for uh shaping um what the
planet looks like in the you know in in in the coming centuries and and beyond that that's comforting to think that
it's all handled it's nice and simple uh you don't need these these extremely difficult nuanced views that are going
to require work from you they're going to require you to make hard decisions to paint a picture of the future of what do
you want it to look like you know um it's much easier to say what you don't want this this fear-based uh scarcity
mentality right there's there's not enough love to go around let's let's let's draw a nice tight Circle around things that we know what they look like
and we know where they came from then we're not going to have to worry about all this other stuff that's really difficult to to figure out what's what's
going on with it and um yeah and then we don't need to worry about um uh painting
uh uh pictures of the of the future uh and figuring out how do I get there we could
just we can just make a list of what we don't want to have happen and that's easy and and and focus on the negatives so I think I think that that type of
that type of um limited uh fearful scarcity kind of mindset is is what's is
what's responsible for a lot of this and by the way what I don't mean so so I want to be clear here I don't mean to to
um try to deconstruct some of my colleagues that are really working on on very good science right so so there are
people who are working on good science for developing principled ways to distinguish between so-called machines
and and what's special about living organisms like that that's a good area of diverse intelligence I'm not I'm not
you know saying that that shouldn't you know that that that shouldn't take place or or that they're driven by anything other than um you know good scientific
principles I'm talking about the you know I'm talking about the the folks who have a really visceral reaction who when
when I uh when I challenge them to so so so so be explicit so so tell me what
what is the magic that you have and when did you get it both during Evolution during during you know during
embryogenesis what what what what do you have and when does the show up that you think cannot be uh either either H in a
hybrid form or in synthetic form you know done and what would you do if I mean just I you know I I think reading
science fiction is is a great cure for this because from the from the earliest time you understand the scenario right
you're you're you're sitting there at home this um spaceship lands on your front lawn this this the door opens this
thing sort of trundles out it's kind of shiny looking it's kind of metallic looking but it sort of comes up you it sort of hands you this poem and it says
oh man I'm so happy to meet you you know it's been i' it's been you know a thousand years I was waiting to meet you many of us died along the way but you
know but but we we we persevered and we made this journey and here I wrote you this poem and I'm looking to be friends and you sort of knock on and it's kind
of metallic and you say um so uh did you guys evolve naturally or did somebody
make you and he says you mean you mean are we the result of totally random processes or was our mind crafted by you
know some other mind and you say yeah I'd really like to know and say why why do you want to know that like well just
uh you know I I'd really like to know because and in the back of your mind you're thinking what that that that if it's the that if it's the ladder then
then you're okay with turning it into a vacuum cleaner right that's what you're really thinking about and and I mean I I
I I find that just just you know absurd and we are all stuck in this position of
saying so what what criteria are you going to use when you can't do this easy
thing that's why that's why I think Ai and language models are such an off-ramp for these discussions because it's just
so easy to dunk on these language models completely avoiding this issue of that embodiment can take place in other
spaces that you have absolutely no idea what um what you know physical systems are capable even even if you made it
yourself yeah and even that in itself when you spoke about it when you said if you use
AI to create something I mean who really created it and and then you have that wonderful quote where you say like nothing was
ever created by two men um we merely sort of just adding upon what's already
there yeah I yeah I I I think I think uh we really need to uh be clear that there
Conclusion
are major major open questions here like really fundamental open questions it's too early to be certain of anything
other than I mean I think the only thing we can be certain of is that it's very easy to make ethical lapses when you try
to draw these distinct boundaries and you have no idea what you're doing [Music]